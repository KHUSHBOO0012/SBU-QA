{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tuning_squad.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "765BFKBvakDO",
        "colab_type": "code",
        "outputId": "a34d1f0d-b22b-43f1-bb49-9909ee25f728",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "#upload files from file system\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a63a1b53-b106-41f5-8118-7ecc04b3c3a2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a63a1b53-b106-41f5-8118-7ecc04b3c3a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving handmade_qa_sbu.json to handmade_qa_sbu.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'handmade_qa_sbu.json': b'{\"data\": [{\"paragraphs\": [{\"context\": \"Domestic Student Health Insurance Plan (SHIP) .Benefits and Highlights of the SHIP.SHIP has been developed especially for Stony Brook students (and their dependents) to provide access to comprehensive care that complements the quality health services on campus.The details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well-suited to the needs of the Stony Brook students and respectful of their budgets. SHIP is administered by United Healthcare. The Plans meet all of the student health insurance standards developed by the American College Health Association.SHIP is tailor-made for the college population.Provides continuous coverage at a reasonable cost for most on or off-campus medical care over Fall/Winter and Spring/Summer Semesters.Covers pre-existing medical conditions & preventative care.Annual deductible $200 for an individual.Annual out of pocket limit of $3,000 which includes deductibles, copays and coinsurance.Covers inpatient and outpatient mental health care.No deductible applied to prescription drug coverage.Please note: Office visits for Primary Care and Specialists have a $35 copayment with 0% coinsurance with a referral and 30% coinsurance without a referral.Emergency Room vs. Urgent Care: Only Emergency Services for the treatment of an Emergency Condition are covered in an ER.Emergency Room: $100 copay after policy year deductible then you pay 20% coinsurance (copayment/coinsurance waived if hospital admission).Urgent Care: $35 copay after policy year deductible then you pay 0% for cost-sharing.The fee is billed to your student account in SOLAR. Just like all other tuition & fees, this charge is payable by cash, check, money order, credit card or through financial aid. Payments are made to the Bursar in the Administration Building or through SOLAR.  If you have questions about benefits, coverage, claims or exclusions you may contact United Healthcare Customer Service at 1-800-767-0700 or  customerservice@uhcsr.com or visit  myaccount.uhcsr.com/login. For questions about insurance charges on your student account or your waiver status, you may contact the Student Health Insurance Office located at - FSA Services Office,157 East Side Dining, Phone: (631) 632-6517, Email: studenthealthinsurance@stonybrook.edu.\", \"qas\": [{\"answers\": [{\"answer_start\": 0, \"text\": \"Student Health Insurance plan (SHIP)\"}], \"question\": \"Which insurance is available for domestic stuents?\", \"id\": \"c0a0\"}, {\"answers\": [{\"answer_start\": 486, \"text\": \"United Healthcare\"}], \"question\": \"Who administrates SHIP?\", \"id\": \"c0a1\"}, {\"answers\": [{\"answer_start\": 877, \"text\": \"$200\"}], \"question\": \"What is the annual deductible amount for SHIP?\", \"id\": \"c0a2\"}, {\"answers\": [{\"answer_start\": 930, \"text\": \"$3,000\"}], \"question\": \"What is the Annual out of pocket limit?\", \"id\": \"c0a3\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"Solar account\"}], \"question\": \"Where is the fee billed?\", \"id\": \"c0a4\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"United Healthcare Customer Service at 1-800-767-0700 or customerservice@uhcsr.com or visit  myaccount.uhcsr.com/login   \"}], \"question\": \"Who should we contact for questions related to claims?\", \"id\": \"c0a5\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \" FSA Services Office 157 East Side Dining Phone: (631) 632-6517 Email: studenthealthinsurance@stonybrook.edu \"}], \"question\": \"Who should we contact for questions related to insurance charges?\", \"id\": \"c0a6\"}]}, {\"context\": \"2018 - 2019 United Healthcare Rates for Fall/Winter 2018 is $624.45 and for Spring/Summer 2019 is $867.83. This is billed to your student account in SOLAR.Unlimited coverage for primary care providers, specialists, emergency visits and hospitals. Unlimited coverage for preventative care, including annual physicals, GYN exams, routine screenings and immunizations. Prescription Drug Coverage: $10 copay for tier 1 drugs, and a $20 copay for tier 2 or 3 drugs. Unlimited coverage for inter-collegiate athletics. Unlimited coverage for mental health. Evacuation and Repatriation Services. Coverage for Gender Reassignment Care. \", \"qas\": [{\"answers\": [{\"answer_start\": 60, \"text\": \"$624.45\"}], \"question\": \"What is the cost of insurance for Fall 2018?\", \"id\": \"c1a0\"}, {\"answers\": [{\"answer_start\": 98, \"text\": \"$867.83\"}], \"question\": \"What is the cost of insurance for Spring 2019?\", \"id\": \"c1a1\"}, {\"answers\": [{\"answer_start\": 394, \"text\": \"$10\"}], \"question\": \"What is the copay for tier 1 drugs?\", \"id\": \"c1a2\"}, {\"answers\": [{\"answer_start\": 428, \"text\": \"$20\"}], \"question\": \"What is the copay for tier 2 drugs?\", \"id\": \"c1a3\"}, {\"answers\": [{\"answer_start\": 428, \"text\": \"$20\"}], \"question\": \"What is the copay for tier 2 drugs?\", \"id\": \"c1a4\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"Solar account\"}], \"question\": \"Where is the fee billed?\", \"id\": \"c1a5\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"unlimited\"}], \"question\": \"How much coverge for emergency room visits?\", \"id\": \"c1a6\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"unlimited\"}], \"question\": \"How much coverge for hospital visits?\", \"id\": \"c1a7\"}]}, {\"context\": \"You are required to graduate as soon as you complete the requirements for the degree. You can always take additional classes as a non-matriculated student after your graduation or even informally work with a professor assuming you have a working relationship with a professor already. Note that if you are an international student, you may require appropriate immigration authorization for this. But in no case you can delay your graduation.\", \"qas\": [{\"answers\": [{\"answer_start\": 285, \"text\": \"No\"}], \"question\": \"Can I stay after completing my graduation requirements?\", \"id\": \"c2a0\"}]}, {\"context\": \"A course can be repeated once for \\\\\"grade forgiveness.\\\\\"  Only the most recent attempt/grade will count towards the grade point average, but both attempts and both grades will appear on the official transcript. Retaking a course requires prior approval on the \\\\\"GRADUATE COURSE RETAKE APPROVAL FORM\\\\u200b\\\\\" available from the Graduate School website. Note only courses designated in the graduate bulletin as \\\\\"not repeatable for credit\\\\\" can be retaken this way. Grades for courses that are \\\\\"repeatable for credit\\\\\" cannot be forgiven this way. \", \"qas\": [{\"answers\": [{\"answer_start\": 209, \"text\": \"Retaking a course requires prior approval on the \\\\\"GRADUATE COURSE RETAKE APPROVAL FORM\\\\u200b\\\\\" available from the Graduate School website\"}], \"question\": \"Can I repeat the same class under the same or different professor to improve my grade?\", \"id\": \"c3a0\"}]}, {\"context\": \"Niranjan Balasubramanian \\\\u200bis affiliated with the Department of Biomedical Informatics and Center of Excellence in Wireless & Information Technology (CEWIT). He received his PhD from University of Massachusetts, Amherst, where he was a part of the Center for Intelligent Information Retrieval (CIIR). Before he started his PhD studies, he was a software engineer at the Center For Natural Language Processing (CNLP) at Syracuse University. He completed his Masters degree in Computer Science at the University of Buffalo in 2003. Prior to joining the computer science department at Stony Brook in spring 2015, Dr. Balasubramanian was a post-doctoral researcher in the Turing Center at the University of Washington in Seattle.Niranjan Balasubramanian\\'s research is motivated by the challenge of building systems that can extract, understand, and reason with information present in natural language texts. His research interests are in two broad areas: NLP and information retrieval. He has worked on different projects in areas like  Question Answering at a 4th Grade Level, Event Schema Generation from news stories, Machine Learning for Information Retrieval, Energy-efficient Mobile Search, and Automatic Wikipedia Pages. \", \"qas\": [{\"answers\": [{\"answer_start\": 182, \"text\": \"University of Massachusetts, Amherst\"}], \"question\": \"Niranjan received his PhD from which university?\", \"id\": \"c4a0\"}]}, {\"context\": \"Rezaul Chowdhury received his Ph.D. from the Department of Computer Sciences, UT Austin, working with Professor Vijaya Ramachandran, and defending \\\\\"Cache-efficient Algorithms and Data Structures: Theory and Experimental Evaluation\\\\\". Prior to joining SBU in 2011, he was in Boston working with Professor Sandor Vajda\\'s Structural Bioinformatics Group at Boston University, and Professor Charles Leiserson\\'s SuperTech Research Group at MIT. Before moving to Boston, he was a postdoctoral fellow at the Center for Computational Visualization (CVC), Institute for Computational Engineering & Sciences (ICES), University of Texas at Austin. He worked with Professor Chandrajit Bajaj. Chowdhury now leads the Theoretical and Experimental Algorithmics (TEA) Group where they concentrate on both algorithm design and algorithm engineering. He holda a joint appointment with the Institute for Advanced Computational Sciences (IACS).Rezaul Chowdhury is currently involved in an NSF-funded project with Charles Leiserson and Steven Johnson of MIT on building a stencil computation compiler called \\\\\"Pochoir\\\\\". A stencil defines the value of a grid point in a d-dimensional spatial grid at time t as a function of neighboring grid points at recent times before t. Stencil computations are conceptually simple to implement using nested loops, but looping implementations suffer from poor cache performance on multicore processors. Cache-efficient divide-and-conquer stencil algorithms exist, but most programmers find them difficult to implement. Moreover, open problems remain in adapting these algorithms to realistic applications that lack the perfect regularity of simple examples. This research aims to develop a language embedded in C++ that can express stencil computations concisely and can be compiled automatically into highly efficient algorithmic code that will make good use of the memory hierarchy and processor pipelines endemic to multicore processors and will run fast on a diverse set of hardware platforms. A wide variety of stencil-based applications \\\\u2014 ranging across physics, biology, chemistry, energy, climate, mechanical and electrical engineering, finance, and other areas \\\\u2014 will become easier to develop and maintain. Some of his other projects focus on efficient resource-oblivious algorithms, fast energetics computation, and protein-protein docking Awards. Rezaul Chowdhury is a recipient of the prestigious NSF CAREER Award. Rezaul Chowdhury received a best paper award in IPDPS 2010 for introducing the notion of multicore-oblivious algorithms. He is also interested in programming contests, and won an ACM ICPC Regional Contest as a student. Some contest problems he authored for training students are included in the \\\\\"Programming Challenges: The Programming Contest Training Manual\\\\\" by Steven Skiena & Miguel Revilla. \", \"qas\": [{\"answers\": [{\"answer_start\": 78, \"text\": \"UT Austin\"}], \"question\": \"Prof Rezaul received his PhD from which university?\", \"id\": \"c5a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"physics, biology, chemistry, energy, climate, mechanical and electrical engineering, finance \"}], \"question\": \"What are some stencil based applications?\", \"id\": \"c5a1\"}, {\"answers\": [{\"answer_start\": 2503, \"text\": \"introducing the notion of multicore-oblivious algorithms\"}], \"question\": \"Prof Rezaul received best paper award for which paper?\", \"id\": \"c5a2\"}, {\"answers\": [{\"answer_start\": 1039, \"text\": \"building a stencil computation compiler called \\\\\"Pochoir\\\\\"\"}], \"question\": \"Prof Rezaul is involved in which NSF funded project?\", \"id\": \"c5a3\"}, {\"answers\": [{\"answer_start\": 464, \"text\": \"he was a postdoctoral fellow at the Center for Computational Visualization (CVC), Institute for Computational Engineering & Sciences (ICES), University of Texas at Austin\"}], \"question\": \"Before moving to Boston, Prof Rezaul was involved in which project?\", \"id\": \"c5a4\"}]}, {\"context\": \"In 1965, the State University appointed John S. Toll, a renowned physicist from the University of Maryland as the second president of Stony Brook.[14] In 1966, the University set forth initial timetables for the development of the Health Science Center, which would house the University\\'s health programs and hospital. Despite the budgetary concerns and challenges from Albany, the University released a formalized plan early in 1968 and funding for recruitment of faculty was provided. At the same time, residential housing was expanded to 3,000, the Stony Brook Union opened in 1970, and in 1971, the massive expansion project for the campus library (named in memory of Frank Melville Jr., father of philanthropist Ward Melville) was completed.\", \"qas\": [{\"answers\": [{\"answer_start\": 40, \"text\": \"John S. Toll\"}], \"question\": \"Who was second president of stony brook university?\", \"id\": \"c6a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"1,970\"}, {\"answer_start\": 580, \"text\": \"1970\"}], \"question\": \"When did stony brook university expanded stuent housing?\", \"id\": \"c6a1\"}]}, {\"context\": \"The institution was founded 61 years ago in 1957 in Oyster Bay as State University College on Long Island, and moved to Stony Brook in 1962.The university has expanded to include approximately 220 major buildings with a combined area of more than 12.2 million gross square feet across 1,454 acres (5.9 km2) of land. In 2001, Stony Brook was elected to the Association of American Universities, joining four private universities (Cornell, Columbia, NYU, and Rochester) and one public university (SUNY Buffalo) elsewhere in its state. It is also a member of the larger Universities Research Association.\", \"qas\": [{\"answers\": [{\"answer_start\": 44, \"text\": \"1957\"}, {\"answer_start\": 0, \"text\": \"in1957\"}], \"question\": \"When was stony brook university founded?\", \"id\": \"c7a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"220#around 220\"}], \"question\": \"How many buildings does university have?\", \"id\": \"c7a1\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"yes\"}, {\"answer_start\": 0, \"text\": \"it is\"}], \"question\": \"Is sbu part of Universities Research Association?\", \"id\": \"c7a2\"}]}, {\"context\": \"The State University of New York at Stony Brook, commonly known as Stony Brook University (SBU) or SUNY Stony Brook, is a public sea-grant and space-grant research university in Stony Brook, New York. It is part of the State University of New York (SUNY) system.\", \"qas\": [{\"answers\": [{\"answer_start\": 36, \"text\": \"Stony Brook\"}, {\"answer_start\": 0, \"text\": \"New york\"}, {\"answer_start\": 0, \"text\": \"Long Island\"}], \"question\": \"Where is stony brook university located?\", \"id\": \"c8a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"Yes\"}, {\"answer_start\": 0, \"text\": \"it is\"}], \"question\": \"Is Stony Brook university part of SUNY system?\", \"id\": \"c8a1\"}]}, {\"context\": \"Stony Brook\\'s intercollegiate athletic teams are the Seawolves. Since 1994, they have competed in Division I of the NCAA, and are members of the America East Conference and the Colonial Athletic Association.\", \"qas\": [{\"answers\": [{\"answer_start\": 0, \"text\": \"Seawolvers\"}], \"question\": \"By what name stony brook athletic team is known?\", \"id\": \"c9a0\"}]}, {\"context\": \"Stony Brook is the largest single-site employer on Long Island; more than 26,000 students are enrolled at the university, which has over 15,000 employees and over 2,700 faculty.\", \"qas\": [{\"answers\": [{\"answer_start\": 64, \"text\": \"more than 26,000\"}], \"question\": \"How many employees does university have?\", \"id\": \"c10a0\"}]}, {\"context\": \"In 1960 the Heald Report, commissioned by Governor Nelson Rockefeller, recommended a major new public university be built on Long Island to \\\\\"stand with the finest in the country\\\\\", a report that would ultimately shape most of the University\\'s growth for years to come.\", \"qas\": [{\"answers\": [{\"answer_start\": 51, \"text\": \"Nelson Rockefeller\"}, {\"answer_start\": 42, \"text\": \"Governor Nelson Rockefeller\"}], \"question\": \"Who was governor of New york in 1960?\", \"id\": \"c11a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"in 1960\"}, {\"answer_start\": 3, \"text\": \"1960\"}], \"question\": \"When was Heral Report commissioned?\", \"id\": \"c11a1\"}]}, {\"context\": \"Ward Melville, a philanthropist and businessman from the Three Village area in western Suffolk County donated over 400 acres of land to the state for the development of a state university and in 1962 the institution relocated to Stony Brook and officially renamed as the State University of New York at Stony Brook. However, the name has fallen out of favor, and since 2005, has been replaced with simply Stony Brook University (SBU).The campus had 782 students enrolled in 1962, but enrollment had increased more than tenfold by 1969, surpassing the 8,000 mark, fueled by the large funding of public higher education in the Sputnik era. In 1963, only three years after the release of the Heald Report, the Governor commissioned the \\\\\"Education of Health Professions\\\\\" (Muir Report) report. The report outlined the need for expansion of the university system to prepare medical professionals for the future needs of the state. The report was particularly important for Stony Brook as it recommended creation of a Health Science Center and academic hospital at the campus to serve the need of the fastest-growing counties (Nassau and Suffolk) in New York at the time.\", \"qas\": [{\"answers\": [{\"answer_start\": 449, \"text\": \"782\"}], \"question\": \"How many students were enrolled in 1962?\", \"id\": \"c12a0\"}]}, {\"context\": \"The 1990s affirmed Stony Brook\\'s success at building a research university with a strong undergraduate education. Under the leadership of its fourth president, Shirley Strum Kenny, the administration sought out to showcase the value of the institution. Kenny was responsible for campus wide improvement projects which included large scale landscaping, renovations of every residence hall, the continued growth of the athletics programs, the improvement of student life, ever increasing research expenditures, a branding/marketing campaign, and the University\\'s increasing ties with private philanthropy.\", \"qas\": [{\"answers\": [{\"answer_start\": 160, \"text\": \"Shirley Strum Kenny\"}, {\"answer_start\": 0, \"text\": \"kenny\"}], \"question\": \"Who was forth president of stony brook univerist?\", \"id\": \"c13a0\"}]}, {\"context\": \"In 1998, the University became one of the top 100 of American research universities in the U.S. News & World Report, and its relatively affordable tuition placed it among the best values among universities in the nation. That same year, the University and Battelle Memorial Institute were chosen by the Department of Energy as joint operators of the Brookhaven National Laboratories, joining a selective group of universities that operated national laboratories across the nation. Enrollment reached the 20,000 mark in 2001, and the administration\\'s improvement efforts climaxed with the invitation to the highly selective Association of American Universities, an organization of sixty-two universities across North America committed to a strong system of research and education, becoming only the third public university in the northeast to receive such invitation (Buffalo and Rutgers admitted in 1989).\", \"qas\": [{\"answers\": [{\"answer_start\": 0, \"text\": \"relatively affordable tuition#relatively affordable\"}], \"question\": \"What makes stony brook univeristy best values univeristY?\", \"id\": \"c14a0\"}]}, {\"context\": \"2002 saw the opening of the $22 million Kenneth P. LaValle Stadium and the inauguration of the massive Charles B. Wang Center dedicated to Asian and American culture, funded by a $50 million donation from Charles B. Wang. At the time, it was the largest private donation to a SUNY institution. In 2003, chemistry professor Paul Lauterbur received a Nobel Prize in Physiology or Medicine for his research and discovery of Nuclear Magnetic Resonance, which was instrumental in the development of NMR Imaging (MRI) while at Stony Brook. In 2005, the University bought the Flowerfield property adjacent to campus through eminent domain as land for the development of a Research and Development Park. Plans for a law school were in the talks but scrapped shortly after. In 2009, president Shirley Strum Kenny stepped down, and in May, Dr. Samuel Stanley Jr was announced as Stony Brook\\'s fifth president. The late 2000s saw the University receive historic philanthropic donations. Hedge funder Jim Simons made multiple multi-million donations, including a $25 million donation to the Stony Brook Foundation in 2006, a $60 million donation for the development of the Simons Center for Geometry and Physics in 2008, and a landmark $150 million donation to the University in 2011. Other major donations were provided by alumni Joe Nathan, Stuart Goldstein, and Glenn Dubin for major renovation of athletic facilities. In 2010 Stanley announced Project 50 Forward, a comprehensive plan for the development of the University in the next fifty years with a focus on \\\\u201coperational excellence, academic greatness, and building for the future.\\\\\"\", \"qas\": [{\"answers\": [{\"answer_start\": 0, \"text\": \"Kenneth P. LaValle Stadium# kenneth#Kenneth P. LaValle\"}], \"question\": \"Which stadium was opened in 2002?\", \"id\": \"c15a0\"}, {\"answers\": [{\"answer_start\": 1319, \"text\": \"Joe Nathan, Stuart Goldstein, and Glenn Dubin\"}], \"question\": \"Who helped in mojor innovation of athletic facility?\", \"id\": \"c15a1\"}]}, {\"context\": \"In 2012, the $40 million Walter J. Hawrys Campus Recreation Center opened, soon followed by the on-campus Hilton Garden Inn in May 2013. Frey Hall, named after alumnus Dr. Robert Frey, opened in 2013 after undergoing renovations as the former Old Chemistry building. The Stony Brook University Arena underwent a $21 million overhaul, re-opening as the Island Federal Arena in 2014. In July 2015, a new $40.8 million Computer Science building opened, spanning 70,000 square feet. New dormitories, known as Chavez Hall and Tubman Hall, along with a new East Side Dining hall, opened in the fall of 2016. In January 2019, Stony Brook Medicine is set to open their $194 million cancer center to the public.Current projects include the renovation of the Stony Brook Union, a new $100 million engineering and applied sciences building and an on-campus housing complex.In 2018, Stony Brook received its best ranking yet in the U.S. News & World Report, at 80th in the United States.\", \"qas\": [{\"answers\": [{\"answer_start\": 459, \"text\": \"70,000 square feet\"}, {\"answer_start\": 0, \"text\": \"70000\"}], \"question\": \"What is span of new computer science buiding?\", \"id\": \"c16a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"$40.8 million#40.8 million\"}], \"question\": \"How much new Computer science building costed?\", \"id\": \"c16a1\"}]}, {\"context\": \"The west campus is the center of the academic life of the university. It houses the majority of academic, athletic, and undergraduate student housing facilities while also being the original site of the university. The modern campus is centered around the academic mall which stretches for more than a quarter of a mile from the Simons Center for Geometry and Physics in the west end to the Administration Building in the east end. The academic mall includes the Student Activity Center, Frank Melville Jr. Memorial Library, Staller Center for the Arts, Humanities, Psychology A & B, Harriman Hall, Frey Hall (previously known as Old Chemistry), the Earth and Space Science, Mathematics, and Physics facilities. Short distances from the mall are the Engineering Quad home to the Engineering, Light Engineering, Heavy Engineering, and Computing Center facilities. The Life Science Complex, Javits Lecture Center, Social Behavioral Sciences, Computer Science, and Student Union facilities are also on the west campus. Among the latest additions to the campus is the Simons Center for Geometry and Physics, the new Walter J. Hawrys Campus Recreation Center, the Hilton Garden Inn hotel, Frey Hall, and a new Computer Science building. The Staller Center which contains the largest movie screen in Long Island\\'s Suffolk County holds the annual Stony Brook Film Festival. The athletic facilities are in the northwest quadrant of west campus which include the Stony Brook Sports Complex, Stony Brook University Arena, Kenneth P. LaValle Stadium, Joe Nathan Field, University Track, and University Field.\", \"qas\": [{\"answers\": [{\"answer_start\": 0, \"text\": \"List out Athletic facilities of stony brook univeristy.\"}], \"question\": \"Which campus is center for academic life in Stony Brook University?\", \"id\": \"c17a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"\"}], \"question\": \"Stony Brook Sports Complex, Stony Brook University Arena, Kenneth P. LaValle Stadium, Joe Nathan Field, University Track, and University Field\", \"id\": \"c17a1\"}]}, {\"context\": \"The university\\'s athletics teams were originally known as the Soundmen or the Baymen in the early 1950s when the campus was located in Oyster Bay. Their name was changed to the Warriors in 1960, and again to the Patriots and Lady Patriots in 1966. In 1994, as Stony Brook prepared to become a Division I program, the team nickname was changed again, this time to its current day incarnation, the Seawolves. The team\\'s mascot is named Wolfie. Stony Brook games are announced by Josh Caray, grandson of famed broadcaster Harry Caray and son of Skip Caray.\", \"qas\": [{\"answers\": [{\"answer_start\": 62, \"text\": \"Soundmen or the Baymen\"}, {\"answer_start\": 62, \"text\": \"Soundmen\"}, {\"answer_start\": 78, \"text\": \"Baymen\"}], \"question\": \"What was original name of university\\'s athletic team?\", \"id\": \"c18a0\"}, {\"answers\": [{\"answer_start\": 0, \"text\": \"wolfie\"}], \"question\": \"What is mascot of stony brook univeristy team?\", \"id\": \"c18a1\"}]}, {\"context\": \"In recent years, Stony Brook\\'s athletic facilities have undergone several additions and renovations. The Goldstein Family Student-Athlete Development Center opened in 2006 after a million-dollar donation by alumnus Stuart Goldstein. In 2011, Joe Nathan Field, dedicated to six-time MLB All-Star relief pitcher and Stony Brook alumnus Joe Nathan, opened after renovations to the former University Field were made possible by Nathan\\'s $500,000 donation. Island Federal Arena, formerly known as the Stony Brook University Arena, opened in 2014 after a two-year, $21.1 million renovation. The Pritchard Gymnasium, current home of the volleyball team and former home of the men\\'s and women\\'s basketball teams, underwent a $1.5 million renovation in 2008. Alumnus Glenn Dubin donated $4.3 million to a strength and conditioning facility named the Dubin Family Athletic Performance Center, which opened in 2012. The Dubin family also pledged $5 million for a $10 million for the Dubin Family Indoor Training Center, set to open in early 2019.Stony Brook garnered national attention during their 2012 College World Series run. The Seawolves upset the LSU Tigers in a three-game series to win the Baton Rouge Super Regional and reach the College World Series in Omaha, the first America East team to do so. Coach Matt Senk was awarded the National College Baseball Writers Association\\'s Coach of the Year award. Outfielder Travis Jankowski was drafted by the San Diego Padres in the first round of the 2012 MLB Draft.After going winless in four consecutive America East Finals in men\\'s basketball, the Seawolves earned their first bid to the NCAA Tournament in 2016 by defeating the Vermont Catamounts 80\\\\u201374. They lost to Kentucky in the first round of the NCAA Tournament by a score of 85\\\\u201357.Stony Brook has established itself as a dominant force in women\\'s lacrosse. Since 2013, the Seawolves have finished in first place in the America East for six straight seasons, making six consecutive NCAA Division I Women\\'s Lacrosse Championship tournaments. During the 2018 season, the Seawolves were ranked No. 1 nationally in all three major polls (IWLCA Coaches\\' Poll, Cascade/Inside Lacrosse, Nike/US Lacrosse) for at least ten weeks.\", \"qas\": [{\"answers\": [{\"answer_start\": 242, \"text\": \"Joe Nathan\"}, {\"answer_start\": 0, \"text\": \" NBA pitcher Joe Nathan Field\"}], \"question\": \"To whom Joe Nathan Field is dedicated to?\", \"id\": \"c19a0\"}, {\"answers\": [{\"answer_start\": 2043, \"text\": \"During the 2018 season\"}, {\"answer_start\": 2054, \"text\": \"2018\"}], \"question\": \"in which season  stony brook university ranked 1?\", \"id\": \"c19a1\"}]}, {\"context\": \"In 2013, Stony Brook University launched its own bike share system to provide a sustainable transportation alternative for students (Wolf Ride Bike Share). In 2016, the university provides 8 stations and 63 bikes.Docking stations and bikes are supplied by PBSC Urban Solutions.The university is next to the Stony Brook LIRR station on the Port Jefferson Line.\", \"qas\": [{\"answers\": [{\"answer_start\": 339, \"text\": \"Port Jefferson\"}], \"question\": \"How many departments are present in Stony Brook University?\", \"id\": \"c20a0\"}]}]}]}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "TBO17MxCazKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "r_lwbIT6XOvl",
        "colab_type": "code",
        "outputId": "8ef80b31-ac14-463a-dd96-aeb1f79e62f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "#upload files from drive (RECOMMENDED-faster than uploading from local file system)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gGiZWVQGZ-zM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "164295c9-4173-487b-b6d5-beb5c05b493b"
      },
      "cell_type": "code",
      "source": [
        "!cp -a '/content/drive/My Drive/bert_reqs/output_small' .\n",
        "!unzip uncased_L-12_H-768_A-12.zip\n",
        "!ls output_small/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "events.out.tfevents.1544376696.39f9f894c121\n",
            "graph.pbtxt\n",
            "model.ckpt-10000.data-00000-of-00001\n",
            "model.ckpt-10000.index\n",
            "model.ckpt-10000.meta\n",
            "model.ckpt-11000.data-00000-of-00001\n",
            "model.ckpt-11000.index\n",
            "model.ckpt-11000.meta\n",
            "model.ckpt-7000.data-00000-of-00001\n",
            "model.ckpt-7000.index\n",
            "model.ckpt-7000.meta\n",
            "model.ckpt-8000.data-00000-of-00001\n",
            "model.ckpt-8000.index\n",
            "model.ckpt-8000.meta\n",
            "model.ckpt-9000.data-00000-of-00001\n",
            "model.ckpt-9000.index\n",
            "model.ckpt-9000.meta\n",
            "train.tf_record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rERgDuNUWMyQ",
        "colab_type": "code",
        "outputId": "f8f66174-090a-411b-e95d-47f98a03c1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# TASK = 'qna_sbu'\n",
        "# TASK = 'dev-v2.0'\n",
        "# TASK_DATA_DIR = TASK+'.json'\n",
        "# print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "# !ls $TASK_DATA_DIR\n",
        "\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = 'uncased_L-12_H-768_A-12/'#+BERT_MODEL\n",
        "BERT_BASE_DIR = BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "\n",
        "\n",
        "OUTPUT_DIR = 'output_small'\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: uncased_L-12_H-768_A-12/ *****\n",
            "***** Model output directory: output_small *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ncwCt5n8OSg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following really verbose cells was copied from run_squad.py in an attempt to understand the concept of fine-tuning more thouroughly, you can run the run_squad.py file directly"
      ]
    },
    {
      "metadata": {
        "id": "pWod0J3J3BOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import six\n",
        "import tensorflow as tf\n",
        "\n",
        "flags = tf.flags\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "## Required parameters\n",
        "flags.DEFINE_string(\n",
        "    \"bert_config_file\", BERT_MODEL+'/bert_config.json',\n",
        "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
        "    \"This specifies the model architecture.\")\n",
        "\n",
        "flags.DEFINE_string(\"vocab_file\", BERT_MODEL+'/vocab.txt',\n",
        "                    \"The vocabulary file that the BERT model was trained on.\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"output_dir\", OUTPUT_DIR,\n",
        "    \"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "## Other parameters\n",
        "flags.DEFINE_string(\"train_file\", None,\n",
        "                    \"SQuAD json for training. E.g., train-v1.1.json\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"predict_file\", TASK+'.json',\n",
        "    \"SQuAD json for predictions. E.g., dev-v1.1.json or test-v1.1.json\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"init_checkpoint\", None,\n",
        "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"do_lower_case\", True,\n",
        "    \"Whether to lower case the input text. Should be True for uncased \"\n",
        "    \"models and False for cased models.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_seq_length\", 384,\n",
        "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
        "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
        "    \"than this will be padded.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"doc_stride\", 128,\n",
        "    \"When splitting up a long document into chunks, how much stride to \"\n",
        "    \"take between chunks.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_query_length\", 64,\n",
        "    \"The maximum number of tokens for the question. Questions longer than \"\n",
        "    \"this will be truncated to this length.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n",
        "\n",
        "flags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n",
        "\n",
        "flags.DEFINE_integer(\"predict_batch_size\", 8,\n",
        "                     \"Total batch size for predictions.\")\n",
        "\n",
        "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
        "\n",
        "flags.DEFINE_float(\"num_train_epochs\", 3.0,\n",
        "                   \"Total number of training epochs to perform.\")\n",
        "\n",
        "flags.DEFINE_float(\n",
        "    \"warmup_proportion\", 0.1,\n",
        "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
        "    \"E.g., 0.1 = 10% of training.\")\n",
        "\n",
        "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
        "                     \"How often to save the model checkpoint.\")\n",
        "\n",
        "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
        "                     \"How many steps to make in each estimator call.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"n_best_size\", 20,\n",
        "    \"The total number of n-best predictions to generate in the \"\n",
        "    \"nbest_predictions.json output file.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_answer_length\", 30,\n",
        "    \"The maximum length of an answer that can be generated. This is needed \"\n",
        "    \"because the start and end predictions are not conditioned on one another.\")\n",
        "\n",
        "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_name\", None,\n",
        "    \"The Cloud TPU to use for training. This should be either the name \"\n",
        "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
        "    \"url.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_zone\", None,\n",
        "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"gcp_project\", None,\n",
        "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\"master\", None, \"[Optional] TensorFlow master URL.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"num_tpu_cores\", 8,\n",
        "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"verbose_logging\", False,\n",
        "    \"If true, all of the warnings related to data processing will be printed. \"\n",
        "    \"A number of warnings are expected for a normal SQuAD evaluation.\")\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    \"version_2_with_negative\", False,\n",
        "    \"If true, the SQuAD examples contain some that do not have an answer.\")\n",
        "\n",
        "flags.DEFINE_float(\n",
        "    \"null_score_diff_threshold\", 0.0,\n",
        "    \"If null_score - best_non_null is greater than the threshold predict null.\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YO1nMl-2ujng",
        "colab_type": "code",
        "outputId": "27307b3b-7b72-4b21-b27f-24d65e11e254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8052
        }
      },
      "cell_type": "code",
      "source": [
        "class SquadExample(object):\n",
        "  \"\"\"A single training/test example for simple sequence classification.\n",
        "\n",
        "     For examples without an answer, the start and end position are -1.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               qas_id,\n",
        "               question_text,\n",
        "               doc_tokens,\n",
        "               orig_answer_text=None,\n",
        "               start_position=None,\n",
        "               end_position=None,\n",
        "               is_impossible=False):\n",
        "    self.qas_id = qas_id\n",
        "    self.question_text = question_text\n",
        "    self.doc_tokens = doc_tokens\n",
        "    self.orig_answer_text = orig_answer_text\n",
        "    self.start_position = start_position\n",
        "    self.end_position = end_position\n",
        "    self.is_impossible = is_impossible\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.__repr__()\n",
        "\n",
        "  def __repr__(self):\n",
        "    s = \"\"\n",
        "    s += \"qas_id: %s\" % (tokenization.printable_text(self.qas_id))\n",
        "    s += \", question_text: %s\" % (\n",
        "        tokenization.printable_text(self.question_text))\n",
        "    s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
        "    if self.start_position:\n",
        "      s += \", start_position: %d\" % (self.start_position)\n",
        "    if self.start_position:\n",
        "      s += \", end_position: %d\" % (self.end_position)\n",
        "    if self.start_position:\n",
        "      s += \", is_impossible: %r\" % (self.is_impossible)\n",
        "    return s\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               unique_id,\n",
        "               example_index,\n",
        "               doc_span_index,\n",
        "               tokens,\n",
        "               token_to_orig_map,\n",
        "               token_is_max_context,\n",
        "               input_ids,\n",
        "               input_mask,\n",
        "               segment_ids,\n",
        "               start_position=None,\n",
        "               end_position=None,\n",
        "               is_impossible=None):\n",
        "    self.unique_id = unique_id\n",
        "    self.example_index = example_index\n",
        "    self.doc_span_index = doc_span_index\n",
        "    self.tokens = tokens\n",
        "    self.token_to_orig_map = token_to_orig_map\n",
        "    self.token_is_max_context = token_is_max_context\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.start_position = start_position\n",
        "    self.end_position = end_position\n",
        "    self.is_impossible = is_impossible\n",
        "\n",
        "\n",
        "def read_squad_examples(input_file, is_training):\n",
        "  \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
        "  with tf.gfile.Open(input_file, \"r\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "  def is_whitespace(c):\n",
        "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  examples = []\n",
        "  for entry in input_data:\n",
        "    for paragraph in entry[\"paragraphs\"]:\n",
        "      paragraph_text = paragraph[\"context\"]\n",
        "      doc_tokens = []\n",
        "      char_to_word_offset = []\n",
        "      prev_is_whitespace = True\n",
        "      for c in paragraph_text:\n",
        "        if is_whitespace(c):\n",
        "          prev_is_whitespace = True\n",
        "        else:\n",
        "          if prev_is_whitespace:\n",
        "            doc_tokens.append(c)\n",
        "          else:\n",
        "            doc_tokens[-1] += c\n",
        "          prev_is_whitespace = False\n",
        "        char_to_word_offset.append(len(doc_tokens) - 1)\n",
        "\n",
        "      for qa in paragraph[\"qas\"]:\n",
        "        qas_id = qa[\"id\"]\n",
        "        question_text = qa[\"question\"]\n",
        "        start_position = None\n",
        "        end_position = None\n",
        "        orig_answer_text = None\n",
        "        is_impossible = False\n",
        "        if is_training:\n",
        "\n",
        "          if FLAGS.version_2_with_negative:\n",
        "            is_impossible = qa[\"is_impossible\"]\n",
        "          if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
        "            raise ValueError(\n",
        "                \"For training, each question should have exactly 1 answer.\")\n",
        "          if not is_impossible:\n",
        "            answer = qa[\"answers\"][\"0\"]\n",
        "            orig_answer_text = answer[\"text\"]\n",
        "            answer_offset = answer[\"answer_start\"]\n",
        "            answer_length = len(orig_answer_text)\n",
        "            start_position = char_to_word_offset[answer_offset]\n",
        "            end_position = char_to_word_offset[answer_offset + answer_length -\n",
        "                                               1]\n",
        "            # Only add answers where the text can be exactly recovered from the\n",
        "            # document. If this CAN'T happen it's likely due to weird Unicode\n",
        "            # stuff so we will just skip the example.\n",
        "            #\n",
        "            # Note that this means for training mode, every example is NOT\n",
        "            # guaranteed to be preserved.\n",
        "            actual_text = \" \".join(\n",
        "                doc_tokens[start_position:(end_position + 1)])\n",
        "            cleaned_answer_text = \" \".join(\n",
        "                tokenization.whitespace_tokenize(orig_answer_text))\n",
        "            if actual_text.find(cleaned_answer_text) == -1:\n",
        "              tf.logging.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
        "                                 actual_text, cleaned_answer_text)\n",
        "              continue\n",
        "          else:\n",
        "            start_position = -1\n",
        "            end_position = -1\n",
        "            orig_answer_text = \"\"\n",
        "\n",
        "        example = SquadExample(\n",
        "            qas_id=qas_id,\n",
        "            question_text=question_text,\n",
        "            doc_tokens=doc_tokens,\n",
        "            orig_answer_text=orig_answer_text,\n",
        "            start_position=start_position,\n",
        "            end_position=end_position,\n",
        "            is_impossible=is_impossible)\n",
        "        examples.append(example)\n",
        "\n",
        "  return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
        "                                 doc_stride, max_query_length, is_training,\n",
        "                                 output_fn):\n",
        "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "  unique_id = 1000000000\n",
        "\n",
        "  for (example_index, example) in enumerate(examples):\n",
        "    query_tokens = tokenizer.tokenize(example.question_text)\n",
        "\n",
        "    if len(query_tokens) > max_query_length:\n",
        "      query_tokens = query_tokens[0:max_query_length]\n",
        "\n",
        "    tok_to_orig_index = []\n",
        "    orig_to_tok_index = []\n",
        "    all_doc_tokens = []\n",
        "    for (i, token) in enumerate(example.doc_tokens):\n",
        "      orig_to_tok_index.append(len(all_doc_tokens))\n",
        "      sub_tokens = tokenizer.tokenize(token)\n",
        "      for sub_token in sub_tokens:\n",
        "        tok_to_orig_index.append(i)\n",
        "        all_doc_tokens.append(sub_token)\n",
        "\n",
        "    tok_start_position = None\n",
        "    tok_end_position = None\n",
        "    if is_training and example.is_impossible:\n",
        "      tok_start_position = -1\n",
        "      tok_end_position = -1\n",
        "    if is_training and not example.is_impossible:\n",
        "      tok_start_position = orig_to_tok_index[example.start_position]\n",
        "      if example.end_position < len(example.doc_tokens) - 1:\n",
        "        tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
        "      else:\n",
        "        tok_end_position = len(all_doc_tokens) - 1\n",
        "      (tok_start_position, tok_end_position) = _improve_answer_span(\n",
        "          all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
        "          example.orig_answer_text)\n",
        "\n",
        "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
        "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
        "\n",
        "    # We can have documents that are longer than the maximum sequence length.\n",
        "    # To deal with this we do a sliding window approach, where we take chunks\n",
        "    # of the up to our max length with a stride of `doc_stride`.\n",
        "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"DocSpan\", [\"start\", \"length\"])\n",
        "    doc_spans = []\n",
        "    start_offset = 0\n",
        "    while start_offset < len(all_doc_tokens):\n",
        "      length = len(all_doc_tokens) - start_offset\n",
        "      if length > max_tokens_for_doc:\n",
        "        length = max_tokens_for_doc\n",
        "      doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
        "      if start_offset + length == len(all_doc_tokens):\n",
        "        break\n",
        "      start_offset += min(length, doc_stride)\n",
        "\n",
        "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
        "      tokens = []\n",
        "      token_to_orig_map = {}\n",
        "      token_is_max_context = {}\n",
        "      segment_ids = []\n",
        "      tokens.append(\"[CLS]\")\n",
        "      segment_ids.append(0)\n",
        "      for token in query_tokens:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      segment_ids.append(0)\n",
        "\n",
        "      for i in range(doc_span.length):\n",
        "        split_token_index = doc_span.start + i\n",
        "        token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
        "\n",
        "        is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
        "                                               split_token_index)\n",
        "        token_is_max_context[len(tokens)] = is_max_context\n",
        "        tokens.append(all_doc_tokens[split_token_index])\n",
        "        segment_ids.append(1)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      segment_ids.append(1)\n",
        "\n",
        "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "      # tokens are attended to.\n",
        "      input_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "      assert len(input_ids) == max_seq_length\n",
        "      assert len(input_mask) == max_seq_length\n",
        "      assert len(segment_ids) == max_seq_length\n",
        "\n",
        "      start_position = None\n",
        "      end_position = None\n",
        "      if is_training and not example.is_impossible:\n",
        "        # For training, if our document chunk does not contain an annotation\n",
        "        # we throw it out, since there is nothing to predict.\n",
        "        doc_start = doc_span.start\n",
        "        doc_end = doc_span.start + doc_span.length - 1\n",
        "        out_of_span = False\n",
        "        if not (tok_start_position >= doc_start and\n",
        "                tok_end_position <= doc_end):\n",
        "          out_of_span = True\n",
        "        if out_of_span:\n",
        "          start_position = 0\n",
        "          end_position = 0\n",
        "        else:\n",
        "          doc_offset = len(query_tokens) + 2\n",
        "          start_position = tok_start_position - doc_start + doc_offset\n",
        "          end_position = tok_end_position - doc_start + doc_offset\n",
        "\n",
        "      if is_training and example.is_impossible:\n",
        "        start_position = 0\n",
        "        end_position = 0\n",
        "\n",
        "      if example_index < 20:\n",
        "        tf.logging.info(\"*** Example ***\")\n",
        "        tf.logging.info(\"unique_id: %s\" % (unique_id))\n",
        "        tf.logging.info(\"example_index: %s\" % (example_index))\n",
        "        tf.logging.info(\"doc_span_index: %s\" % (doc_span_index))\n",
        "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "            [tokenization.printable_text(x) for x in tokens]))\n",
        "        tf.logging.info(\"token_to_orig_map: %s\" % \" \".join(\n",
        "            [\"%d:%d\" % (x, y) for (x, y) in six.iteritems(token_to_orig_map)]))\n",
        "        tf.logging.info(\"token_is_max_context: %s\" % \" \".join([\n",
        "            \"%d:%s\" % (x, y) for (x, y) in six.iteritems(token_is_max_context)\n",
        "        ]))\n",
        "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "        tf.logging.info(\n",
        "            \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "        tf.logging.info(\n",
        "            \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "        if is_training and example.is_impossible:\n",
        "          tf.logging.info(\"impossible example\")\n",
        "        if is_training and not example.is_impossible:\n",
        "          answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
        "          tf.logging.info(\"start_position: %d\" % (start_position))\n",
        "          tf.logging.info(\"end_position: %d\" % (end_position))\n",
        "          tf.logging.info(\n",
        "              \"answer: %s\" % (tokenization.printable_text(answer_text)))\n",
        "\n",
        "      feature = InputFeatures(\n",
        "          unique_id=unique_id,\n",
        "          example_index=example_index,\n",
        "          doc_span_index=doc_span_index,\n",
        "          tokens=tokens,\n",
        "          token_to_orig_map=token_to_orig_map,\n",
        "          token_is_max_context=token_is_max_context,\n",
        "          input_ids=input_ids,\n",
        "          input_mask=input_mask,\n",
        "          segment_ids=segment_ids,\n",
        "          start_position=start_position,\n",
        "          end_position=end_position,\n",
        "          is_impossible=example.is_impossible)\n",
        "\n",
        "      # Run callback\n",
        "      output_fn(feature)\n",
        "\n",
        "      unique_id += 1\n",
        "\n",
        "\n",
        "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n",
        "                         orig_answer_text):\n",
        "  \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
        "\n",
        "  # The SQuAD annotations are character based. We first project them to\n",
        "  # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
        "  # often find a \"better match\". For example:\n",
        "  #\n",
        "  #   Question: What year was John Smith born?\n",
        "  #   Context: The leader was John Smith (1895-1943).\n",
        "  #   Answer: 1895\n",
        "  #\n",
        "  # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
        "  # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
        "  # the exact answer, 1895.\n",
        "  #\n",
        "  # However, this is not always possible. Consider the following:\n",
        "  #\n",
        "  #   Question: What country is the top exporter of electornics?\n",
        "  #   Context: The Japanese electronics industry is the lagest in the world.\n",
        "  #   Answer: Japan\n",
        "  #\n",
        "  # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
        "  # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
        "  # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
        "  # in SQuAD, but does happen.\n",
        "  tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
        "\n",
        "  for new_start in range(input_start, input_end + 1):\n",
        "    for new_end in range(input_end, new_start - 1, -1):\n",
        "      text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
        "      if text_span == tok_answer_text:\n",
        "        return (new_start, new_end)\n",
        "\n",
        "  return (input_start, input_end)\n",
        "\n",
        "\n",
        "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
        "  \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
        "\n",
        "  # Because of the sliding window approach taken to scoring documents, a single\n",
        "  # token can appear in multiple documents. E.g.\n",
        "  #  Doc: the man went to the store and bought a gallon of milk\n",
        "  #  Span A: the man went to the\n",
        "  #  Span B: to the store and bought\n",
        "  #  Span C: and bought a gallon of\n",
        "  #  ...\n",
        "  #\n",
        "  # Now the word 'bought' will have two scores from spans B and C. We only\n",
        "  # want to consider the score with \"maximum context\", which we define as\n",
        "  # the *minimum* of its left and right context (the *sum* of left and\n",
        "  # right context will always be the same, of course).\n",
        "  #\n",
        "  # In the example the maximum context for 'bought' would be span C since\n",
        "  # it has 1 left context and 3 right context, while span B has 4 left context\n",
        "  # and 0 right context.\n",
        "  best_score = None\n",
        "  best_span_index = None\n",
        "  for (span_index, doc_span) in enumerate(doc_spans):\n",
        "    end = doc_span.start + doc_span.length - 1\n",
        "    if position < doc_span.start:\n",
        "      continue\n",
        "    if position > end:\n",
        "      continue\n",
        "    num_left_context = position - doc_span.start\n",
        "    num_right_context = end - position\n",
        "    score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
        "    if best_score is None or score > best_score:\n",
        "      best_score = score\n",
        "      best_span_index = span_index\n",
        "\n",
        "  return cur_span_index == best_span_index\n",
        "\n",
        "\n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  final_hidden = model.get_sequence_output()\n",
        "\n",
        "  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=3)\n",
        "  batch_size = final_hidden_shape[0]\n",
        "  seq_length = final_hidden_shape[1]\n",
        "  hidden_size = final_hidden_shape[2]\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"cls/squad/output_weights\", [2, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"cls/squad/output_bias\", [2], initializer=tf.zeros_initializer())\n",
        "\n",
        "  final_hidden_matrix = tf.reshape(final_hidden,\n",
        "                                   [batch_size * seq_length, hidden_size])\n",
        "  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=True)\n",
        "  logits = tf.nn.bias_add(logits, output_bias)\n",
        "\n",
        "  logits = tf.reshape(logits, [batch_size, seq_length, 2])\n",
        "  logits = tf.transpose(logits, [2, 0, 1])\n",
        "\n",
        "  unstacked_logits = tf.unstack(logits, axis=0)\n",
        "\n",
        "  (start_logits, end_logits) = (unstacked_logits[0], unstacked_logits[1])\n",
        "\n",
        "  return (start_logits, end_logits)\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    unique_ids = features[\"unique_ids\"]\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (start_logits, end_logits) = create_model(\n",
        "        bert_config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      seq_length = modeling.get_shape_list(input_ids)[1]\n",
        "\n",
        "      def compute_loss(logits, positions):\n",
        "        one_hot_positions = tf.one_hot(\n",
        "            positions, depth=seq_length, dtype=tf.float32)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "        loss = -tf.reduce_mean(\n",
        "            tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n",
        "        return loss\n",
        "\n",
        "      start_positions = features[\"start_positions\"]\n",
        "      end_positions = features[\"end_positions\"]\n",
        "\n",
        "      start_loss = compute_loss(start_logits, start_positions)\n",
        "      end_loss = compute_loss(end_logits, end_positions)\n",
        "\n",
        "      total_loss = (start_loss + end_loss) / 2.0\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      predictions = {\n",
        "          \"unique_ids\": unique_ids,\n",
        "          \"start_logits\": start_logits,\n",
        "          \"end_logits\": end_logits,\n",
        "      }\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n",
        "\n",
        "\n",
        "def input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  name_to_features = {\n",
        "      \"unique_ids\": tf.FixedLenFeature([], tf.int64),\n",
        "      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "  }\n",
        "\n",
        "  if is_training:\n",
        "    name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
        "    name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
        "\n",
        "  def _decode_record(record, name_to_features):\n",
        "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "    example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "    # So cast all int64 to int32.\n",
        "    for name in list(example.keys()):\n",
        "      t = example[name]\n",
        "      if t.dtype == tf.int64:\n",
        "        t = tf.to_int32(t)\n",
        "      example[name] = t\n",
        "\n",
        "    return example\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    # For training, we want a lot of parallel reading and shuffling.\n",
        "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "    d = tf.data.TFRecordDataset(input_file)\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.apply(\n",
        "        tf.contrib.data.map_and_batch(\n",
        "            lambda record: _decode_record(record, name_to_features),\n",
        "            batch_size=batch_size,\n",
        "            drop_remainder=drop_remainder))\n",
        "\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "RawResult = collections.namedtuple(\"RawResult\",\n",
        "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])\n",
        "\n",
        "\n",
        "def write_predictions(all_examples, all_features, all_results, n_best_size,\n",
        "                      max_answer_length, do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file):\n",
        "  \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n",
        "  tf.logging.info(\"Writing predictions to: %s\" % (output_prediction_file))\n",
        "  tf.logging.info(\"Writing nbest to: %s\" % (output_nbest_file))\n",
        "\n",
        "  example_index_to_features = collections.defaultdict(list)\n",
        "  for feature in all_features:\n",
        "    example_index_to_features[feature.example_index].append(feature)\n",
        "\n",
        "  unique_id_to_result = {}\n",
        "  for result in all_results:\n",
        "    unique_id_to_result[result.unique_id] = result\n",
        "\n",
        "  _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "      \"PrelimPrediction\",\n",
        "      [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "  all_predictions = collections.OrderedDict()\n",
        "  all_nbest_json = collections.OrderedDict()\n",
        "  scores_diff_json = collections.OrderedDict()\n",
        "\n",
        "  for (example_index, example) in enumerate(all_examples):\n",
        "    features = example_index_to_features[example_index]\n",
        "\n",
        "    prelim_predictions = []\n",
        "    # keep track of the minimum score of null start+end of position 0\n",
        "    score_null = 1000000  # large and positive\n",
        "    min_null_feature_index = 0  # the paragraph slice with min mull score\n",
        "    null_start_logit = 0  # the start logit at the slice with min null score\n",
        "    null_end_logit = 0  # the end logit at the slice with min null score\n",
        "    for (feature_index, feature) in enumerate(features):\n",
        "      result = unique_id_to_result[feature.unique_id]\n",
        "      start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n",
        "      end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n",
        "      # if we could have irrelevant answers, get the min score of irrelevant\n",
        "      if FLAGS.version_2_with_negative:\n",
        "        feature_null_score = result.start_logits[0] + result.end_logits[0]\n",
        "        if feature_null_score < score_null:\n",
        "          score_null = feature_null_score\n",
        "          min_null_feature_index = feature_index\n",
        "          null_start_logit = result.start_logits[0]\n",
        "          null_end_logit = result.end_logits[0]\n",
        "      for start_index in start_indexes:\n",
        "        for end_index in end_indexes:\n",
        "          # We could hypothetically create invalid predictions, e.g., predict\n",
        "          # that the start of the span is in the question. We throw out all\n",
        "          # invalid predictions.\n",
        "          if start_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if end_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if start_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if end_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if not feature.token_is_max_context.get(start_index, False):\n",
        "            continue\n",
        "          if end_index < start_index:\n",
        "            continue\n",
        "          length = end_index - start_index + 1\n",
        "          if length > max_answer_length:\n",
        "            continue\n",
        "          prelim_predictions.append(\n",
        "              _PrelimPrediction(\n",
        "                  feature_index=feature_index,\n",
        "                  start_index=start_index,\n",
        "                  end_index=end_index,\n",
        "                  start_logit=result.start_logits[start_index],\n",
        "                  end_logit=result.end_logits[end_index]))\n",
        "\n",
        "    if FLAGS.version_2_with_negative:\n",
        "      prelim_predictions.append(\n",
        "          _PrelimPrediction(\n",
        "              feature_index=min_null_feature_index,\n",
        "              start_index=0,\n",
        "              end_index=0,\n",
        "              start_logit=null_start_logit,\n",
        "              end_logit=null_end_logit))\n",
        "    prelim_predictions = sorted(\n",
        "        prelim_predictions,\n",
        "        key=lambda x: (x.start_logit + x.end_logit),\n",
        "        reverse=True)\n",
        "\n",
        "    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "    seen_predictions = {}\n",
        "    nbest = []\n",
        "    for pred in prelim_predictions:\n",
        "      if len(nbest) >= n_best_size:\n",
        "        break\n",
        "      feature = features[pred.feature_index]\n",
        "      if pred.start_index > 0:  # this is a non-null prediction\n",
        "        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
        "        orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
        "        orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
        "        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
        "        tok_text = \" \".join(tok_tokens)\n",
        "\n",
        "        # De-tokenize WordPieces that have been split off.\n",
        "        tok_text = tok_text.replace(\" ##\", \"\")\n",
        "        tok_text = tok_text.replace(\"##\", \"\")\n",
        "\n",
        "        # Clean whitespace\n",
        "        tok_text = tok_text.strip()\n",
        "        tok_text = \" \".join(tok_text.split())\n",
        "        orig_text = \" \".join(orig_tokens)\n",
        "\n",
        "        final_text = get_final_text(tok_text, orig_text, do_lower_case)\n",
        "        if final_text in seen_predictions:\n",
        "          continue\n",
        "\n",
        "        seen_predictions[final_text] = True\n",
        "      else:\n",
        "        final_text = \"\"\n",
        "        seen_predictions[final_text] = True\n",
        "\n",
        "      nbest.append(\n",
        "          _NbestPrediction(\n",
        "              text=final_text,\n",
        "              start_logit=pred.start_logit,\n",
        "              end_logit=pred.end_logit))\n",
        "\n",
        "    # if we didn't inlude the empty option in the n-best, inlcude it\n",
        "    if FLAGS.version_2_with_negative:\n",
        "      if \"\" not in seen_predictions:\n",
        "        nbest.append(\n",
        "            _NbestPrediction(\n",
        "                text=\"\", start_logit=null_start_logit,\n",
        "                end_logit=null_end_logit))\n",
        "    # In very rare edge cases we could have no valid predictions. So we\n",
        "    # just create a nonce prediction in this case to avoid failure.\n",
        "    if not nbest:\n",
        "      nbest.append(\n",
        "          _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
        "\n",
        "    assert len(nbest) >= 1\n",
        "\n",
        "    total_scores = []\n",
        "    best_non_null_entry = None\n",
        "    for entry in nbest:\n",
        "      total_scores.append(entry.start_logit + entry.end_logit)\n",
        "      if not best_non_null_entry:\n",
        "        if entry.text:\n",
        "          best_non_null_entry = entry\n",
        "\n",
        "    probs = _compute_softmax(total_scores)\n",
        "\n",
        "    nbest_json = []\n",
        "    for (i, entry) in enumerate(nbest):\n",
        "      output = collections.OrderedDict()\n",
        "      output[\"text\"] = entry.text\n",
        "      output[\"probability\"] = probs[i]\n",
        "      output[\"start_logit\"] = entry.start_logit\n",
        "      output[\"end_logit\"] = entry.end_logit\n",
        "      nbest_json.append(output)\n",
        "\n",
        "    assert len(nbest_json) >= 1\n",
        "\n",
        "    if not FLAGS.version_2_with_negative:\n",
        "      all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
        "    else:\n",
        "      # predict \"\" iff the null score - the score of best non-null > threshold\n",
        "      score_diff = score_null - best_non_null_entry.start_logit - (\n",
        "          best_non_null_entry.end_logit)\n",
        "      scores_diff_json[example.qas_id] = score_diff\n",
        "      if score_diff > FLAGS.null_score_diff_threshold:\n",
        "        all_predictions[example.qas_id] = \"\"\n",
        "      else:\n",
        "        all_predictions[example.qas_id] = best_non_null_entry.text\n",
        "\n",
        "    all_nbest_json[example.qas_id] = nbest_json\n",
        "\n",
        "  with tf.gfile.GFile(output_prediction_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n",
        "\n",
        "  with tf.gfile.GFile(output_nbest_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n",
        "\n",
        "  if FLAGS.version_2_with_negative:\n",
        "    with tf.gfile.GFile(output_null_log_odds_file, \"w\") as writer:\n",
        "      writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")\n",
        "\n",
        "\n",
        "def get_final_text(pred_text, orig_text, do_lower_case):\n",
        "  \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
        "\n",
        "  # When we created the data, we kept track of the alignment between original\n",
        "  # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n",
        "  # now `orig_text` contains the span of our original text corresponding to the\n",
        "  # span that we predicted.\n",
        "  #\n",
        "  # However, `orig_text` may contain extra characters that we don't want in\n",
        "  # our prediction.\n",
        "  #\n",
        "  # For example, let's say:\n",
        "  #   pred_text = steve smith\n",
        "  #   orig_text = Steve Smith's\n",
        "  #\n",
        "  # We don't want to return `orig_text` because it contains the extra \"'s\".\n",
        "  #\n",
        "  # We don't want to return `pred_text` because it's already been normalized\n",
        "  # (the SQuAD eval script also does punctuation stripping/lower casing but\n",
        "  # our tokenizer does additional normalization like stripping accent\n",
        "  # characters).\n",
        "  #\n",
        "  # What we really want to return is \"Steve Smith\".\n",
        "  #\n",
        "  # Therefore, we have to apply a semi-complicated alignment heruistic between\n",
        "  # `pred_text` and `orig_text` to get a character-to-charcter alignment. This\n",
        "  # can fail in certain cases in which case we just return `orig_text`.\n",
        "\n",
        "  def _strip_spaces(text):\n",
        "    ns_chars = []\n",
        "    ns_to_s_map = collections.OrderedDict()\n",
        "    for (i, c) in enumerate(text):\n",
        "      if c == \" \":\n",
        "        continue\n",
        "      ns_to_s_map[len(ns_chars)] = i\n",
        "      ns_chars.append(c)\n",
        "    ns_text = \"\".join(ns_chars)\n",
        "    return (ns_text, ns_to_s_map)\n",
        "\n",
        "  # We first tokenize `orig_text`, strip whitespace from the result\n",
        "  # and `pred_text`, and check if they are the same length. If they are\n",
        "  # NOT the same length, the heuristic has failed. If they are the same\n",
        "  # length, we assume the characters are one-to-one aligned.\n",
        "  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)\n",
        "\n",
        "  tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
        "\n",
        "  start_position = tok_text.find(pred_text)\n",
        "  if start_position == -1:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\n",
        "          \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
        "    return orig_text\n",
        "  end_position = start_position + len(pred_text) - 1\n",
        "\n",
        "  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
        "  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
        "\n",
        "  if len(orig_ns_text) != len(tok_ns_text):\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
        "                      orig_ns_text, tok_ns_text)\n",
        "    return orig_text\n",
        "\n",
        "  # We then project the characters in `pred_text` back to `orig_text` using\n",
        "  # the character-to-character alignment.\n",
        "  tok_s_to_ns_map = {}\n",
        "  for (i, tok_index) in six.iteritems(tok_ns_to_s_map):\n",
        "    tok_s_to_ns_map[tok_index] = i\n",
        "\n",
        "  orig_start_position = None\n",
        "  if start_position in tok_s_to_ns_map:\n",
        "    ns_start_position = tok_s_to_ns_map[start_position]\n",
        "    if ns_start_position in orig_ns_to_s_map:\n",
        "      orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
        "\n",
        "  if orig_start_position is None:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Couldn't map start position\")\n",
        "    return orig_text\n",
        "\n",
        "  orig_end_position = None\n",
        "  if end_position in tok_s_to_ns_map:\n",
        "    ns_end_position = tok_s_to_ns_map[end_position]\n",
        "    if ns_end_position in orig_ns_to_s_map:\n",
        "      orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
        "\n",
        "  if orig_end_position is None:\n",
        "    if FLAGS.verbose_logging:\n",
        "      tf.logging.info(\"Couldn't map end position\")\n",
        "    return orig_text\n",
        "\n",
        "  output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
        "  return output_text\n",
        "\n",
        "\n",
        "def _get_best_indexes(logits, n_best_size):\n",
        "  \"\"\"Get the n-best logits from a list.\"\"\"\n",
        "  index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  best_indexes = []\n",
        "  for i in range(len(index_and_score)):\n",
        "    if i >= n_best_size:\n",
        "      break\n",
        "    best_indexes.append(index_and_score[i][0])\n",
        "  return best_indexes\n",
        "\n",
        "\n",
        "def _compute_softmax(scores):\n",
        "  \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
        "  if not scores:\n",
        "    return []\n",
        "\n",
        "  max_score = None\n",
        "  for score in scores:\n",
        "    if max_score is None or score > max_score:\n",
        "      max_score = score\n",
        "\n",
        "  exp_scores = []\n",
        "  total_sum = 0.0\n",
        "  for score in scores:\n",
        "    x = math.exp(score - max_score)\n",
        "    exp_scores.append(x)\n",
        "    total_sum += x\n",
        "\n",
        "  probs = []\n",
        "  for score in exp_scores:\n",
        "    probs.append(score / total_sum)\n",
        "  return probs\n",
        "\n",
        "\n",
        "class FeatureWriter(object):\n",
        "  \"\"\"Writes InputFeature to TF example file.\"\"\"\n",
        "\n",
        "  def __init__(self, filename, is_training):\n",
        "    self.filename = filename\n",
        "    self.is_training = is_training\n",
        "    self.num_features = 0\n",
        "    self._writer = tf.python_io.TFRecordWriter(filename)\n",
        "\n",
        "  def process_feature(self, feature):\n",
        "    \"\"\"Write a InputFeature to the TFRecordWriter as a tf.train.Example.\"\"\"\n",
        "    self.num_features += 1\n",
        "\n",
        "    def create_int_feature(values):\n",
        "      feature = tf.train.Feature(\n",
        "          int64_list=tf.train.Int64List(value=list(values)))\n",
        "      return feature\n",
        "\n",
        "    features = collections.OrderedDict()\n",
        "    features[\"unique_ids\"] = create_int_feature([feature.unique_id])\n",
        "    features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "    features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "    features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "\n",
        "    if self.is_training:\n",
        "      features[\"start_positions\"] = create_int_feature([feature.start_position])\n",
        "      features[\"end_positions\"] = create_int_feature([feature.end_position])\n",
        "      impossible = 0\n",
        "      if feature.is_impossible:\n",
        "        impossible = 1\n",
        "      features[\"is_impossible\"] = create_int_feature([impossible])\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "    self._writer.write(tf_example.SerializeToString())\n",
        "\n",
        "  def close(self):\n",
        "    self._writer.close()\n",
        "\n",
        "\n",
        "def validate_flags_or_throw(bert_config):\n",
        "  \"\"\"Validate the input FLAGS or throw an exception.\"\"\"\n",
        "  if not FLAGS.do_train and not FLAGS.do_predict:\n",
        "    raise ValueError(\"At least one of `do_train` or `do_predict` must be True.\")\n",
        "\n",
        "  if FLAGS.do_train:\n",
        "    if not FLAGS.train_file:\n",
        "      raise ValueError(\n",
        "          \"If `do_train` is True, then `train_file` must be specified.\")\n",
        "  if FLAGS.do_predict:\n",
        "    if not FLAGS.predict_file:\n",
        "      raise ValueError(\n",
        "          \"If `do_predict` is True, then `predict_file` must be specified.\")\n",
        "\n",
        "  if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
        "    raise ValueError(\n",
        "        \"Cannot use sequence length %d because the BERT model \"\n",
        "        \"was only trained up to sequence length %d\" %\n",
        "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
        "\n",
        "  if FLAGS.max_seq_length <= FLAGS.max_query_length + 3:\n",
        "    raise ValueError(\n",
        "        \"The max_seq_length (%d) must be greater than max_query_length \"\n",
        "        \"(%d) + 3\" % (FLAGS.max_seq_length, FLAGS.max_query_length))\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
        "\n",
        "  validate_flags_or_throw(bert_config)\n",
        "\n",
        "  tf.gfile.MakeDirs(FLAGS.output_dir)\n",
        "\n",
        "  tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
        "\n",
        "  tpu_cluster_resolver = None\n",
        "  if FLAGS.use_tpu and FLAGS.tpu_name:\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
        "\n",
        "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      master=FLAGS.master,\n",
        "      model_dir=FLAGS.output_dir,\n",
        "      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "          num_shards=FLAGS.num_tpu_cores,\n",
        "          per_host_input_for_training=is_per_host))\n",
        "\n",
        "  train_examples = None\n",
        "  num_train_steps = None\n",
        "  num_warmup_steps = None\n",
        "  if FLAGS.do_train:\n",
        "    train_examples = read_squad_examples(\n",
        "        input_file=FLAGS.train_file, is_training=True)\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
        "\n",
        "    # Pre-shuffle the input to avoid having to make a very large shuffle\n",
        "    # buffer in in the `input_fn`.\n",
        "    rng = random.Random(12345)\n",
        "    rng.shuffle(train_examples)\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=FLAGS.init_checkpoint,\n",
        "      learning_rate=FLAGS.learning_rate,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      use_one_hot_embeddings=FLAGS.use_tpu)\n",
        "\n",
        "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "  # or GPU.\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=FLAGS.train_batch_size,\n",
        "      predict_batch_size=FLAGS.predict_batch_size)\n",
        "\n",
        "  if FLAGS.do_train:\n",
        "    # We write to a temporary file to avoid storing very large constant tensors\n",
        "    # in memory.\n",
        "    train_writer = FeatureWriter(\n",
        "        filename=os.path.join(FLAGS.output_dir, \"train.tf_record\"),\n",
        "        is_training=True)\n",
        "    convert_examples_to_features(\n",
        "        examples=train_examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        doc_stride=FLAGS.doc_stride,\n",
        "        max_query_length=FLAGS.max_query_length,\n",
        "        is_training=True,\n",
        "        output_fn=train_writer.process_feature)\n",
        "    train_writer.close()\n",
        "\n",
        "    tf.logging.info(\"***** Running training *****\")\n",
        "    tf.logging.info(\"  Num orig examples = %d\", len(train_examples))\n",
        "    tf.logging.info(\"  Num split examples = %d\", train_writer.num_features)\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
        "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "    del train_examples\n",
        "\n",
        "    train_input_fn = input_fn_builder(\n",
        "        input_file=train_writer.filename,\n",
        "        seq_length=FLAGS.max_seq_length,\n",
        "        is_training=True,\n",
        "        drop_remainder=True)\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "  if FLAGS.do_predict:\n",
        "    eval_examples = read_squad_examples(\n",
        "        input_file=FLAGS.predict_file, is_training=False)\n",
        "\n",
        "    eval_writer = FeatureWriter(\n",
        "        filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
        "        is_training=False)\n",
        "    eval_features = []\n",
        "\n",
        "    def append_feature(feature):\n",
        "      eval_features.append(feature)\n",
        "      eval_writer.process_feature(feature)\n",
        "\n",
        "    convert_examples_to_features(\n",
        "        examples=eval_examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        doc_stride=FLAGS.doc_stride,\n",
        "        max_query_length=FLAGS.max_query_length,\n",
        "        is_training=False,\n",
        "        output_fn=append_feature)\n",
        "    eval_writer.close()\n",
        "\n",
        "    tf.logging.info(\"***** Running predictions *****\")\n",
        "    tf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\n",
        "    tf.logging.info(\"  Num split examples = %d\", len(eval_features))\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    predict_input_fn = input_fn_builder(\n",
        "        input_file=eval_writer.filename,\n",
        "        seq_length=FLAGS.max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    # If running eval on the TPU, you will need to specify the number of\n",
        "    # steps.\n",
        "    all_results = []\n",
        "    for result in estimator.predict(\n",
        "        predict_input_fn, yield_single_examples=True):\n",
        "      if len(all_results) % 1000 == 0:\n",
        "        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n",
        "      unique_id = int(result[\"unique_ids\"])\n",
        "      start_logits = [float(x) for x in result[\"start_logits\"].flat]\n",
        "      end_logits = [float(x) for x in result[\"end_logits\"].flat]\n",
        "      all_results.append(\n",
        "          RawResult(\n",
        "              unique_id=unique_id,\n",
        "              start_logits=start_logits,\n",
        "              end_logits=end_logits))\n",
        "\n",
        "    output_prediction_file = os.path.join(FLAGS.output_dir, \"predictions.json\")\n",
        "    output_nbest_file = os.path.join(FLAGS.output_dir, \"nbest_predictions.json\")\n",
        "    output_null_log_odds_file = os.path.join(FLAGS.output_dir, \"null_odds.json\")\n",
        "\n",
        "    write_predictions(eval_examples, eval_features, all_results,\n",
        "                      FLAGS.n_best_size, FLAGS.max_answer_length,\n",
        "                      FLAGS.do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  flags.mark_flag_as_required(\"vocab_file\")\n",
        "  flags.mark_flag_as_required(\"bert_config_file\")\n",
        "  flags.mark_flag_as_required(\"output_dir\")\n",
        "  tf.app.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7bec4f06a8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/Downloads/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7bec07d358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --vocab_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n",
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --bert_config_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n",
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:358: UserWarning: Flag --output_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] in what country is normandy located ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n",
            "INFO:tensorflow:input_ids: 101 1999 2054 2406 2003 13298 2284 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when were the norman ##s in normandy ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n",
            "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2020 1996 5879 2015 1999 13298 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] from which countries did the norse originate ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n",
            "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n",
            "INFO:tensorflow:input_ids: 101 2013 2029 3032 2106 1996 15342 21754 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000003\n",
            "INFO:tensorflow:example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who was the norse leader ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:1 11:2 12:2 13:2 14:3 15:3 16:3 17:3 18:3 19:4 20:4 21:5 22:5 23:5 24:6 25:6 26:7 27:7 28:7 29:8 30:9 31:10 32:11 33:12 34:13 35:14 36:15 37:16 38:17 39:18 40:19 41:20 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:26 50:27 51:28 52:29 53:30 54:31 55:32 56:32 57:32 58:32 59:33 60:34 61:35 62:35 63:35 64:35 65:35 66:36 67:37 68:38 69:39 70:40 71:40 72:41 73:42 74:43 75:44 76:44 77:45 78:46 79:47 80:48 81:48 82:48 83:49 84:50 85:51 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:59 96:59 97:59 98:60 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:71 111:71 112:71 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:80 124:80 125:80 126:80 127:81 128:82 129:83 130:84 131:84 132:84 133:85 134:86 135:87 136:88 137:89 138:90 139:91 140:92 141:93 142:93 143:94 144:95 145:96 146:97 147:98 148:99 149:100 150:101 151:102 152:103 153:103 154:104 155:105 156:106 157:107 158:108 159:109 160:110 161:111 162:112 163:112\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2001 1996 15342 3003 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000004\n",
            "INFO:tensorflow:example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what century did the norman ##s first gain their separate identity ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:5 28:5 29:5 30:6 31:6 32:7 33:7 34:7 35:8 36:9 37:10 38:11 39:12 40:13 41:14 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:22 51:23 52:24 53:25 54:26 55:26 56:27 57:28 58:29 59:30 60:31 61:32 62:32 63:32 64:32 65:33 66:34 67:35 68:35 69:35 70:35 71:35 72:36 73:37 74:38 75:39 76:40 77:40 78:41 79:42 80:43 81:44 82:44 83:45 84:46 85:47 86:48 87:48 88:48 89:49 90:50 91:51 92:52 93:52 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:59 102:59 103:59 104:60 105:61 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:69 114:70 115:71 116:71 117:71 118:71 119:72 120:72 121:73 122:74 123:75 124:76 125:77 126:78 127:79 128:80 129:80 130:80 131:80 132:80 133:81 134:82 135:83 136:84 137:84 138:84 139:85 140:86 141:87 142:88 143:89 144:90 145:91 146:92 147:93 148:93 149:94 150:95 151:96 152:97 153:98 154:99 155:100 156:101 157:102 158:103 159:103 160:104 161:105 162:106 163:107 164:108 165:109 166:110 167:111 168:112 169:112\n",
            "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2301 2106 1996 5879 2015 2034 5114 2037 3584 4767 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000005\n",
            "INFO:tensorflow:example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who gave their name to normandy in the 1000 ' s and 1100 ' s [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 17:0 18:1 19:1 20:2 21:2 22:2 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:5 31:5 32:5 33:6 34:6 35:7 36:7 37:7 38:8 39:9 40:10 41:11 42:12 43:13 44:14 45:15 46:16 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:23 55:24 56:25 57:26 58:26 59:27 60:28 61:29 62:30 63:31 64:32 65:32 66:32 67:32 68:33 69:34 70:35 71:35 72:35 73:35 74:35 75:36 76:37 77:38 78:39 79:40 80:40 81:41 82:42 83:43 84:44 85:44 86:45 87:46 88:47 89:48 90:48 91:48 92:49 93:50 94:51 95:52 96:52 97:52 98:53 99:54 100:55 101:56 102:57 103:58 104:59 105:59 106:59 107:60 108:61 109:62 110:63 111:64 112:65 113:66 114:67 115:68 116:69 117:70 118:71 119:71 120:71 121:71 122:72 123:72 124:73 125:74 126:75 127:76 128:77 129:78 130:79 131:80 132:80 133:80 134:80 135:80 136:81 137:82 138:83 139:84 140:84 141:84 142:85 143:86 144:87 145:88 146:89 147:90 148:91 149:92 150:93 151:93 152:94 153:95 154:96 155:97 156:98 157:99 158:100 159:101 160:102 161:103 162:103 163:104 164:105 165:106 166:107 167:108 168:109 169:110 170:111 171:112 172:112\n",
            "INFO:tensorflow:token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2435 2037 2171 2000 13298 1999 1996 6694 1005 1055 1998 22096 1005 1055 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000006\n",
            "INFO:tensorflow:example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is france a region of ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 2605 1037 2555 1997 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000007\n",
            "INFO:tensorflow:example_index: 7\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who did king charles iii swear fe ##al ##ty to ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:2 19:3 20:3 21:3 22:3 23:3 24:4 25:4 26:5 27:5 28:5 29:6 30:6 31:7 32:7 33:7 34:8 35:9 36:10 37:11 38:12 39:13 40:14 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:22 50:23 51:24 52:25 53:26 54:26 55:27 56:28 57:29 58:30 59:31 60:32 61:32 62:32 63:32 64:33 65:34 66:35 67:35 68:35 69:35 70:35 71:36 72:37 73:38 74:39 75:40 76:40 77:41 78:42 79:43 80:44 81:44 82:45 83:46 84:47 85:48 86:48 87:48 88:49 89:50 90:51 91:52 92:52 93:52 94:53 95:54 96:55 97:56 98:57 99:58 100:59 101:59 102:59 103:60 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:69 113:70 114:71 115:71 116:71 117:71 118:72 119:72 120:73 121:74 122:75 123:76 124:77 125:78 126:79 127:80 128:80 129:80 130:80 131:80 132:81 133:82 134:83 135:84 136:84 137:84 138:85 139:86 140:87 141:88 142:89 143:90 144:91 145:92 146:93 147:93 148:94 149:95 150:96 151:97 152:98 153:99 154:100 155:101 156:102 157:103 158:103 159:104 160:105 161:106 162:107 163:108 164:109 165:110 166:111 167:112 168:112\n",
            "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2106 2332 2798 3523 8415 10768 2389 3723 2000 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000008\n",
            "INFO:tensorflow:example_index: 8\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when did the frankish identity emerge ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 1996 26165 4767 12636 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000009\n",
            "INFO:tensorflow:example_index: 9\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who was the duke in the battle of hastings ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:32 50:33 51:34 52:34 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:42 63:42 64:42 65:43 66:44 67:45 68:46 69:46 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:59 86:60 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:71 102:72 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:80 111:80 112:81 113:82 114:83 115:84 116:84 117:85 118:86 119:87 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:94 128:95 129:96 130:97 131:98 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:104 140:105 141:106 142:106 143:107 144:108 145:109 146:110 147:111 148:112 149:112 150:113 151:114 152:115 153:116 154:117 155:118 156:119 157:120 158:121 159:121 160:122 161:123 162:124 163:125 164:126 165:127 166:128 167:129 168:129 169:130 170:131 171:131 172:132 173:133 174:134 175:135 176:136 177:137 178:138 179:139 180:140 181:141 182:141 183:142 184:143 185:144 186:145 187:146 188:146 189:147 190:148 191:148 192:148 193:149 194:150 195:151 196:152 197:153 198:154 199:155 200:156 201:156 202:157 203:158 204:159 205:159 206:160 207:161 208:162 209:163 210:164 211:165 212:166 213:167 214:168 215:169 216:170 217:171 218:172 219:173 220:173 221:173 222:174 223:175 224:176 225:177 226:178 227:179 228:180 229:181 230:182 231:183 232:184 233:185 234:186 235:187 236:188 237:189 238:190 239:191 240:192 241:192 242:193 243:194 244:195 245:196 246:196 247:196 248:197 249:198 250:199 251:200 252:201 253:202 254:203 255:204 256:205 257:205 258:206 259:207 260:208 261:209 262:210 263:211 264:212 265:212 266:213 267:214 268:214 269:215 270:216 271:217 272:218 273:219 274:220 275:221 276:222 277:223 278:224 279:225 280:225\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2001 1996 3804 1999 1996 2645 1997 12296 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000010\n",
            "INFO:tensorflow:example_index: 10\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who ruled the duchy of normandy [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n",
            "INFO:tensorflow:input_ids: 101 2040 5451 1996 11068 1997 13298 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000011\n",
            "INFO:tensorflow:example_index: 11\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what religion were the norman ##s [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n",
            "INFO:tensorflow:input_ids: 101 2054 4676 2020 1996 5879 2015 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000012\n",
            "INFO:tensorflow:example_index: 12\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what type of major impact did the norman dynasty have on modern europe ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 16:0 17:1 18:2 19:3 20:4 21:5 22:6 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:32 53:32 54:33 55:34 56:34 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:42 66:42 67:42 68:42 69:43 70:44 71:45 72:46 73:46 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:53 83:54 84:55 85:56 86:57 87:58 88:59 89:59 90:60 91:60 92:61 93:62 94:63 95:63 96:64 97:65 98:66 99:67 100:67 101:68 102:69 103:70 104:71 105:71 106:72 107:73 108:74 109:75 110:76 111:77 112:78 113:79 114:80 115:80 116:81 117:82 118:83 119:84 120:84 121:85 122:86 123:87 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:98 137:99 138:100 139:101 140:102 141:103 142:104 143:104 144:105 145:106 146:106 147:107 148:108 149:109 150:110 151:111 152:112 153:112 154:113 155:114 156:115 157:116 158:117 159:118 160:119 161:120 162:121 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:128 171:129 172:129 173:130 174:131 175:131 176:132 177:133 178:134 179:135 180:136 181:137 182:138 183:139 184:140 185:141 186:141 187:142 188:143 189:144 190:145 191:146 192:146 193:147 194:148 195:148 196:148 197:149 198:150 199:151 200:152 201:153 202:154 203:155 204:156 205:156 206:157 207:158 208:159 209:159 210:160 211:161 212:162 213:163 214:164 215:165 216:166 217:167 218:168 219:169 220:170 221:171 222:172 223:173 224:173 225:173 226:174 227:175 228:176 229:177 230:178 231:179 232:180 233:181 234:182 235:183 236:184 237:185 238:186 239:187 240:188 241:189 242:190 243:191 244:192 245:192 246:193 247:194 248:195 249:196 250:196 251:196 252:197 253:198 254:199 255:200 256:201 257:202 258:203 259:204 260:205 261:205 262:206 263:207 264:208 265:209 266:210 267:211 268:212 269:212 270:213 271:214 272:214 273:215 274:216 275:217 276:218 277:219 278:220 279:221 280:222 281:223 282:224 283:225 284:225\n",
            "INFO:tensorflow:token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2828 1997 2350 4254 2106 1996 5879 5321 2031 2006 2715 2885 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000013\n",
            "INFO:tensorflow:example_index: 13\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who was famed for their christian spirit ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:32 47:32 48:33 49:34 50:34 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:42 61:42 62:42 63:43 64:44 65:45 66:46 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:59 84:60 85:60 86:61 87:62 88:63 89:63 90:64 91:65 92:66 93:67 94:67 95:68 96:69 97:70 98:71 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:80 109:80 110:81 111:82 112:83 113:84 114:84 115:85 116:86 117:87 118:87 119:88 120:89 121:90 122:91 123:92 124:93 125:94 126:95 127:96 128:97 129:98 130:98 131:99 132:100 133:101 134:102 135:103 136:104 137:104 138:105 139:106 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:112 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:121 158:122 159:123 160:124 161:125 162:126 163:127 164:128 165:129 166:129 167:130 168:131 169:131 170:132 171:133 172:134 173:135 174:136 175:137 176:138 177:139 178:140 179:141 180:141 181:142 182:143 183:144 184:145 185:146 186:146 187:147 188:148 189:148 190:148 191:149 192:150 193:151 194:152 195:153 196:154 197:155 198:156 199:156 200:157 201:158 202:159 203:159 204:160 205:161 206:162 207:163 208:164 209:165 210:166 211:167 212:168 213:169 214:170 215:171 216:172 217:173 218:173 219:173 220:174 221:175 222:176 223:177 224:178 225:179 226:180 227:181 228:182 229:183 230:184 231:185 232:186 233:187 234:188 235:189 236:190 237:191 238:192 239:192 240:193 241:194 242:195 243:196 244:196 245:196 246:197 247:198 248:199 249:200 250:201 251:202 252:203 253:204 254:205 255:205 256:206 257:207 258:208 259:209 260:210 261:211 262:212 263:212 264:213 265:214 266:214 267:215 268:216 269:217 270:218 271:219 272:220 273:221 274:222 275:223 276:224 277:225 278:225\n",
            "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2001 15607 2005 2037 3017 4382 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000014\n",
            "INFO:tensorflow:example_index: 14\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who ass ##imi ##lt ##ed the roman language ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n",
            "INFO:tensorflow:input_ids: 101 2040 4632 27605 7096 2098 1996 3142 2653 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000015\n",
            "INFO:tensorflow:example_index: 15\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who ruled the country of normandy ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:32 46:32 47:33 48:34 49:34 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:42 60:42 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:53 76:54 77:55 78:56 79:57 80:58 81:59 82:59 83:60 84:60 85:61 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:71 99:72 100:73 101:74 102:75 103:76 104:77 105:78 106:79 107:80 108:80 109:81 110:82 111:83 112:84 113:84 114:85 115:86 116:87 117:87 118:88 119:89 120:90 121:91 122:92 123:93 124:94 125:95 126:96 127:97 128:98 129:98 130:99 131:100 132:101 133:102 134:103 135:104 136:104 137:105 138:106 139:106 140:107 141:108 142:109 143:110 144:111 145:112 146:112 147:113 148:114 149:115 150:116 151:117 152:118 153:119 154:120 155:121 156:121 157:122 158:123 159:124 160:125 161:126 162:127 163:128 164:129 165:129 166:130 167:131 168:131 169:132 170:133 171:134 172:135 173:136 174:137 175:138 176:139 177:140 178:141 179:141 180:142 181:143 182:144 183:145 184:146 185:146 186:147 187:148 188:148 189:148 190:149 191:150 192:151 193:152 194:153 195:154 196:155 197:156 198:156 199:157 200:158 201:159 202:159 203:160 204:161 205:162 206:163 207:164 208:165 209:166 210:167 211:168 212:169 213:170 214:171 215:172 216:173 217:173 218:173 219:174 220:175 221:176 222:177 223:178 224:179 225:180 226:181 227:182 228:183 229:184 230:185 231:186 232:187 233:188 234:189 235:190 236:191 237:192 238:192 239:193 240:194 241:195 242:196 243:196 244:196 245:197 246:198 247:199 248:200 249:201 250:202 251:203 252:204 253:205 254:205 255:206 256:207 257:208 258:209 259:210 260:211 261:212 262:212 263:213 264:214 265:214 266:215 267:216 268:217 269:218 270:219 271:220 272:221 273:222 274:223 275:224 276:225 277:225\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True\n",
            "INFO:tensorflow:input_ids: 101 2040 5451 1996 2406 1997 13298 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000016\n",
            "INFO:tensorflow:example_index: 16\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what principality did william the conquer ##er found ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n",
            "INFO:tensorflow:input_ids: 101 2054 18018 2106 2520 1996 16152 2121 2179 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000017\n",
            "INFO:tensorflow:example_index: 17\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the original meaning of the word norman ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ##ð ##ma ##ð ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:3 17:3 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:9 26:9 27:9 28:9 29:9 30:10 31:11 32:12 33:12 34:12 35:13 36:14 37:15 38:15 39:15 40:16 41:17 42:18 43:19 44:20 45:21 46:22 47:23 48:23 49:24 50:24 51:24 52:25 53:25 54:25 55:25 56:26 57:27 58:28 59:29 60:30 61:31 62:31 63:31 64:31 65:31 66:31 67:32 68:32 69:33 70:34 71:35 72:35 73:35 74:35 75:36 76:36 77:36 78:37 79:38 80:38 81:38 82:39 83:39 84:40 85:41 86:42 87:42 88:43 89:44 90:44 91:45 92:46 93:47 94:47 95:47 96:47 97:48 98:48 99:48\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 2434 3574 1997 1996 2773 5879 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000018\n",
            "INFO:tensorflow:example_index: 18\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when was the latin version of the word norman first recorded ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ##ð ##ma ##ð ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:2 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:9 28:9 29:9 30:9 31:9 32:10 33:11 34:12 35:12 36:12 37:13 38:14 39:15 40:15 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:23 50:23 51:24 52:24 53:24 54:25 55:25 56:25 57:25 58:26 59:27 60:28 61:29 62:30 63:31 64:31 65:31 66:31 67:31 68:31 69:32 70:32 71:33 72:34 73:35 74:35 75:35 76:35 77:36 78:36 79:36 80:37 81:38 82:38 83:38 84:39 85:39 86:40 87:41 88:42 89:42 90:43 91:44 92:44 93:45 94:46 95:47 96:47 97:47 98:47 99:48 100:48 101:48\n",
            "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 3763 2544 1997 1996 2773 5879 2034 2680 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000019\n",
            "INFO:tensorflow:example_index: 19\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what name comes from the english words norman ##s / norman ##z ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ##ð ##ma ##ð ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:3 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:9 29:9 30:9 31:9 32:9 33:10 34:11 35:12 36:12 37:12 38:13 39:14 40:15 41:15 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:23 51:23 52:24 53:24 54:24 55:25 56:25 57:25 58:25 59:26 60:27 61:28 62:29 63:30 64:31 65:31 66:31 67:31 68:31 69:31 70:32 71:32 72:33 73:34 74:35 75:35 76:35 77:35 78:36 79:36 80:36 81:37 82:38 83:38 84:38 85:39 86:39 87:40 88:41 89:42 90:42 91:43 92:44 93:44 94:45 95:46 96:47 97:47 98:47 99:47 100:48 101:48 102:48\n",
            "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2171 3310 2013 1996 2394 2616 5879 2015 1013 5879 2480 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 11873\n",
            "INFO:tensorflow:  Num split examples = 12232\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /Downloads/output, running initialization to predict.\n",
            "WARNING:tensorflow:From <ipython-input-6-c0b9d81f07b9>:574: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Processing example: 0\n",
            "INFO:tensorflow:Processing example: 1000\n",
            "INFO:tensorflow:Processing example: 2000\n",
            "INFO:tensorflow:Processing example: 3000\n",
            "INFO:tensorflow:Processing example: 4000\n",
            "INFO:tensorflow:Processing example: 5000\n",
            "INFO:tensorflow:Processing example: 6000\n",
            "INFO:tensorflow:Processing example: 7000\n",
            "INFO:tensorflow:Processing example: 8000\n",
            "INFO:tensorflow:Processing example: 9000\n",
            "INFO:tensorflow:Processing example: 10000\n",
            "INFO:tensorflow:Processing example: 11000\n",
            "INFO:tensorflow:Processing example: 12000\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:Writing predictions to: /Downloads/output/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: /Downloads/output/nbest_predictions.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OJ5sp-Ny9e2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Just run this line as it is, as you don't need to train the network again \n",
        "### Make sure that you are keeping the check points in the output directory"
      ]
    },
    {
      "metadata": {
        "id": "dvNxcImTSHR6",
        "colab_type": "code",
        "outputId": "d66e1c24-d45d-4293-a282-3e3c85248975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10926
        }
      },
      "cell_type": "code",
      "source": [
        "!python run_squad.py \\\n",
        "  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n",
        "  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
        "  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n",
        "  --do_train=False \\\n",
        "  --train_file=train-v1.2.json \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file='handmade_qa_sbu.json' \\\n",
        "  --train_batch_size=8 \\\n",
        "  --learning_rate=3e-5 \\\n",
        "  --num_train_epochs=2.0 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --output_dir=$OUTPUT_DIR "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fa796b29f28>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'output_small', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa78c2a6ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] which insurance is available for domestic stu ##ents ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:5 18:5 19:6 20:6 21:7 22:8 23:9 24:10 25:11 26:11 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:20 37:20 38:21 39:22 40:22 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:36 58:36 59:37 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:55 78:56 79:56 80:56 81:57 82:58 83:59 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:75 102:76 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:85 112:86 113:87 114:88 115:89 116:90 117:91 118:92 119:92 120:92 121:93 122:94 123:94 124:94 125:95 126:96 127:97 128:98 129:98 130:98 131:99 132:100 133:101 134:102 135:103 136:104 137:105 138:106 139:107 140:108 141:109 142:109 143:109 144:110 145:111 146:112 147:113 148:113 149:113 150:114 151:115 152:115 153:115 154:116 155:116 156:116 157:116 158:117 159:117 160:117 161:118 162:119 163:120 164:121 165:121 166:122 167:122 168:122 169:123 170:123 171:123 172:123 173:124 174:124 175:125 176:126 177:127 178:127 179:127 180:128 181:129 182:130 183:131 184:132 185:133 186:133 187:133 188:133 189:134 190:135 191:136 192:136 193:136 194:136 195:136 196:136 197:137 198:137 199:138 200:139 201:139 202:139 203:139 204:140 205:140 206:141 207:142 208:142 209:143 210:144 211:145 212:145 213:145 214:146 215:146 216:146 217:146 218:147 219:148 220:149 221:150 222:151 223:151 224:151 225:152 226:152 227:153 228:154 229:155 230:156 231:157 232:158 233:159 234:160 235:161 236:162 237:162 238:163 239:163 240:163 241:164 242:165 243:165 244:166 245:166 246:167 247:168 248:169 249:169 250:170 251:171 252:171 253:172 254:172 255:173 256:174 257:175 258:175 259:175 260:175 261:176 262:177 263:177 264:178 265:179 266:179 267:180 268:181 269:182 270:183 271:184 272:185 273:186 274:187 275:188 276:189 277:190 278:191 279:192 280:193 281:194 282:194 283:194 284:195 285:195 286:196 287:196 288:197 289:197 290:198 291:199 292:200 293:201 294:201 295:201 296:201 297:202 298:203 299:204 300:205 301:205 302:206 303:206 304:207 305:207 306:207 307:207 308:207 309:207 310:207 311:208 312:209 313:210 314:211 315:211 316:211 317:211 318:212 319:212 320:213 321:213 322:214 323:214 324:215 325:216 326:217 327:218 328:218 329:218 330:218 331:219 332:220 333:221 334:222 335:222 336:223 337:224 338:224 339:224 340:224 341:224 342:225 343:226 344:227 345:228 346:229 347:230 348:231 349:232 350:233 351:233 352:234 353:235 354:236 355:237 356:238 357:239 358:240 359:240 360:241 361:242 362:243 363:244 364:244 365:245 366:246 367:246 368:247 369:247 370:248 371:249 372:249 373:250 374:251 375:252 376:253 377:254 378:255 379:255 380:256 381:257 382:258\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2029 5427 2003 2800 2005 4968 24646 11187 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] which insurance is available for domestic stu ##ents ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:107 12:108 13:109 14:109 15:109 16:110 17:111 18:112 19:113 20:113 21:113 22:114 23:115 24:115 25:115 26:116 27:116 28:116 29:116 30:117 31:117 32:117 33:118 34:119 35:120 36:121 37:121 38:122 39:122 40:122 41:123 42:123 43:123 44:123 45:124 46:124 47:125 48:126 49:127 50:127 51:127 52:128 53:129 54:130 55:131 56:132 57:133 58:133 59:133 60:133 61:134 62:135 63:136 64:136 65:136 66:136 67:136 68:136 69:137 70:137 71:138 72:139 73:139 74:139 75:139 76:140 77:140 78:141 79:142 80:142 81:143 82:144 83:145 84:145 85:145 86:146 87:146 88:146 89:146 90:147 91:148 92:149 93:150 94:151 95:151 96:151 97:152 98:152 99:153 100:154 101:155 102:156 103:157 104:158 105:159 106:160 107:161 108:162 109:162 110:163 111:163 112:163 113:164 114:165 115:165 116:166 117:166 118:167 119:168 120:169 121:169 122:170 123:171 124:171 125:172 126:172 127:173 128:174 129:175 130:175 131:175 132:175 133:176 134:177 135:177 136:178 137:179 138:179 139:180 140:181 141:182 142:183 143:184 144:185 145:186 146:187 147:188 148:189 149:190 150:191 151:192 152:193 153:194 154:194 155:194 156:195 157:195 158:196 159:196 160:197 161:197 162:198 163:199 164:200 165:201 166:201 167:201 168:201 169:202 170:203 171:204 172:205 173:205 174:206 175:206 176:207 177:207 178:207 179:207 180:207 181:207 182:207 183:208 184:209 185:210 186:211 187:211 188:211 189:211 190:212 191:212 192:213 193:213 194:214 195:214 196:215 197:216 198:217 199:218 200:218 201:218 202:218 203:219 204:220 205:221 206:222 207:222 208:223 209:224 210:224 211:224 212:224 213:224 214:225 215:226 216:227 217:228 218:229 219:230 220:231 221:232 222:233 223:233 224:234 225:235 226:236 227:237 228:238 229:239 230:240 231:240 232:241 233:242 234:243 235:244 236:244 237:245 238:246 239:246 240:247 241:247 242:248 243:249 244:249 245:250 246:251 247:252 248:253 249:254 250:255 251:255 252:256 253:257 254:258 255:259 256:260 257:261 258:261 259:261 260:262 261:263 262:264 263:265 264:266 265:267 266:268 267:268 268:269 269:270 270:271 271:272 272:273 273:274 274:274 275:275 276:275 277:276 278:277 279:278 280:278 281:279 282:280 283:281 284:282 285:283 286:284 287:285 288:286 289:287 290:287 291:287 292:287 293:287 294:287 295:287 296:287 297:287 298:288 299:289 300:289 301:289 302:289 303:289 304:289 305:289 306:289 307:289 308:289 309:290 310:291 311:292 312:292 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:292 324:292 325:293 326:294 327:295 328:296 329:297 330:298 331:299 332:300 333:301 334:302 335:303 336:304 337:304 338:305 339:305 340:306 341:307 342:308 343:309 344:310 345:311 346:312 347:313 348:314 349:315 350:316 351:317 352:317 353:318 354:319 355:319 356:319 357:320 358:321 359:322 360:322 361:323 362:323 363:324 364:324 365:324 366:324 367:325 368:325 369:325 370:325 371:325 372:325 373:326 374:326 375:327 376:327 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2029 5427 2003 2800 2005 4968 24646 11187 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] which insurance is available for domestic stu ##ents ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:180 12:181 13:182 14:183 15:184 16:185 17:186 18:187 19:188 20:189 21:190 22:191 23:192 24:193 25:194 26:194 27:194 28:195 29:195 30:196 31:196 32:197 33:197 34:198 35:199 36:200 37:201 38:201 39:201 40:201 41:202 42:203 43:204 44:205 45:205 46:206 47:206 48:207 49:207 50:207 51:207 52:207 53:207 54:207 55:208 56:209 57:210 58:211 59:211 60:211 61:211 62:212 63:212 64:213 65:213 66:214 67:214 68:215 69:216 70:217 71:218 72:218 73:218 74:218 75:219 76:220 77:221 78:222 79:222 80:223 81:224 82:224 83:224 84:224 85:224 86:225 87:226 88:227 89:228 90:229 91:230 92:231 93:232 94:233 95:233 96:234 97:235 98:236 99:237 100:238 101:239 102:240 103:240 104:241 105:242 106:243 107:244 108:244 109:245 110:246 111:246 112:247 113:247 114:248 115:249 116:249 117:250 118:251 119:252 120:253 121:254 122:255 123:255 124:256 125:257 126:258 127:259 128:260 129:261 130:261 131:261 132:262 133:263 134:264 135:265 136:266 137:267 138:268 139:268 140:269 141:270 142:271 143:272 144:273 145:274 146:274 147:275 148:275 149:276 150:277 151:278 152:278 153:279 154:280 155:281 156:282 157:283 158:284 159:285 160:286 161:287 162:287 163:287 164:287 165:287 166:287 167:287 168:287 169:287 170:288 171:289 172:289 173:289 174:289 175:289 176:289 177:289 178:289 179:289 180:289 181:290 182:291 183:292 184:292 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:292 196:292 197:293 198:294 199:295 200:296 201:297 202:298 203:299 204:300 205:301 206:302 207:303 208:304 209:304 210:305 211:305 212:306 213:307 214:308 215:309 216:310 217:311 218:312 219:313 220:314 221:315 222:316 223:317 224:317 225:318 226:319 227:319 228:319 229:320 230:321 231:322 232:322 233:323 234:323 235:324 236:324 237:324 238:324 239:325 240:325 241:325 242:325 243:325 244:325 245:326 246:326 247:327 248:327 249:327 250:327 251:327 252:327 253:327 254:327 255:327 256:327 257:327 258:327\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True\n",
            "INFO:tensorflow:input_ids: 101 2029 5427 2003 2800 2005 4968 24646 11187 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000003\n",
            "INFO:tensorflow:example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who ad ##mini ##stra ##tes ship ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:5 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:11 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:22 39:22 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:30 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:36 56:36 57:37 58:38 59:39 60:40 61:41 62:42 63:43 64:44 65:45 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:56 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:65 88:66 89:67 90:68 91:69 92:69 93:70 94:71 95:72 96:73 97:74 98:75 99:75 100:76 101:77 102:78 103:79 104:80 105:81 106:82 107:83 108:84 109:85 110:86 111:87 112:88 113:89 114:90 115:91 116:92 117:92 118:92 119:93 120:94 121:94 122:94 123:95 124:96 125:97 126:98 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:109 141:109 142:110 143:111 144:112 145:113 146:113 147:113 148:114 149:115 150:115 151:115 152:116 153:116 154:116 155:116 156:117 157:117 158:117 159:118 160:119 161:120 162:121 163:121 164:122 165:122 166:122 167:123 168:123 169:123 170:123 171:124 172:124 173:125 174:126 175:127 176:127 177:127 178:128 179:129 180:130 181:131 182:132 183:133 184:133 185:133 186:133 187:134 188:135 189:136 190:136 191:136 192:136 193:136 194:136 195:137 196:137 197:138 198:139 199:139 200:139 201:139 202:140 203:140 204:141 205:142 206:142 207:143 208:144 209:145 210:145 211:145 212:146 213:146 214:146 215:146 216:147 217:148 218:149 219:150 220:151 221:151 222:151 223:152 224:152 225:153 226:154 227:155 228:156 229:157 230:158 231:159 232:160 233:161 234:162 235:162 236:163 237:163 238:163 239:164 240:165 241:165 242:166 243:166 244:167 245:168 246:169 247:169 248:170 249:171 250:171 251:172 252:172 253:173 254:174 255:175 256:175 257:175 258:175 259:176 260:177 261:177 262:178 263:179 264:179 265:180 266:181 267:182 268:183 269:184 270:185 271:186 272:187 273:188 274:189 275:190 276:191 277:192 278:193 279:194 280:194 281:194 282:195 283:195 284:196 285:196 286:197 287:197 288:198 289:199 290:200 291:201 292:201 293:201 294:201 295:202 296:203 297:204 298:205 299:205 300:206 301:206 302:207 303:207 304:207 305:207 306:207 307:207 308:207 309:208 310:209 311:210 312:211 313:211 314:211 315:211 316:212 317:212 318:213 319:213 320:214 321:214 322:215 323:216 324:217 325:218 326:218 327:218 328:218 329:219 330:220 331:221 332:222 333:222 334:223 335:224 336:224 337:224 338:224 339:224 340:225 341:226 342:227 343:228 344:229 345:230 346:231 347:232 348:233 349:233 350:234 351:235 352:236 353:237 354:238 355:239 356:240 357:240 358:241 359:242 360:243 361:244 362:244 363:245 364:246 365:246 366:247 367:247 368:248 369:249 370:249 371:250 372:251 373:252 374:253 375:254 376:255 377:255 378:256 379:257 380:258 381:259 382:260\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 4748 25300 20528 4570 2911 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000004\n",
            "INFO:tensorflow:example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] who ad ##mini ##stra ##tes ship ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:107 10:108 11:109 12:109 13:109 14:110 15:111 16:112 17:113 18:113 19:113 20:114 21:115 22:115 23:115 24:116 25:116 26:116 27:116 28:117 29:117 30:117 31:118 32:119 33:120 34:121 35:121 36:122 37:122 38:122 39:123 40:123 41:123 42:123 43:124 44:124 45:125 46:126 47:127 48:127 49:127 50:128 51:129 52:130 53:131 54:132 55:133 56:133 57:133 58:133 59:134 60:135 61:136 62:136 63:136 64:136 65:136 66:136 67:137 68:137 69:138 70:139 71:139 72:139 73:139 74:140 75:140 76:141 77:142 78:142 79:143 80:144 81:145 82:145 83:145 84:146 85:146 86:146 87:146 88:147 89:148 90:149 91:150 92:151 93:151 94:151 95:152 96:152 97:153 98:154 99:155 100:156 101:157 102:158 103:159 104:160 105:161 106:162 107:162 108:163 109:163 110:163 111:164 112:165 113:165 114:166 115:166 116:167 117:168 118:169 119:169 120:170 121:171 122:171 123:172 124:172 125:173 126:174 127:175 128:175 129:175 130:175 131:176 132:177 133:177 134:178 135:179 136:179 137:180 138:181 139:182 140:183 141:184 142:185 143:186 144:187 145:188 146:189 147:190 148:191 149:192 150:193 151:194 152:194 153:194 154:195 155:195 156:196 157:196 158:197 159:197 160:198 161:199 162:200 163:201 164:201 165:201 166:201 167:202 168:203 169:204 170:205 171:205 172:206 173:206 174:207 175:207 176:207 177:207 178:207 179:207 180:207 181:208 182:209 183:210 184:211 185:211 186:211 187:211 188:212 189:212 190:213 191:213 192:214 193:214 194:215 195:216 196:217 197:218 198:218 199:218 200:218 201:219 202:220 203:221 204:222 205:222 206:223 207:224 208:224 209:224 210:224 211:224 212:225 213:226 214:227 215:228 216:229 217:230 218:231 219:232 220:233 221:233 222:234 223:235 224:236 225:237 226:238 227:239 228:240 229:240 230:241 231:242 232:243 233:244 234:244 235:245 236:246 237:246 238:247 239:247 240:248 241:249 242:249 243:250 244:251 245:252 246:253 247:254 248:255 249:255 250:256 251:257 252:258 253:259 254:260 255:261 256:261 257:261 258:262 259:263 260:264 261:265 262:266 263:267 264:268 265:268 266:269 267:270 268:271 269:272 270:273 271:274 272:274 273:275 274:275 275:276 276:277 277:278 278:278 279:279 280:280 281:281 282:282 283:283 284:284 285:285 286:286 287:287 288:287 289:287 290:287 291:287 292:287 293:287 294:287 295:287 296:288 297:289 298:289 299:289 300:289 301:289 302:289 303:289 304:289 305:289 306:289 307:290 308:291 309:292 310:292 311:292 312:292 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:293 324:294 325:295 326:296 327:297 328:298 329:299 330:300 331:301 332:302 333:303 334:304 335:304 336:305 337:305 338:306 339:307 340:308 341:309 342:310 343:311 344:312 345:313 346:314 347:315 348:316 349:317 350:317 351:318 352:319 353:319 354:319 355:320 356:321 357:322 358:322 359:323 360:323 361:324 362:324 363:324 364:324 365:325 366:325 367:325 368:325 369:325 370:325 371:326 372:326 373:327 374:327 375:327 376:327 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 4748 25300 20528 4570 2911 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000005\n",
            "INFO:tensorflow:example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] who ad ##mini ##stra ##tes ship ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:180 10:181 11:182 12:183 13:184 14:185 15:186 16:187 17:188 18:189 19:190 20:191 21:192 22:193 23:194 24:194 25:194 26:195 27:195 28:196 29:196 30:197 31:197 32:198 33:199 34:200 35:201 36:201 37:201 38:201 39:202 40:203 41:204 42:205 43:205 44:206 45:206 46:207 47:207 48:207 49:207 50:207 51:207 52:207 53:208 54:209 55:210 56:211 57:211 58:211 59:211 60:212 61:212 62:213 63:213 64:214 65:214 66:215 67:216 68:217 69:218 70:218 71:218 72:218 73:219 74:220 75:221 76:222 77:222 78:223 79:224 80:224 81:224 82:224 83:224 84:225 85:226 86:227 87:228 88:229 89:230 90:231 91:232 92:233 93:233 94:234 95:235 96:236 97:237 98:238 99:239 100:240 101:240 102:241 103:242 104:243 105:244 106:244 107:245 108:246 109:246 110:247 111:247 112:248 113:249 114:249 115:250 116:251 117:252 118:253 119:254 120:255 121:255 122:256 123:257 124:258 125:259 126:260 127:261 128:261 129:261 130:262 131:263 132:264 133:265 134:266 135:267 136:268 137:268 138:269 139:270 140:271 141:272 142:273 143:274 144:274 145:275 146:275 147:276 148:277 149:278 150:278 151:279 152:280 153:281 154:282 155:283 156:284 157:285 158:286 159:287 160:287 161:287 162:287 163:287 164:287 165:287 166:287 167:287 168:288 169:289 170:289 171:289 172:289 173:289 174:289 175:289 176:289 177:289 178:289 179:290 180:291 181:292 182:292 183:292 184:292 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:293 196:294 197:295 198:296 199:297 200:298 201:299 202:300 203:301 204:302 205:303 206:304 207:304 208:305 209:305 210:306 211:307 212:308 213:309 214:310 215:311 216:312 217:313 218:314 219:315 220:316 221:317 222:317 223:318 224:319 225:319 226:319 227:320 228:321 229:322 230:322 231:323 232:323 233:324 234:324 235:324 236:324 237:325 238:325 239:325 240:325 241:325 242:325 243:326 244:326 245:327 246:327 247:327 248:327 249:327 250:327 251:327 252:327 253:327 254:327 255:327 256:327\n",
            "INFO:tensorflow:token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True\n",
            "INFO:tensorflow:input_ids: 101 2040 4748 25300 20528 4570 2911 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000006\n",
            "INFO:tensorflow:example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual de ##du ##ct ##ible amount for ship ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:5 21:5 22:6 23:6 24:7 25:8 26:9 27:10 28:11 29:11 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:20 41:21 42:22 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:29 52:30 53:30 54:31 55:32 56:33 57:34 58:35 59:36 60:36 61:36 62:37 63:38 64:39 65:40 66:41 67:42 68:43 69:44 70:45 71:46 72:47 73:48 74:49 75:50 76:51 77:52 78:53 79:54 80:55 81:56 82:56 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:67 95:68 96:69 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:75 105:76 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:85 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:92 123:92 124:93 125:94 126:94 127:94 128:95 129:96 130:97 131:98 132:98 133:98 134:99 135:100 136:101 137:102 138:103 139:104 140:105 141:106 142:107 143:108 144:109 145:109 146:109 147:110 148:111 149:112 150:113 151:113 152:113 153:114 154:115 155:115 156:115 157:116 158:116 159:116 160:116 161:117 162:117 163:117 164:118 165:119 166:120 167:121 168:121 169:122 170:122 171:122 172:123 173:123 174:123 175:123 176:124 177:124 178:125 179:126 180:127 181:127 182:127 183:128 184:129 185:130 186:131 187:132 188:133 189:133 190:133 191:133 192:134 193:135 194:136 195:136 196:136 197:136 198:136 199:136 200:137 201:137 202:138 203:139 204:139 205:139 206:139 207:140 208:140 209:141 210:142 211:142 212:143 213:144 214:145 215:145 216:145 217:146 218:146 219:146 220:146 221:147 222:148 223:149 224:150 225:151 226:151 227:151 228:152 229:152 230:153 231:154 232:155 233:156 234:157 235:158 236:159 237:160 238:161 239:162 240:162 241:163 242:163 243:163 244:164 245:165 246:165 247:166 248:166 249:167 250:168 251:169 252:169 253:170 254:171 255:171 256:172 257:172 258:173 259:174 260:175 261:175 262:175 263:175 264:176 265:177 266:177 267:178 268:179 269:179 270:180 271:181 272:182 273:183 274:184 275:185 276:186 277:187 278:188 279:189 280:190 281:191 282:192 283:193 284:194 285:194 286:194 287:195 288:195 289:196 290:196 291:197 292:197 293:198 294:199 295:200 296:201 297:201 298:201 299:201 300:202 301:203 302:204 303:205 304:205 305:206 306:206 307:207 308:207 309:207 310:207 311:207 312:207 313:207 314:208 315:209 316:210 317:211 318:211 319:211 320:211 321:212 322:212 323:213 324:213 325:214 326:214 327:215 328:216 329:217 330:218 331:218 332:218 333:218 334:219 335:220 336:221 337:222 338:222 339:223 340:224 341:224 342:224 343:224 344:224 345:225 346:226 347:227 348:228 349:229 350:230 351:231 352:232 353:233 354:233 355:234 356:235 357:236 358:237 359:238 360:239 361:240 362:240 363:241 364:242 365:243 366:244 367:244 368:245 369:246 370:246 371:247 372:247 373:248 374:249 375:249 376:250 377:251 378:252 379:253 380:254 381:255 382:255\n",
            "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2139 8566 6593 7028 3815 2005 2911 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000007\n",
            "INFO:tensorflow:example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual de ##du ##ct ##ible amount for ship ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:107 15:108 16:109 17:109 18:109 19:110 20:111 21:112 22:113 23:113 24:113 25:114 26:115 27:115 28:115 29:116 30:116 31:116 32:116 33:117 34:117 35:117 36:118 37:119 38:120 39:121 40:121 41:122 42:122 43:122 44:123 45:123 46:123 47:123 48:124 49:124 50:125 51:126 52:127 53:127 54:127 55:128 56:129 57:130 58:131 59:132 60:133 61:133 62:133 63:133 64:134 65:135 66:136 67:136 68:136 69:136 70:136 71:136 72:137 73:137 74:138 75:139 76:139 77:139 78:139 79:140 80:140 81:141 82:142 83:142 84:143 85:144 86:145 87:145 88:145 89:146 90:146 91:146 92:146 93:147 94:148 95:149 96:150 97:151 98:151 99:151 100:152 101:152 102:153 103:154 104:155 105:156 106:157 107:158 108:159 109:160 110:161 111:162 112:162 113:163 114:163 115:163 116:164 117:165 118:165 119:166 120:166 121:167 122:168 123:169 124:169 125:170 126:171 127:171 128:172 129:172 130:173 131:174 132:175 133:175 134:175 135:175 136:176 137:177 138:177 139:178 140:179 141:179 142:180 143:181 144:182 145:183 146:184 147:185 148:186 149:187 150:188 151:189 152:190 153:191 154:192 155:193 156:194 157:194 158:194 159:195 160:195 161:196 162:196 163:197 164:197 165:198 166:199 167:200 168:201 169:201 170:201 171:201 172:202 173:203 174:204 175:205 176:205 177:206 178:206 179:207 180:207 181:207 182:207 183:207 184:207 185:207 186:208 187:209 188:210 189:211 190:211 191:211 192:211 193:212 194:212 195:213 196:213 197:214 198:214 199:215 200:216 201:217 202:218 203:218 204:218 205:218 206:219 207:220 208:221 209:222 210:222 211:223 212:224 213:224 214:224 215:224 216:224 217:225 218:226 219:227 220:228 221:229 222:230 223:231 224:232 225:233 226:233 227:234 228:235 229:236 230:237 231:238 232:239 233:240 234:240 235:241 236:242 237:243 238:244 239:244 240:245 241:246 242:246 243:247 244:247 245:248 246:249 247:249 248:250 249:251 250:252 251:253 252:254 253:255 254:255 255:256 256:257 257:258 258:259 259:260 260:261 261:261 262:261 263:262 264:263 265:264 266:265 267:266 268:267 269:268 270:268 271:269 272:270 273:271 274:272 275:273 276:274 277:274 278:275 279:275 280:276 281:277 282:278 283:278 284:279 285:280 286:281 287:282 288:283 289:284 290:285 291:286 292:287 293:287 294:287 295:287 296:287 297:287 298:287 299:287 300:287 301:288 302:289 303:289 304:289 305:289 306:289 307:289 308:289 309:289 310:289 311:289 312:290 313:291 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:292 324:292 325:292 326:292 327:292 328:293 329:294 330:295 331:296 332:297 333:298 334:299 335:300 336:301 337:302 338:303 339:304 340:304 341:305 342:305 343:306 344:307 345:308 346:309 347:310 348:311 349:312 350:313 351:314 352:315 353:316 354:317 355:317 356:318 357:319 358:319 359:319 360:320 361:321 362:322 363:322 364:323 365:323 366:324 367:324 368:324 369:324 370:325 371:325 372:325 373:325 374:325 375:325 376:326 377:326 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2139 8566 6593 7028 3815 2005 2911 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000008\n",
            "INFO:tensorflow:example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual de ##du ##ct ##ible amount for ship ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 14:180 15:181 16:182 17:183 18:184 19:185 20:186 21:187 22:188 23:189 24:190 25:191 26:192 27:193 28:194 29:194 30:194 31:195 32:195 33:196 34:196 35:197 36:197 37:198 38:199 39:200 40:201 41:201 42:201 43:201 44:202 45:203 46:204 47:205 48:205 49:206 50:206 51:207 52:207 53:207 54:207 55:207 56:207 57:207 58:208 59:209 60:210 61:211 62:211 63:211 64:211 65:212 66:212 67:213 68:213 69:214 70:214 71:215 72:216 73:217 74:218 75:218 76:218 77:218 78:219 79:220 80:221 81:222 82:222 83:223 84:224 85:224 86:224 87:224 88:224 89:225 90:226 91:227 92:228 93:229 94:230 95:231 96:232 97:233 98:233 99:234 100:235 101:236 102:237 103:238 104:239 105:240 106:240 107:241 108:242 109:243 110:244 111:244 112:245 113:246 114:246 115:247 116:247 117:248 118:249 119:249 120:250 121:251 122:252 123:253 124:254 125:255 126:255 127:256 128:257 129:258 130:259 131:260 132:261 133:261 134:261 135:262 136:263 137:264 138:265 139:266 140:267 141:268 142:268 143:269 144:270 145:271 146:272 147:273 148:274 149:274 150:275 151:275 152:276 153:277 154:278 155:278 156:279 157:280 158:281 159:282 160:283 161:284 162:285 163:286 164:287 165:287 166:287 167:287 168:287 169:287 170:287 171:287 172:287 173:288 174:289 175:289 176:289 177:289 178:289 179:289 180:289 181:289 182:289 183:289 184:290 185:291 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:292 196:292 197:292 198:292 199:292 200:293 201:294 202:295 203:296 204:297 205:298 206:299 207:300 208:301 209:302 210:303 211:304 212:304 213:305 214:305 215:306 216:307 217:308 218:309 219:310 220:311 221:312 222:313 223:314 224:315 225:316 226:317 227:317 228:318 229:319 230:319 231:319 232:320 233:321 234:322 235:322 236:323 237:323 238:324 239:324 240:324 241:324 242:325 243:325 244:325 245:325 246:325 247:325 248:326 249:326 250:327 251:327 252:327 253:327 254:327 255:327 256:327 257:327 258:327 259:327 260:327 261:327\n",
            "INFO:tensorflow:token_is_max_context: 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2139 8566 6593 7028 3815 2005 2911 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000009\n",
            "INFO:tensorflow:example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual out of pocket limit ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:5 18:5 19:6 20:6 21:7 22:8 23:9 24:10 25:11 26:11 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:20 37:20 38:21 39:22 40:22 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:36 58:36 59:37 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:55 78:56 79:56 80:56 81:57 82:58 83:59 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:75 102:76 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:85 112:86 113:87 114:88 115:89 116:90 117:91 118:92 119:92 120:92 121:93 122:94 123:94 124:94 125:95 126:96 127:97 128:98 129:98 130:98 131:99 132:100 133:101 134:102 135:103 136:104 137:105 138:106 139:107 140:108 141:109 142:109 143:109 144:110 145:111 146:112 147:113 148:113 149:113 150:114 151:115 152:115 153:115 154:116 155:116 156:116 157:116 158:117 159:117 160:117 161:118 162:119 163:120 164:121 165:121 166:122 167:122 168:122 169:123 170:123 171:123 172:123 173:124 174:124 175:125 176:126 177:127 178:127 179:127 180:128 181:129 182:130 183:131 184:132 185:133 186:133 187:133 188:133 189:134 190:135 191:136 192:136 193:136 194:136 195:136 196:136 197:137 198:137 199:138 200:139 201:139 202:139 203:139 204:140 205:140 206:141 207:142 208:142 209:143 210:144 211:145 212:145 213:145 214:146 215:146 216:146 217:146 218:147 219:148 220:149 221:150 222:151 223:151 224:151 225:152 226:152 227:153 228:154 229:155 230:156 231:157 232:158 233:159 234:160 235:161 236:162 237:162 238:163 239:163 240:163 241:164 242:165 243:165 244:166 245:166 246:167 247:168 248:169 249:169 250:170 251:171 252:171 253:172 254:172 255:173 256:174 257:175 258:175 259:175 260:175 261:176 262:177 263:177 264:178 265:179 266:179 267:180 268:181 269:182 270:183 271:184 272:185 273:186 274:187 275:188 276:189 277:190 278:191 279:192 280:193 281:194 282:194 283:194 284:195 285:195 286:196 287:196 288:197 289:197 290:198 291:199 292:200 293:201 294:201 295:201 296:201 297:202 298:203 299:204 300:205 301:205 302:206 303:206 304:207 305:207 306:207 307:207 308:207 309:207 310:207 311:208 312:209 313:210 314:211 315:211 316:211 317:211 318:212 319:212 320:213 321:213 322:214 323:214 324:215 325:216 326:217 327:218 328:218 329:218 330:218 331:219 332:220 333:221 334:222 335:222 336:223 337:224 338:224 339:224 340:224 341:224 342:225 343:226 344:227 345:228 346:229 347:230 348:231 349:232 350:233 351:233 352:234 353:235 354:236 355:237 356:238 357:239 358:240 359:240 360:241 361:242 362:243 363:244 364:244 365:245 366:246 367:246 368:247 369:247 370:248 371:249 372:249 373:250 374:251 375:252 376:253 377:254 378:255 379:255 380:256 381:257 382:258\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2041 1997 4979 5787 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000010\n",
            "INFO:tensorflow:example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual out of pocket limit ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:107 12:108 13:109 14:109 15:109 16:110 17:111 18:112 19:113 20:113 21:113 22:114 23:115 24:115 25:115 26:116 27:116 28:116 29:116 30:117 31:117 32:117 33:118 34:119 35:120 36:121 37:121 38:122 39:122 40:122 41:123 42:123 43:123 44:123 45:124 46:124 47:125 48:126 49:127 50:127 51:127 52:128 53:129 54:130 55:131 56:132 57:133 58:133 59:133 60:133 61:134 62:135 63:136 64:136 65:136 66:136 67:136 68:136 69:137 70:137 71:138 72:139 73:139 74:139 75:139 76:140 77:140 78:141 79:142 80:142 81:143 82:144 83:145 84:145 85:145 86:146 87:146 88:146 89:146 90:147 91:148 92:149 93:150 94:151 95:151 96:151 97:152 98:152 99:153 100:154 101:155 102:156 103:157 104:158 105:159 106:160 107:161 108:162 109:162 110:163 111:163 112:163 113:164 114:165 115:165 116:166 117:166 118:167 119:168 120:169 121:169 122:170 123:171 124:171 125:172 126:172 127:173 128:174 129:175 130:175 131:175 132:175 133:176 134:177 135:177 136:178 137:179 138:179 139:180 140:181 141:182 142:183 143:184 144:185 145:186 146:187 147:188 148:189 149:190 150:191 151:192 152:193 153:194 154:194 155:194 156:195 157:195 158:196 159:196 160:197 161:197 162:198 163:199 164:200 165:201 166:201 167:201 168:201 169:202 170:203 171:204 172:205 173:205 174:206 175:206 176:207 177:207 178:207 179:207 180:207 181:207 182:207 183:208 184:209 185:210 186:211 187:211 188:211 189:211 190:212 191:212 192:213 193:213 194:214 195:214 196:215 197:216 198:217 199:218 200:218 201:218 202:218 203:219 204:220 205:221 206:222 207:222 208:223 209:224 210:224 211:224 212:224 213:224 214:225 215:226 216:227 217:228 218:229 219:230 220:231 221:232 222:233 223:233 224:234 225:235 226:236 227:237 228:238 229:239 230:240 231:240 232:241 233:242 234:243 235:244 236:244 237:245 238:246 239:246 240:247 241:247 242:248 243:249 244:249 245:250 246:251 247:252 248:253 249:254 250:255 251:255 252:256 253:257 254:258 255:259 256:260 257:261 258:261 259:261 260:262 261:263 262:264 263:265 264:266 265:267 266:268 267:268 268:269 269:270 270:271 271:272 272:273 273:274 274:274 275:275 276:275 277:276 278:277 279:278 280:278 281:279 282:280 283:281 284:282 285:283 286:284 287:285 288:286 289:287 290:287 291:287 292:287 293:287 294:287 295:287 296:287 297:287 298:288 299:289 300:289 301:289 302:289 303:289 304:289 305:289 306:289 307:289 308:289 309:290 310:291 311:292 312:292 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:292 324:292 325:293 326:294 327:295 328:296 329:297 330:298 331:299 332:300 333:301 334:302 335:303 336:304 337:304 338:305 339:305 340:306 341:307 342:308 343:309 344:310 345:311 346:312 347:313 348:314 349:315 350:316 351:317 352:317 353:318 354:319 355:319 356:319 357:320 358:321 359:322 360:322 361:323 362:323 363:324 364:324 365:324 366:324 367:325 368:325 369:325 370:325 371:325 372:325 373:326 374:326 375:327 376:327 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2041 1997 4979 5787 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000011\n",
            "INFO:tensorflow:example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] what is the annual out of pocket limit ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:180 12:181 13:182 14:183 15:184 16:185 17:186 18:187 19:188 20:189 21:190 22:191 23:192 24:193 25:194 26:194 27:194 28:195 29:195 30:196 31:196 32:197 33:197 34:198 35:199 36:200 37:201 38:201 39:201 40:201 41:202 42:203 43:204 44:205 45:205 46:206 47:206 48:207 49:207 50:207 51:207 52:207 53:207 54:207 55:208 56:209 57:210 58:211 59:211 60:211 61:211 62:212 63:212 64:213 65:213 66:214 67:214 68:215 69:216 70:217 71:218 72:218 73:218 74:218 75:219 76:220 77:221 78:222 79:222 80:223 81:224 82:224 83:224 84:224 85:224 86:225 87:226 88:227 89:228 90:229 91:230 92:231 93:232 94:233 95:233 96:234 97:235 98:236 99:237 100:238 101:239 102:240 103:240 104:241 105:242 106:243 107:244 108:244 109:245 110:246 111:246 112:247 113:247 114:248 115:249 116:249 117:250 118:251 119:252 120:253 121:254 122:255 123:255 124:256 125:257 126:258 127:259 128:260 129:261 130:261 131:261 132:262 133:263 134:264 135:265 136:266 137:267 138:268 139:268 140:269 141:270 142:271 143:272 144:273 145:274 146:274 147:275 148:275 149:276 150:277 151:278 152:278 153:279 154:280 155:281 156:282 157:283 158:284 159:285 160:286 161:287 162:287 163:287 164:287 165:287 166:287 167:287 168:287 169:287 170:288 171:289 172:289 173:289 174:289 175:289 176:289 177:289 178:289 179:289 180:289 181:290 182:291 183:292 184:292 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:292 196:292 197:293 198:294 199:295 200:296 201:297 202:298 203:299 204:300 205:301 206:302 207:303 208:304 209:304 210:305 211:305 212:306 213:307 214:308 215:309 216:310 217:311 218:312 219:313 220:314 221:315 222:316 223:317 224:317 225:318 226:319 227:319 228:319 229:320 230:321 231:322 232:322 233:323 234:323 235:324 236:324 237:324 238:324 239:325 240:325 241:325 242:325 243:325 244:325 245:326 246:326 247:327 248:327 249:327 250:327 251:327 252:327 253:327 254:327 255:327 256:327 257:327 258:327\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3296 2041 1997 4979 5787 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000012\n",
            "INFO:tensorflow:example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] where is the fee billed ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:5 16:6 17:6 18:7 19:8 20:9 21:10 22:11 23:11 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:22 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:36 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:56 76:56 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:65 87:66 88:67 89:68 90:69 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:75 99:76 100:77 101:78 102:79 103:80 104:81 105:82 106:83 107:84 108:85 109:86 110:87 111:88 112:89 113:90 114:91 115:92 116:92 117:92 118:93 119:94 120:94 121:94 122:95 123:96 124:97 125:98 126:98 127:98 128:99 129:100 130:101 131:102 132:103 133:104 134:105 135:106 136:107 137:108 138:109 139:109 140:109 141:110 142:111 143:112 144:113 145:113 146:113 147:114 148:115 149:115 150:115 151:116 152:116 153:116 154:116 155:117 156:117 157:117 158:118 159:119 160:120 161:121 162:121 163:122 164:122 165:122 166:123 167:123 168:123 169:123 170:124 171:124 172:125 173:126 174:127 175:127 176:127 177:128 178:129 179:130 180:131 181:132 182:133 183:133 184:133 185:133 186:134 187:135 188:136 189:136 190:136 191:136 192:136 193:136 194:137 195:137 196:138 197:139 198:139 199:139 200:139 201:140 202:140 203:141 204:142 205:142 206:143 207:144 208:145 209:145 210:145 211:146 212:146 213:146 214:146 215:147 216:148 217:149 218:150 219:151 220:151 221:151 222:152 223:152 224:153 225:154 226:155 227:156 228:157 229:158 230:159 231:160 232:161 233:162 234:162 235:163 236:163 237:163 238:164 239:165 240:165 241:166 242:166 243:167 244:168 245:169 246:169 247:170 248:171 249:171 250:172 251:172 252:173 253:174 254:175 255:175 256:175 257:175 258:176 259:177 260:177 261:178 262:179 263:179 264:180 265:181 266:182 267:183 268:184 269:185 270:186 271:187 272:188 273:189 274:190 275:191 276:192 277:193 278:194 279:194 280:194 281:195 282:195 283:196 284:196 285:197 286:197 287:198 288:199 289:200 290:201 291:201 292:201 293:201 294:202 295:203 296:204 297:205 298:205 299:206 300:206 301:207 302:207 303:207 304:207 305:207 306:207 307:207 308:208 309:209 310:210 311:211 312:211 313:211 314:211 315:212 316:212 317:213 318:213 319:214 320:214 321:215 322:216 323:217 324:218 325:218 326:218 327:218 328:219 329:220 330:221 331:222 332:222 333:223 334:224 335:224 336:224 337:224 338:224 339:225 340:226 341:227 342:228 343:229 344:230 345:231 346:232 347:233 348:233 349:234 350:235 351:236 352:237 353:238 354:239 355:240 356:240 357:241 358:242 359:243 360:244 361:244 362:245 363:246 364:246 365:247 366:247 367:248 368:249 369:249 370:250 371:251 372:252 373:253 374:254 375:255 376:255 377:256 378:257 379:258 380:259 381:260 382:261\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2073 2003 1996 7408 14843 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000013\n",
            "INFO:tensorflow:example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] where is the fee billed ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:107 9:108 10:109 11:109 12:109 13:110 14:111 15:112 16:113 17:113 18:113 19:114 20:115 21:115 22:115 23:116 24:116 25:116 26:116 27:117 28:117 29:117 30:118 31:119 32:120 33:121 34:121 35:122 36:122 37:122 38:123 39:123 40:123 41:123 42:124 43:124 44:125 45:126 46:127 47:127 48:127 49:128 50:129 51:130 52:131 53:132 54:133 55:133 56:133 57:133 58:134 59:135 60:136 61:136 62:136 63:136 64:136 65:136 66:137 67:137 68:138 69:139 70:139 71:139 72:139 73:140 74:140 75:141 76:142 77:142 78:143 79:144 80:145 81:145 82:145 83:146 84:146 85:146 86:146 87:147 88:148 89:149 90:150 91:151 92:151 93:151 94:152 95:152 96:153 97:154 98:155 99:156 100:157 101:158 102:159 103:160 104:161 105:162 106:162 107:163 108:163 109:163 110:164 111:165 112:165 113:166 114:166 115:167 116:168 117:169 118:169 119:170 120:171 121:171 122:172 123:172 124:173 125:174 126:175 127:175 128:175 129:175 130:176 131:177 132:177 133:178 134:179 135:179 136:180 137:181 138:182 139:183 140:184 141:185 142:186 143:187 144:188 145:189 146:190 147:191 148:192 149:193 150:194 151:194 152:194 153:195 154:195 155:196 156:196 157:197 158:197 159:198 160:199 161:200 162:201 163:201 164:201 165:201 166:202 167:203 168:204 169:205 170:205 171:206 172:206 173:207 174:207 175:207 176:207 177:207 178:207 179:207 180:208 181:209 182:210 183:211 184:211 185:211 186:211 187:212 188:212 189:213 190:213 191:214 192:214 193:215 194:216 195:217 196:218 197:218 198:218 199:218 200:219 201:220 202:221 203:222 204:222 205:223 206:224 207:224 208:224 209:224 210:224 211:225 212:226 213:227 214:228 215:229 216:230 217:231 218:232 219:233 220:233 221:234 222:235 223:236 224:237 225:238 226:239 227:240 228:240 229:241 230:242 231:243 232:244 233:244 234:245 235:246 236:246 237:247 238:247 239:248 240:249 241:249 242:250 243:251 244:252 245:253 246:254 247:255 248:255 249:256 250:257 251:258 252:259 253:260 254:261 255:261 256:261 257:262 258:263 259:264 260:265 261:266 262:267 263:268 264:268 265:269 266:270 267:271 268:272 269:273 270:274 271:274 272:275 273:275 274:276 275:277 276:278 277:278 278:279 279:280 280:281 281:282 282:283 283:284 284:285 285:286 286:287 287:287 288:287 289:287 290:287 291:287 292:287 293:287 294:287 295:288 296:289 297:289 298:289 299:289 300:289 301:289 302:289 303:289 304:289 305:289 306:290 307:291 308:292 309:292 310:292 311:292 312:292 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:293 323:294 324:295 325:296 326:297 327:298 328:299 329:300 330:301 331:302 332:303 333:304 334:304 335:305 336:305 337:306 338:307 339:308 340:309 341:310 342:311 343:312 344:313 345:314 346:315 347:316 348:317 349:317 350:318 351:319 352:319 353:319 354:320 355:321 356:322 357:322 358:323 359:323 360:324 361:324 362:324 363:324 364:325 365:325 366:325 367:325 368:325 369:325 370:326 371:326 372:327 373:327 374:327 375:327 376:327 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True\n",
            "INFO:tensorflow:input_ids: 101 2073 2003 1996 7408 14843 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000014\n",
            "INFO:tensorflow:example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] where is the fee billed ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:180 9:181 10:182 11:183 12:184 13:185 14:186 15:187 16:188 17:189 18:190 19:191 20:192 21:193 22:194 23:194 24:194 25:195 26:195 27:196 28:196 29:197 30:197 31:198 32:199 33:200 34:201 35:201 36:201 37:201 38:202 39:203 40:204 41:205 42:205 43:206 44:206 45:207 46:207 47:207 48:207 49:207 50:207 51:207 52:208 53:209 54:210 55:211 56:211 57:211 58:211 59:212 60:212 61:213 62:213 63:214 64:214 65:215 66:216 67:217 68:218 69:218 70:218 71:218 72:219 73:220 74:221 75:222 76:222 77:223 78:224 79:224 80:224 81:224 82:224 83:225 84:226 85:227 86:228 87:229 88:230 89:231 90:232 91:233 92:233 93:234 94:235 95:236 96:237 97:238 98:239 99:240 100:240 101:241 102:242 103:243 104:244 105:244 106:245 107:246 108:246 109:247 110:247 111:248 112:249 113:249 114:250 115:251 116:252 117:253 118:254 119:255 120:255 121:256 122:257 123:258 124:259 125:260 126:261 127:261 128:261 129:262 130:263 131:264 132:265 133:266 134:267 135:268 136:268 137:269 138:270 139:271 140:272 141:273 142:274 143:274 144:275 145:275 146:276 147:277 148:278 149:278 150:279 151:280 152:281 153:282 154:283 155:284 156:285 157:286 158:287 159:287 160:287 161:287 162:287 163:287 164:287 165:287 166:287 167:288 168:289 169:289 170:289 171:289 172:289 173:289 174:289 175:289 176:289 177:289 178:290 179:291 180:292 181:292 182:292 183:292 184:292 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:293 195:294 196:295 197:296 198:297 199:298 200:299 201:300 202:301 203:302 204:303 205:304 206:304 207:305 208:305 209:306 210:307 211:308 212:309 213:310 214:311 215:312 216:313 217:314 218:315 219:316 220:317 221:317 222:318 223:319 224:319 225:319 226:320 227:321 228:322 229:322 230:323 231:323 232:324 233:324 234:324 235:324 236:325 237:325 238:325 239:325 240:325 241:325 242:326 243:326 244:327 245:327 246:327 247:327 248:327 249:327 250:327 251:327 252:327 253:327 254:327 255:327\n",
            "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:False 205:False 206:False 207:False 208:False 209:False 210:False 211:False 212:False 213:False 214:False 215:False 216:False 217:False 218:False 219:False 220:False 221:False 222:False 223:False 224:False 225:False 226:False 227:False 228:False 229:False 230:False 231:False 232:False 233:False 234:False 235:False 236:False 237:False 238:False 239:False 240:False 241:False 242:False 243:False 244:False 245:False 246:False 247:False 248:False 249:False 250:False 251:False 252:False 253:False 254:False 255:True\n",
            "INFO:tensorflow:input_ids: 101 2073 2003 1996 7408 14843 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000015\n",
            "INFO:tensorflow:example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to claims ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:5 19:5 20:6 21:6 22:7 23:8 24:9 25:10 26:11 27:11 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:20 39:21 40:22 41:22 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:30 52:31 53:32 54:33 55:34 56:35 57:36 58:36 59:36 60:37 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:56 81:56 82:57 83:58 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:69 96:70 97:71 98:72 99:73 100:74 101:75 102:75 103:76 104:77 105:78 106:79 107:80 108:81 109:82 110:83 111:84 112:85 113:86 114:87 115:88 116:89 117:90 118:91 119:92 120:92 121:92 122:93 123:94 124:94 125:94 126:95 127:96 128:97 129:98 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:105 139:106 140:107 141:108 142:109 143:109 144:109 145:110 146:111 147:112 148:113 149:113 150:113 151:114 152:115 153:115 154:115 155:116 156:116 157:116 158:116 159:117 160:117 161:117 162:118 163:119 164:120 165:121 166:121 167:122 168:122 169:122 170:123 171:123 172:123 173:123 174:124 175:124 176:125 177:126 178:127 179:127 180:127 181:128 182:129 183:130 184:131 185:132 186:133 187:133 188:133 189:133 190:134 191:135 192:136 193:136 194:136 195:136 196:136 197:136 198:137 199:137 200:138 201:139 202:139 203:139 204:139 205:140 206:140 207:141 208:142 209:142 210:143 211:144 212:145 213:145 214:145 215:146 216:146 217:146 218:146 219:147 220:148 221:149 222:150 223:151 224:151 225:151 226:152 227:152 228:153 229:154 230:155 231:156 232:157 233:158 234:159 235:160 236:161 237:162 238:162 239:163 240:163 241:163 242:164 243:165 244:165 245:166 246:166 247:167 248:168 249:169 250:169 251:170 252:171 253:171 254:172 255:172 256:173 257:174 258:175 259:175 260:175 261:175 262:176 263:177 264:177 265:178 266:179 267:179 268:180 269:181 270:182 271:183 272:184 273:185 274:186 275:187 276:188 277:189 278:190 279:191 280:192 281:193 282:194 283:194 284:194 285:195 286:195 287:196 288:196 289:197 290:197 291:198 292:199 293:200 294:201 295:201 296:201 297:201 298:202 299:203 300:204 301:205 302:205 303:206 304:206 305:207 306:207 307:207 308:207 309:207 310:207 311:207 312:208 313:209 314:210 315:211 316:211 317:211 318:211 319:212 320:212 321:213 322:213 323:214 324:214 325:215 326:216 327:217 328:218 329:218 330:218 331:218 332:219 333:220 334:221 335:222 336:222 337:223 338:224 339:224 340:224 341:224 342:224 343:225 344:226 345:227 346:228 347:229 348:230 349:231 350:232 351:233 352:233 353:234 354:235 355:236 356:237 357:238 358:239 359:240 360:240 361:241 362:242 363:243 364:244 365:244 366:245 367:246 368:246 369:247 370:247 371:248 372:249 373:249 374:250 375:251 376:252 377:253 378:254 379:255 380:255 381:256 382:257\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 4447 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000016\n",
            "INFO:tensorflow:example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to claims ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:107 13:108 14:109 15:109 16:109 17:110 18:111 19:112 20:113 21:113 22:113 23:114 24:115 25:115 26:115 27:116 28:116 29:116 30:116 31:117 32:117 33:117 34:118 35:119 36:120 37:121 38:121 39:122 40:122 41:122 42:123 43:123 44:123 45:123 46:124 47:124 48:125 49:126 50:127 51:127 52:127 53:128 54:129 55:130 56:131 57:132 58:133 59:133 60:133 61:133 62:134 63:135 64:136 65:136 66:136 67:136 68:136 69:136 70:137 71:137 72:138 73:139 74:139 75:139 76:139 77:140 78:140 79:141 80:142 81:142 82:143 83:144 84:145 85:145 86:145 87:146 88:146 89:146 90:146 91:147 92:148 93:149 94:150 95:151 96:151 97:151 98:152 99:152 100:153 101:154 102:155 103:156 104:157 105:158 106:159 107:160 108:161 109:162 110:162 111:163 112:163 113:163 114:164 115:165 116:165 117:166 118:166 119:167 120:168 121:169 122:169 123:170 124:171 125:171 126:172 127:172 128:173 129:174 130:175 131:175 132:175 133:175 134:176 135:177 136:177 137:178 138:179 139:179 140:180 141:181 142:182 143:183 144:184 145:185 146:186 147:187 148:188 149:189 150:190 151:191 152:192 153:193 154:194 155:194 156:194 157:195 158:195 159:196 160:196 161:197 162:197 163:198 164:199 165:200 166:201 167:201 168:201 169:201 170:202 171:203 172:204 173:205 174:205 175:206 176:206 177:207 178:207 179:207 180:207 181:207 182:207 183:207 184:208 185:209 186:210 187:211 188:211 189:211 190:211 191:212 192:212 193:213 194:213 195:214 196:214 197:215 198:216 199:217 200:218 201:218 202:218 203:218 204:219 205:220 206:221 207:222 208:222 209:223 210:224 211:224 212:224 213:224 214:224 215:225 216:226 217:227 218:228 219:229 220:230 221:231 222:232 223:233 224:233 225:234 226:235 227:236 228:237 229:238 230:239 231:240 232:240 233:241 234:242 235:243 236:244 237:244 238:245 239:246 240:246 241:247 242:247 243:248 244:249 245:249 246:250 247:251 248:252 249:253 250:254 251:255 252:255 253:256 254:257 255:258 256:259 257:260 258:261 259:261 260:261 261:262 262:263 263:264 264:265 265:266 266:267 267:268 268:268 269:269 270:270 271:271 272:272 273:273 274:274 275:274 276:275 277:275 278:276 279:277 280:278 281:278 282:279 283:280 284:281 285:282 286:283 287:284 288:285 289:286 290:287 291:287 292:287 293:287 294:287 295:287 296:287 297:287 298:287 299:288 300:289 301:289 302:289 303:289 304:289 305:289 306:289 307:289 308:289 309:289 310:290 311:291 312:292 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:292 324:292 325:292 326:293 327:294 328:295 329:296 330:297 331:298 332:299 333:300 334:301 335:302 336:303 337:304 338:304 339:305 340:305 341:306 342:307 343:308 344:309 345:310 346:311 347:312 348:313 349:314 350:315 351:316 352:317 353:317 354:318 355:319 356:319 357:319 358:320 359:321 360:322 361:322 362:323 363:323 364:324 365:324 366:324 367:324 368:325 369:325 370:325 371:325 372:325 373:325 374:326 375:326 376:327 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 4447 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000017\n",
            "INFO:tensorflow:example_index: 5\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to claims ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:180 13:181 14:182 15:183 16:184 17:185 18:186 19:187 20:188 21:189 22:190 23:191 24:192 25:193 26:194 27:194 28:194 29:195 30:195 31:196 32:196 33:197 34:197 35:198 36:199 37:200 38:201 39:201 40:201 41:201 42:202 43:203 44:204 45:205 46:205 47:206 48:206 49:207 50:207 51:207 52:207 53:207 54:207 55:207 56:208 57:209 58:210 59:211 60:211 61:211 62:211 63:212 64:212 65:213 66:213 67:214 68:214 69:215 70:216 71:217 72:218 73:218 74:218 75:218 76:219 77:220 78:221 79:222 80:222 81:223 82:224 83:224 84:224 85:224 86:224 87:225 88:226 89:227 90:228 91:229 92:230 93:231 94:232 95:233 96:233 97:234 98:235 99:236 100:237 101:238 102:239 103:240 104:240 105:241 106:242 107:243 108:244 109:244 110:245 111:246 112:246 113:247 114:247 115:248 116:249 117:249 118:250 119:251 120:252 121:253 122:254 123:255 124:255 125:256 126:257 127:258 128:259 129:260 130:261 131:261 132:261 133:262 134:263 135:264 136:265 137:266 138:267 139:268 140:268 141:269 142:270 143:271 144:272 145:273 146:274 147:274 148:275 149:275 150:276 151:277 152:278 153:278 154:279 155:280 156:281 157:282 158:283 159:284 160:285 161:286 162:287 163:287 164:287 165:287 166:287 167:287 168:287 169:287 170:287 171:288 172:289 173:289 174:289 175:289 176:289 177:289 178:289 179:289 180:289 181:289 182:290 183:291 184:292 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:292 196:292 197:292 198:293 199:294 200:295 201:296 202:297 203:298 204:299 205:300 206:301 207:302 208:303 209:304 210:304 211:305 212:305 213:306 214:307 215:308 216:309 217:310 218:311 219:312 220:313 221:314 222:315 223:316 224:317 225:317 226:318 227:319 228:319 229:319 230:320 231:321 232:322 233:322 234:323 235:323 236:324 237:324 238:324 239:324 240:325 241:325 242:325 243:325 244:325 245:325 246:326 247:326 248:327 249:327 250:327 251:327 252:327 253:327 254:327 255:327 256:327 257:327 258:327 259:327\n",
            "INFO:tensorflow:token_is_max_context: 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 4447 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000018\n",
            "INFO:tensorflow:example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to insurance charges ? [SEP] domestic student health insurance plan ( ship ) . benefits and highlights of the ship . ship has been developed especially for stony brook students ( and their dependent ##s ) to provide access to comprehensive care that complement ##s the quality health services on campus . the details of the plan are reviewed and recommended each year by committee members to ensure that the coverage is well - suited to the needs of the stony brook students and respectful of their budgets . ship is administered by united healthcare . the plans meet all of the student health insurance standards developed by the american college health association . ship is tailor - made for the college population . provides continuous coverage at a reasonable cost for most on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:5 20:5 21:6 22:6 23:7 24:8 25:9 26:10 27:11 28:11 29:11 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:20 40:21 41:22 42:22 43:22 44:23 45:24 46:25 47:26 48:27 49:28 50:29 51:30 52:30 53:31 54:32 55:33 56:34 57:35 58:36 59:36 60:36 61:37 62:38 63:39 64:40 65:41 66:42 67:43 68:44 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:56 83:57 84:58 85:59 86:60 87:61 88:62 89:63 90:64 91:65 92:66 93:67 94:68 95:69 96:69 97:70 98:71 99:72 100:73 101:74 102:75 103:75 104:76 105:77 106:78 107:79 108:80 109:81 110:82 111:83 112:84 113:85 114:86 115:87 116:88 117:89 118:90 119:91 120:92 121:92 122:92 123:93 124:94 125:94 126:94 127:95 128:96 129:97 130:98 131:98 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:109 145:109 146:110 147:111 148:112 149:113 150:113 151:113 152:114 153:115 154:115 155:115 156:116 157:116 158:116 159:116 160:117 161:117 162:117 163:118 164:119 165:120 166:121 167:121 168:122 169:122 170:122 171:123 172:123 173:123 174:123 175:124 176:124 177:125 178:126 179:127 180:127 181:127 182:128 183:129 184:130 185:131 186:132 187:133 188:133 189:133 190:133 191:134 192:135 193:136 194:136 195:136 196:136 197:136 198:136 199:137 200:137 201:138 202:139 203:139 204:139 205:139 206:140 207:140 208:141 209:142 210:142 211:143 212:144 213:145 214:145 215:145 216:146 217:146 218:146 219:146 220:147 221:148 222:149 223:150 224:151 225:151 226:151 227:152 228:152 229:153 230:154 231:155 232:156 233:157 234:158 235:159 236:160 237:161 238:162 239:162 240:163 241:163 242:163 243:164 244:165 245:165 246:166 247:166 248:167 249:168 250:169 251:169 252:170 253:171 254:171 255:172 256:172 257:173 258:174 259:175 260:175 261:175 262:175 263:176 264:177 265:177 266:178 267:179 268:179 269:180 270:181 271:182 272:183 273:184 274:185 275:186 276:187 277:188 278:189 279:190 280:191 281:192 282:193 283:194 284:194 285:194 286:195 287:195 288:196 289:196 290:197 291:197 292:198 293:199 294:200 295:201 296:201 297:201 298:201 299:202 300:203 301:204 302:205 303:205 304:206 305:206 306:207 307:207 308:207 309:207 310:207 311:207 312:207 313:208 314:209 315:210 316:211 317:211 318:211 319:211 320:212 321:212 322:213 323:213 324:214 325:214 326:215 327:216 328:217 329:218 330:218 331:218 332:218 333:219 334:220 335:221 336:222 337:222 338:223 339:224 340:224 341:224 342:224 343:224 344:225 345:226 346:227 347:228 348:229 349:230 350:231 351:232 352:233 353:233 354:234 355:235 356:236 357:237 358:238 359:239 360:240 361:240 362:241 363:242 364:243 365:244 366:244 367:245 368:246 369:246 370:247 371:247 372:248 373:249 374:249 375:250 376:251 377:252 378:253 379:254 380:255 381:255 382:256\n",
            "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 5427 5571 1029 102 4968 3076 2740 5427 2933 1006 2911 1007 1012 6666 1998 11637 1997 1996 2911 1012 2911 2038 2042 2764 2926 2005 16104 9566 2493 1006 1998 2037 7790 2015 1007 2000 3073 3229 2000 7721 2729 2008 13711 2015 1996 3737 2740 2578 2006 3721 1012 1996 4751 1997 1996 2933 2024 8182 1998 6749 2169 2095 2011 2837 2372 2000 5676 2008 1996 6325 2003 2092 1011 10897 2000 1996 3791 1997 1996 16104 9566 2493 1998 26438 1997 2037 26178 1012 2911 2003 8564 2011 2142 9871 1012 1996 3488 3113 2035 1997 1996 3076 2740 5427 4781 2764 2011 1996 2137 2267 2740 2523 1012 2911 2003 22701 1011 2081 2005 1996 2267 2313 1012 3640 7142 6325 2012 1037 9608 3465 2005 2087 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000019\n",
            "INFO:tensorflow:example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to insurance charges ? [SEP] on or off - campus medical care over fall / winter and spring / summer semester ##s . covers pre - existing medical conditions & prevent ##ative care . annual de ##du ##ct ##ible $ 200 for an individual . annual out of pocket limit of $ 3 , 000 which includes de ##du ##ct ##ible ##s , copa ##ys and coins ##urance . covers in ##patient and out ##patient mental health care . no de ##du ##ct ##ible applied to prescription drug coverage . please note : office visits for primary care and specialists have a $ 35 copa ##yme ##nt with 0 % coins ##urance with a refer ##ral and 30 % coins ##urance without a refer ##ral . emergency room vs . urgent care : only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 13:107 14:108 15:109 16:109 17:109 18:110 19:111 20:112 21:113 22:113 23:113 24:114 25:115 26:115 27:115 28:116 29:116 30:116 31:116 32:117 33:117 34:117 35:118 36:119 37:120 38:121 39:121 40:122 41:122 42:122 43:123 44:123 45:123 46:123 47:124 48:124 49:125 50:126 51:127 52:127 53:127 54:128 55:129 56:130 57:131 58:132 59:133 60:133 61:133 62:133 63:134 64:135 65:136 66:136 67:136 68:136 69:136 70:136 71:137 72:137 73:138 74:139 75:139 76:139 77:139 78:140 79:140 80:141 81:142 82:142 83:143 84:144 85:145 86:145 87:145 88:146 89:146 90:146 91:146 92:147 93:148 94:149 95:150 96:151 97:151 98:151 99:152 100:152 101:153 102:154 103:155 104:156 105:157 106:158 107:159 108:160 109:161 110:162 111:162 112:163 113:163 114:163 115:164 116:165 117:165 118:166 119:166 120:167 121:168 122:169 123:169 124:170 125:171 126:171 127:172 128:172 129:173 130:174 131:175 132:175 133:175 134:175 135:176 136:177 137:177 138:178 139:179 140:179 141:180 142:181 143:182 144:183 145:184 146:185 147:186 148:187 149:188 150:189 151:190 152:191 153:192 154:193 155:194 156:194 157:194 158:195 159:195 160:196 161:196 162:197 163:197 164:198 165:199 166:200 167:201 168:201 169:201 170:201 171:202 172:203 173:204 174:205 175:205 176:206 177:206 178:207 179:207 180:207 181:207 182:207 183:207 184:207 185:208 186:209 187:210 188:211 189:211 190:211 191:211 192:212 193:212 194:213 195:213 196:214 197:214 198:215 199:216 200:217 201:218 202:218 203:218 204:218 205:219 206:220 207:221 208:222 209:222 210:223 211:224 212:224 213:224 214:224 215:224 216:225 217:226 218:227 219:228 220:229 221:230 222:231 223:232 224:233 225:233 226:234 227:235 228:236 229:237 230:238 231:239 232:240 233:240 234:241 235:242 236:243 237:244 238:244 239:245 240:246 241:246 242:247 243:247 244:248 245:249 246:249 247:250 248:251 249:252 250:253 251:254 252:255 253:255 254:256 255:257 256:258 257:259 258:260 259:261 260:261 261:261 262:262 263:263 264:264 265:265 266:266 267:267 268:268 269:268 270:269 271:270 272:271 273:272 274:273 275:274 276:274 277:275 278:275 279:276 280:277 281:278 282:278 283:279 284:280 285:281 286:282 287:283 288:284 289:285 290:286 291:287 292:287 293:287 294:287 295:287 296:287 297:287 298:287 299:287 300:288 301:289 302:289 303:289 304:289 305:289 306:289 307:289 308:289 309:289 310:289 311:290 312:291 313:292 314:292 315:292 316:292 317:292 318:292 319:292 320:292 321:292 322:292 323:292 324:292 325:292 326:292 327:293 328:294 329:295 330:296 331:297 332:298 333:299 334:300 335:301 336:302 337:303 338:304 339:304 340:305 341:305 342:306 343:307 344:308 345:309 346:310 347:311 348:312 349:313 350:314 351:315 352:316 353:317 354:317 355:318 356:319 357:319 358:319 359:320 360:321 361:322 362:322 363:323 364:323 365:324 366:324 367:324 368:324 369:325 370:325 371:325 372:325 373:325 374:325 375:326 376:326 377:327 378:327 379:327 380:327 381:327 382:327\n",
            "INFO:tensorflow:token_is_max_context: 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 5427 5571 1029 102 2006 2030 2125 1011 3721 2966 2729 2058 2991 1013 3467 1998 3500 1013 2621 13609 2015 1012 4472 3653 1011 4493 2966 3785 1004 4652 8082 2729 1012 3296 2139 8566 6593 7028 1002 3263 2005 2019 3265 1012 3296 2041 1997 4979 5787 1997 1002 1017 1010 2199 2029 2950 2139 8566 6593 7028 2015 1010 10613 7274 1998 7824 25863 1012 4472 1999 24343 1998 2041 24343 5177 2740 2729 1012 2053 2139 8566 6593 7028 4162 2000 20422 4319 6325 1012 3531 3602 1024 2436 7879 2005 3078 2729 1998 15744 2031 1037 1002 3486 10613 25219 3372 2007 1014 1003 7824 25863 2007 1037 6523 7941 1998 2382 1003 7824 25863 2302 1037 6523 7941 1012 5057 2282 5443 1012 13661 2729 1024 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000020\n",
            "INFO:tensorflow:example_index: 6\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] who should we contact for questions related to insurance charges ? [SEP] only emergency services for the treatment of an emergency condition are covered in an er . emergency room : $ 100 copa ##y after policy year de ##du ##ct ##ible then you pay 20 % coins ##urance ( copa ##yme ##nt / coins ##urance waived if hospital admission ) . urgent care : $ 35 copa ##y after policy year de ##du ##ct ##ible then you pay 0 % for cost - sharing . the fee is billed to your student account in solar . just like all other tuition & fees , this charge is pay ##able by cash , check , money order , credit card or through financial aid . payments are made to the bu ##rsa ##r in the administration building or through solar . if you have questions about benefits , coverage , claims or exclusion ##s you may contact united healthcare customer service at 1 - 800 - 76 ##7 - 07 ##00 or customers ##er ##vic ##e @ uh ##cs ##r . com or visit my ##ac ##co ##unt . uh ##cs ##r . com / log ##in . for questions about insurance charges on your student account or your wai ##ver status , you may contact the student health insurance office located at - f ##sa services office , 157 east side dining , phone : ( 63 ##1 ) 63 ##2 - 65 ##17 , email : student ##hea ##lth ##ins ##urance @ stony ##brook . ed ##u . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 13:180 14:181 15:182 16:183 17:184 18:185 19:186 20:187 21:188 22:189 23:190 24:191 25:192 26:193 27:194 28:194 29:194 30:195 31:195 32:196 33:196 34:197 35:197 36:198 37:199 38:200 39:201 40:201 41:201 42:201 43:202 44:203 45:204 46:205 47:205 48:206 49:206 50:207 51:207 52:207 53:207 54:207 55:207 56:207 57:208 58:209 59:210 60:211 61:211 62:211 63:211 64:212 65:212 66:213 67:213 68:214 69:214 70:215 71:216 72:217 73:218 74:218 75:218 76:218 77:219 78:220 79:221 80:222 81:222 82:223 83:224 84:224 85:224 86:224 87:224 88:225 89:226 90:227 91:228 92:229 93:230 94:231 95:232 96:233 97:233 98:234 99:235 100:236 101:237 102:238 103:239 104:240 105:240 106:241 107:242 108:243 109:244 110:244 111:245 112:246 113:246 114:247 115:247 116:248 117:249 118:249 119:250 120:251 121:252 122:253 123:254 124:255 125:255 126:256 127:257 128:258 129:259 130:260 131:261 132:261 133:261 134:262 135:263 136:264 137:265 138:266 139:267 140:268 141:268 142:269 143:270 144:271 145:272 146:273 147:274 148:274 149:275 150:275 151:276 152:277 153:278 154:278 155:279 156:280 157:281 158:282 159:283 160:284 161:285 162:286 163:287 164:287 165:287 166:287 167:287 168:287 169:287 170:287 171:287 172:288 173:289 174:289 175:289 176:289 177:289 178:289 179:289 180:289 181:289 182:289 183:290 184:291 185:292 186:292 187:292 188:292 189:292 190:292 191:292 192:292 193:292 194:292 195:292 196:292 197:292 198:292 199:293 200:294 201:295 202:296 203:297 204:298 205:299 206:300 207:301 208:302 209:303 210:304 211:304 212:305 213:305 214:306 215:307 216:308 217:309 218:310 219:311 220:312 221:313 222:314 223:315 224:316 225:317 226:317 227:318 228:319 229:319 230:319 231:320 232:321 233:322 234:322 235:323 236:323 237:324 238:324 239:324 240:324 241:325 242:325 243:325 244:325 245:325 246:325 247:326 248:326 249:327 250:327 251:327 252:327 253:327 254:327 255:327 256:327 257:327 258:327 259:327 260:327\n",
            "INFO:tensorflow:token_is_max_context: 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2323 2057 3967 2005 3980 3141 2000 5427 5571 1029 102 2069 5057 2578 2005 1996 3949 1997 2019 5057 4650 2024 3139 1999 2019 9413 1012 5057 2282 1024 1002 2531 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 2322 1003 7824 25863 1006 10613 25219 3372 1013 7824 25863 16301 2065 2902 9634 1007 1012 13661 2729 1024 1002 3486 10613 2100 2044 3343 2095 2139 8566 6593 7028 2059 2017 3477 1014 1003 2005 3465 1011 6631 1012 1996 7408 2003 14843 2000 2115 3076 4070 1999 5943 1012 2074 2066 2035 2060 15413 1004 9883 1010 2023 3715 2003 3477 3085 2011 5356 1010 4638 1010 2769 2344 1010 4923 4003 2030 2083 3361 4681 1012 10504 2024 2081 2000 1996 20934 22381 2099 1999 1996 3447 2311 2030 2083 5943 1012 2065 2017 2031 3980 2055 6666 1010 6325 1010 4447 2030 15945 2015 2017 2089 3967 2142 9871 8013 2326 2012 1015 1011 5385 1011 6146 2581 1011 5718 8889 2030 6304 2121 7903 2063 1030 7910 6169 2099 1012 4012 2030 3942 2026 6305 3597 16671 1012 7910 6169 2099 1012 4012 1013 8833 2378 1012 2005 3980 2055 5427 5571 2006 2115 3076 4070 2030 2115 23701 6299 3570 1010 2017 2089 3967 1996 3076 2740 5427 2436 2284 2012 1011 1042 3736 2578 2436 1010 17403 2264 2217 7759 1010 3042 1024 1006 6191 2487 1007 6191 2475 1011 3515 16576 1010 10373 1024 3076 20192 24658 7076 25863 1030 16104 9697 1012 3968 2226 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000021\n",
            "INFO:tensorflow:example_index: 7\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the cost of insurance for fall 2018 ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:10 28:10 29:11 30:12 31:13 32:13 33:13 34:14 35:15 36:16 37:16 38:16 39:16 40:16 41:16 42:17 43:18 44:19 45:20 46:21 47:22 48:23 49:24 50:25 51:25 52:25 53:26 54:27 55:28 56:29 57:30 58:30 59:31 60:31 61:32 62:33 63:34 64:35 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:40 73:41 74:42 75:43 76:43 77:43 78:44 79:44 80:45 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:49 89:50 90:51 91:52 92:52 93:53 94:53 95:54 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:61 105:61 106:62 107:62 108:63 109:64 110:65 111:66 112:67 113:68 114:68 115:69 116:70 117:71 118:72 119:72 120:72 121:73 122:73 123:74 124:75 125:76 126:77 127:78 128:78 129:79 130:80 131:81 132:81 133:81 134:82 135:82 136:83 137:84 138:85 139:86 140:86 141:86 142:87 143:87\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3465 1997 5427 2005 2991 2760 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000022\n",
            "INFO:tensorflow:example_index: 8\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the cost of insurance for spring 2019 ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:10 28:10 29:11 30:12 31:13 32:13 33:13 34:14 35:15 36:16 37:16 38:16 39:16 40:16 41:16 42:17 43:18 44:19 45:20 46:21 47:22 48:23 49:24 50:25 51:25 52:25 53:26 54:27 55:28 56:29 57:30 58:30 59:31 60:31 61:32 62:33 63:34 64:35 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:40 73:41 74:42 75:43 76:43 77:43 78:44 79:44 80:45 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:49 89:50 90:51 91:52 92:52 93:53 94:53 95:54 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:61 105:61 106:62 107:62 108:63 109:64 110:65 111:66 112:67 113:68 114:68 115:69 116:70 117:71 118:72 119:72 120:72 121:73 122:73 123:74 124:75 125:76 126:77 127:78 128:78 129:79 130:80 131:81 132:81 133:81 134:82 135:82 136:83 137:84 138:85 139:86 140:86 141:86 142:87 143:87\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 3465 1997 5427 2005 3500 10476 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000023\n",
            "INFO:tensorflow:example_index: 9\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the copa ##y for tier 1 drugs ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:10 28:10 29:11 30:12 31:13 32:13 33:13 34:14 35:15 36:16 37:16 38:16 39:16 40:16 41:16 42:17 43:18 44:19 45:20 46:21 47:22 48:23 49:24 50:25 51:25 52:25 53:26 54:27 55:28 56:29 57:30 58:30 59:31 60:31 61:32 62:33 63:34 64:35 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:40 73:41 74:42 75:43 76:43 77:43 78:44 79:44 80:45 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:49 89:50 90:51 91:52 92:52 93:53 94:53 95:54 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:61 105:61 106:62 107:62 108:63 109:64 110:65 111:66 112:67 113:68 114:68 115:69 116:70 117:71 118:72 119:72 120:72 121:73 122:73 123:74 124:75 125:76 126:77 127:78 128:78 129:79 130:80 131:81 132:81 133:81 134:82 135:82 136:83 137:84 138:85 139:86 140:86 141:86 142:87 143:87\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 10613 2100 2005 7563 1015 5850 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000024\n",
            "INFO:tensorflow:example_index: 10\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the copa ##y for tier 2 drugs ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:10 28:10 29:11 30:12 31:13 32:13 33:13 34:14 35:15 36:16 37:16 38:16 39:16 40:16 41:16 42:17 43:18 44:19 45:20 46:21 47:22 48:23 49:24 50:25 51:25 52:25 53:26 54:27 55:28 56:29 57:30 58:30 59:31 60:31 61:32 62:33 63:34 64:35 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:40 73:41 74:42 75:43 76:43 77:43 78:44 79:44 80:45 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:49 89:50 90:51 91:52 92:52 93:53 94:53 95:54 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:61 105:61 106:62 107:62 108:63 109:64 110:65 111:66 112:67 113:68 114:68 115:69 116:70 117:71 118:72 119:72 120:72 121:73 122:73 123:74 124:75 125:76 126:77 127:78 128:78 129:79 130:80 131:81 132:81 133:81 134:82 135:82 136:83 137:84 138:85 139:86 140:86 141:86 142:87 143:87\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 10613 2100 2005 7563 1016 5850 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000025\n",
            "INFO:tensorflow:example_index: 11\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what is the copa ##y for tier 2 drugs ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:10 27:10 28:10 29:11 30:12 31:13 32:13 33:13 34:14 35:15 36:16 37:16 38:16 39:16 40:16 41:16 42:17 43:18 44:19 45:20 46:21 47:22 48:23 49:24 50:25 51:25 52:25 53:26 54:27 55:28 56:29 57:30 58:30 59:31 60:31 61:32 62:33 63:34 64:35 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:40 73:41 74:42 75:43 76:43 77:43 78:44 79:44 80:45 81:45 82:46 83:47 84:48 85:49 86:49 87:49 88:49 89:50 90:51 91:52 92:52 93:53 94:53 95:54 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:61 105:61 106:62 107:62 108:63 109:64 110:65 111:66 112:67 113:68 114:68 115:69 116:70 117:71 118:72 119:72 120:72 121:73 122:73 123:74 124:75 125:76 126:77 127:78 128:78 129:79 130:80 131:81 132:81 133:81 134:82 135:82 136:83 137:84 138:85 139:86 140:86 141:86 142:87 143:87\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2003 1996 10613 2100 2005 7563 1016 5850 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000026\n",
            "INFO:tensorflow:example_index: 12\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] where is the fee billed ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:7 17:7 18:8 19:9 20:10 21:10 22:10 23:10 24:10 25:11 26:12 27:13 28:13 29:13 30:14 31:15 32:16 33:16 34:16 35:16 36:16 37:16 38:17 39:18 40:19 41:20 42:21 43:22 44:23 45:24 46:25 47:25 48:25 49:26 50:27 51:28 52:29 53:30 54:30 55:31 56:31 57:32 58:33 59:34 60:35 61:35 62:36 63:37 64:38 65:39 66:39 67:40 68:40 69:41 70:42 71:43 72:43 73:43 74:44 75:44 76:45 77:45 78:46 79:47 80:48 81:49 82:49 83:49 84:49 85:50 86:51 87:52 88:52 89:53 90:53 91:54 92:54 93:55 94:56 95:57 96:58 97:58 98:59 99:60 100:61 101:61 102:62 103:62 104:63 105:64 106:65 107:66 108:67 109:68 110:68 111:69 112:70 113:71 114:72 115:72 116:72 117:73 118:73 119:74 120:75 121:76 122:77 123:78 124:78 125:79 126:80 127:81 128:81 129:81 130:82 131:82 132:83 133:84 134:85 135:86 136:86 137:86 138:87 139:87\n",
            "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True\n",
            "INFO:tensorflow:input_ids: 101 2073 2003 1996 7408 14843 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000027\n",
            "INFO:tensorflow:example_index: 13\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] how much cover ##ge for emergency room visits ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:7 19:7 20:7 21:8 22:9 23:10 24:10 25:10 26:10 27:10 28:11 29:12 30:13 31:13 32:13 33:14 34:15 35:16 36:16 37:16 38:16 39:16 40:16 41:17 42:18 43:19 44:20 45:21 46:22 47:23 48:24 49:25 50:25 51:25 52:26 53:27 54:28 55:29 56:30 57:30 58:31 59:31 60:32 61:33 62:34 63:35 64:35 65:36 66:37 67:38 68:39 69:39 70:40 71:40 72:41 73:42 74:43 75:43 76:43 77:44 78:44 79:45 80:45 81:46 82:47 83:48 84:49 85:49 86:49 87:49 88:50 89:51 90:52 91:52 92:53 93:53 94:54 95:54 96:55 97:56 98:57 99:58 100:58 101:59 102:60 103:61 104:61 105:62 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:68 114:69 115:70 116:71 117:72 118:72 119:72 120:73 121:73 122:74 123:75 124:76 125:77 126:78 127:78 128:79 129:80 130:81 131:81 132:81 133:82 134:82 135:83 136:84 137:85 138:86 139:86 140:86 141:87 142:87\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True\n",
            "INFO:tensorflow:input_ids: 101 2129 2172 3104 3351 2005 5057 2282 7879 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000028\n",
            "INFO:tensorflow:example_index: 14\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] how much cover ##ge for hospital visits ? [SEP] 2018 - 2019 united healthcare rates for fall / winter 2018 is $ 62 ##4 . 45 and for spring / summer 2019 is $ 86 ##7 . 83 . this is billed to your student account in solar . unlimited coverage for primary care providers , specialists , emergency visits and hospitals . unlimited coverage for prevent ##ative care , including annual physical ##s , g ##yn exams , routine screenings and im ##mun ##izations . prescription drug coverage : $ 10 copa ##y for tier 1 drugs , and a $ 20 copa ##y for tier 2 or 3 drugs . unlimited coverage for inter - collegiate athletics . unlimited coverage for mental health . evacuation and rep ##at ##riation services . coverage for gender re ##ass ##ignment care . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:7 19:7 20:8 21:9 22:10 23:10 24:10 25:10 26:10 27:11 28:12 29:13 30:13 31:13 32:14 33:15 34:16 35:16 36:16 37:16 38:16 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:23 47:24 48:25 49:25 50:25 51:26 52:27 53:28 54:29 55:30 56:30 57:31 58:31 59:32 60:33 61:34 62:35 63:35 64:36 65:37 66:38 67:39 68:39 69:40 70:40 71:41 72:42 73:43 74:43 75:43 76:44 77:44 78:45 79:45 80:46 81:47 82:48 83:49 84:49 85:49 86:49 87:50 88:51 89:52 90:52 91:53 92:53 93:54 94:54 95:55 96:56 97:57 98:58 99:58 100:59 101:60 102:61 103:61 104:62 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:68 113:69 114:70 115:71 116:72 117:72 118:72 119:73 120:73 121:74 122:75 123:76 124:77 125:78 126:78 127:79 128:80 129:81 130:81 131:81 132:82 133:82 134:83 135:84 136:85 137:86 138:86 139:86 140:87 141:87\n",
            "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True\n",
            "INFO:tensorflow:input_ids: 101 2129 2172 3104 3351 2005 2902 7879 1029 102 2760 1011 10476 2142 9871 6165 2005 2991 1013 3467 2760 2003 1002 5786 2549 1012 3429 1998 2005 3500 1013 2621 10476 2003 1002 6564 2581 1012 6640 1012 2023 2003 14843 2000 2115 3076 4070 1999 5943 1012 14668 6325 2005 3078 2729 11670 1010 15744 1010 5057 7879 1998 8323 1012 14668 6325 2005 4652 8082 2729 1010 2164 3296 3558 2015 1010 1043 6038 13869 1010 9410 25437 1998 10047 23041 22318 1012 20422 4319 6325 1024 1002 2184 10613 2100 2005 7563 1015 5850 1010 1998 1037 1002 2322 10613 2100 2005 7563 1016 2030 1017 5850 1012 14668 6325 2005 6970 1011 9234 6482 1012 14668 6325 2005 5177 2740 1012 13982 1998 16360 4017 18769 2578 1012 6325 2005 5907 2128 12054 24838 2729 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000029\n",
            "INFO:tensorflow:example_index: 15\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] can i stay after completing my graduation requirements ? [SEP] you are required to graduate as soon as you complete the requirements for the degree . you can always take additional classes as a non - mat ##ric ##ulated student after your graduation or even informally work with a professor assuming you have a working relationship with a professor already . note that if you are an international student , you may require appropriate immigration authorization for this . but in no case you can delay your graduation . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:21 34:22 35:23 36:23 37:23 38:23 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:44 62:45 63:46 64:47 65:48 66:49 67:50 68:51 69:52 70:52 71:53 72:54 73:55 74:56 75:57 76:58 77:59 78:60 79:60 80:61 81:62 82:63 83:64 84:65 85:66 86:67 87:68 88:69 89:69\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True\n",
            "INFO:tensorflow:input_ids: 101 2064 1045 2994 2044 7678 2026 7665 5918 1029 102 2017 2024 3223 2000 4619 2004 2574 2004 2017 3143 1996 5918 2005 1996 3014 1012 2017 2064 2467 2202 3176 4280 2004 1037 2512 1011 13523 7277 8898 3076 2044 2115 7665 2030 2130 21858 2147 2007 1037 2934 10262 2017 2031 1037 2551 3276 2007 1037 2934 2525 1012 3602 2008 2065 2017 2024 2019 2248 3076 1010 2017 2089 5478 6413 7521 20104 2005 2023 1012 2021 1999 2053 2553 2017 2064 8536 2115 7665 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000030\n",
            "INFO:tensorflow:example_index: 16\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] can i repeat the same class under the same or different professor to improve my grade ? [SEP] a course can be repeated once for \" grade forgiveness . \" only the most recent attempt / grade will count towards the grade point average , but both attempts and both grades will appear on the official transcript . re ##taking a course requires prior approval on the \" graduate course re ##take approval form \" available from the graduate school website . note only courses designated in the graduate bulletin as \" not repeat ##able for credit \" can be re ##taken this way . grades for courses that are \" repeat ##able for credit \" cannot be forgiven this way . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 19:0 20:1 21:2 22:3 23:4 24:5 25:6 26:7 27:7 28:8 29:8 30:8 31:9 32:10 33:11 34:12 35:13 36:13 37:13 38:14 39:15 40:16 41:17 42:18 43:19 44:20 45:20 46:21 47:22 48:23 49:24 50:25 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:33 60:33 61:34 62:35 63:36 64:37 65:38 66:39 67:40 68:41 69:41 70:42 71:43 72:43 73:44 74:45 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:51 83:52 84:53 85:54 86:55 87:56 88:57 89:58 90:59 91:60 92:61 93:61 94:62 95:62 96:63 97:64 98:64 99:65 100:66 101:67 102:67 103:68 104:69 105:69 106:70 107:71 108:72 109:73 110:74 111:75 112:75 113:75 114:76 115:77 116:77 117:78 118:79 119:80 120:81 121:82 122:82\n",
            "INFO:tensorflow:token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True\n",
            "INFO:tensorflow:input_ids: 101 2064 1045 9377 1996 2168 2465 2104 1996 2168 2030 2367 2934 2000 5335 2026 3694 1029 102 1037 2607 2064 2022 5567 2320 2005 1000 3694 17213 1012 1000 2069 1996 2087 3522 3535 1013 3694 2097 4175 2875 1996 3694 2391 2779 1010 2021 2119 4740 1998 2119 7022 2097 3711 2006 1996 2880 24051 1012 2128 17904 1037 2607 5942 3188 6226 2006 1996 1000 4619 2607 2128 15166 6226 2433 1000 2800 2013 1996 4619 2082 4037 1012 3602 2069 5352 4351 1999 1996 4619 13146 2004 1000 2025 9377 3085 2005 4923 1000 2064 2022 2128 25310 2023 2126 1012 7022 2005 5352 2008 2024 1000 9377 3085 2005 4923 1000 3685 2022 24280 2023 2126 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000031\n",
            "INFO:tensorflow:example_index: 17\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] ni ##ran ##jan received his phd from which university ? [SEP] ni ##ran ##jan bala ##su ##bra ##mania ##n is affiliated with the department of biomedical inform ##atics and center of excellence in wireless & information technology ( ce ##wi ##t ) . he received his phd from university of massachusetts , amherst , where he was a part of the center for intelligent information retrieval ( ci ##ir ) . before he started his phd studies , he was a software engineer at the center for natural language processing ( cn ##lp ) at syracuse university . he completed his masters degree in computer science at the university of buffalo in 2003 . prior to joining the computer science department at stony brook in spring 2015 , dr . bala ##su ##bra ##mania ##n was a post - doctoral researcher in the turing center at the university of washington in seattle . ni ##ran ##jan bala ##su ##bra ##mania ##n ' s research is motivated by the challenge of building systems that can extract , understand , and reason with information present in natural language texts . his research interests are in two broad areas : nl ##p and information retrieval . he has worked on different projects in areas like question answering at a 4th grade level , event sc ##hema generation from news stories , machine learning for information retrieval , energy - efficient mobile search , and automatic wikipedia pages . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:0 14:0 15:1 16:1 17:1 18:1 19:1 20:2 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:9 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:19 40:19 41:19 42:19 43:19 44:20 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:27 53:28 54:28 55:29 56:30 57:31 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:41 69:41 70:41 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:47 79:48 80:49 81:50 82:51 83:52 84:53 85:54 86:55 87:56 88:57 89:58 90:59 91:60 92:60 93:60 94:60 95:61 96:62 97:63 98:63 99:64 100:65 101:66 102:67 103:68 104:69 105:70 106:71 107:72 108:73 109:74 110:75 111:76 112:77 113:78 114:78 115:79 116:80 117:81 118:82 119:83 120:84 121:85 122:86 123:87 124:88 125:89 126:90 127:91 128:91 129:92 130:92 131:93 132:93 133:93 134:93 135:93 136:94 137:95 138:96 139:96 140:96 141:97 142:98 143:99 144:100 145:101 146:102 147:103 148:104 149:105 150:106 151:107 152:108 153:108 154:108 155:108 156:108 157:109 158:109 159:109 160:109 161:109 162:109 163:109 164:110 165:111 166:112 167:113 168:114 169:115 170:116 171:117 172:118 173:119 174:120 175:121 176:121 177:122 178:122 179:123 180:124 181:125 182:126 183:127 184:128 185:129 186:130 187:131 188:131 189:132 190:133 191:134 192:135 193:136 194:137 195:138 196:139 197:139 198:140 199:140 200:141 201:142 202:143 203:143 204:144 205:145 206:146 207:147 208:148 209:149 210:150 211:151 212:152 213:153 214:154 215:155 216:156 217:157 218:158 219:159 220:159 221:160 222:161 223:161 224:162 225:163 226:164 227:165 228:165 229:166 230:167 231:168 232:169 233:170 234:170 235:171 236:171 237:171 238:172 239:173 240:173 241:174 242:175 243:176 244:177 245:177\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True\n",
            "INFO:tensorflow:input_ids: 101 9152 5521 8405 2363 2010 8065 2013 2029 2118 1029 102 9152 5521 8405 21451 6342 10024 27010 2078 2003 6989 2007 1996 2533 1997 20906 12367 17592 1998 2415 1997 8012 1999 9949 1004 2592 2974 1006 8292 9148 2102 1007 1012 2002 2363 2010 8065 2013 2118 1997 4404 1010 19850 1010 2073 2002 2001 1037 2112 1997 1996 2415 2005 9414 2592 26384 1006 25022 4313 1007 1012 2077 2002 2318 2010 8065 2913 1010 2002 2001 1037 4007 3992 2012 1996 2415 2005 3019 2653 6364 1006 27166 14277 1007 2012 11736 2118 1012 2002 2949 2010 5972 3014 1999 3274 2671 2012 1996 2118 1997 6901 1999 2494 1012 3188 2000 5241 1996 3274 2671 2533 2012 16104 9566 1999 3500 2325 1010 2852 1012 21451 6342 10024 27010 2078 2001 1037 2695 1011 11316 10753 1999 1996 28639 2415 2012 1996 2118 1997 2899 1999 5862 1012 9152 5521 8405 21451 6342 10024 27010 2078 1005 1055 2470 2003 12774 2011 1996 4119 1997 2311 3001 2008 2064 14817 1010 3305 1010 1998 3114 2007 2592 2556 1999 3019 2653 6981 1012 2010 2470 5426 2024 1999 2048 5041 2752 1024 17953 2361 1998 2592 26384 1012 2002 2038 2499 2006 2367 3934 1999 2752 2066 3160 10739 2012 1037 4343 3694 2504 1010 2724 8040 28433 4245 2013 2739 3441 1010 3698 4083 2005 2592 26384 1010 2943 1011 8114 4684 3945 1010 1998 6882 16948 5530 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000032\n",
            "INFO:tensorflow:example_index: 18\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] prof reza ##ul received his phd from which university ? [SEP] reza ##ul chow ##dh ##ury received his ph . d . from the department of computer sciences , ut austin , working with professor vijay ##a rama ##chan ##dran , and defending \" cache - efficient algorithms and data structures : theory and experimental evaluation \" . prior to joining sb ##u in 2011 , he was in boston working with professor sand ##or va ##j ##da ' s structural bio ##in ##form ##atics group at boston university , and professor charles lei ##ser ##son ' s super ##tech research group at mit . before moving to boston , he was a postdoctoral fellow at the center for computational visual ##ization ( cv ##c ) , institute for computational engineering & sciences ( ice ##s ) , university of texas at austin . he worked with professor chandra ##jit baja ##j . chow ##dh ##ury now leads the theoretical and experimental algorithm ##ics ( tea ) group where they concentrate on both algorithm design and algorithm engineering . he hold ##a a joint appointment with the institute for advanced computational sciences ( ia ##cs ) . reza ##ul chow ##dh ##ury is currently involved in an ns ##f - funded project with charles lei ##ser ##son and steven johnson of mit on building a ste ##nc ##il computation compiler called \" po ##cho ##ir \" . a ste ##nc ##il defines the value of a grid point in a d - dimensional spatial grid at time t as a function of neighboring grid points at recent times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:0 13:0 14:1 15:1 16:1 17:2 18:3 19:4 20:4 21:4 22:4 23:5 24:6 25:7 26:8 27:9 28:10 29:10 30:11 31:12 32:12 33:13 34:14 35:15 36:16 37:16 38:17 39:17 40:17 41:17 42:18 43:19 44:20 45:20 46:20 47:20 48:21 49:22 50:23 51:24 52:24 53:25 54:26 55:27 56:28 57:28 58:28 59:29 60:30 61:31 62:32 63:32 64:33 65:34 66:34 67:35 68:36 69:37 70:38 71:39 72:40 73:41 74:42 75:42 76:43 77:43 78:43 79:43 80:43 81:44 82:45 83:45 84:45 85:45 86:46 87:47 88:48 89:49 90:49 91:50 92:51 93:52 94:53 95:53 96:53 97:53 98:53 99:54 100:54 101:55 102:56 103:57 104:58 105:58 106:59 107:60 108:61 109:62 110:62 111:63 112:64 113:65 114:66 115:67 116:68 117:69 118:70 119:71 120:72 121:73 122:73 123:74 124:74 125:74 126:74 127:74 128:75 129:76 130:77 131:78 132:79 133:80 134:81 135:81 136:81 137:81 138:81 139:82 140:83 141:84 142:85 143:86 144:86 145:87 146:88 147:89 148:90 149:91 150:91 151:92 152:92 153:92 154:93 155:93 156:93 157:94 158:95 159:96 160:97 161:98 162:99 163:100 164:100 165:101 166:101 167:101 168:102 169:103 170:104 171:105 172:106 173:107 174:108 175:109 176:110 177:111 178:112 179:112 180:113 181:114 182:114 183:115 184:116 185:117 186:118 187:119 188:120 189:121 190:122 191:123 192:124 193:125 194:125 195:125 196:125 197:125 198:125 199:125 200:126 201:126 202:126 203:127 204:128 205:129 206:130 207:131 208:132 209:132 210:132 211:132 212:133 213:134 214:135 215:136 216:136 217:136 218:137 219:138 220:139 221:140 222:141 223:142 224:143 225:144 226:145 227:145 228:145 229:146 230:147 231:148 232:149 233:149 234:149 235:149 236:149 237:149 238:150 239:151 240:151 241:151 242:152 243:153 244:154 245:155 246:156 247:157 248:158 249:159 250:160 251:161 252:161 253:161 254:162 255:163 256:164 257:165 258:166 259:167 260:168 261:169 262:170 263:171 264:172 265:173 266:174 267:175 268:176 269:177 270:178 271:178 272:179 273:179 274:179 275:180 276:180 277:181 278:182 279:182 280:183 281:184 282:185 283:186 284:187 285:187 286:188 287:188 288:189 289:190 290:190 291:191 292:192 293:193 294:194 295:195 296:196 297:197 298:198 299:198 300:199 301:199 302:200 303:200 304:200 305:201 306:201 307:201 308:201 309:201 310:202 311:202 312:202 313:203 314:204 315:204 316:205 317:206 318:207 319:208 320:209 321:210 322:211 323:212 324:212 325:213 326:213 327:214 328:215 329:216 330:217 331:218 332:219 333:220 334:221 335:222 336:223 337:224 338:225 339:226 340:227 341:228 342:228 343:229 344:230 345:231 346:231 347:232 348:233 349:234 350:235 351:236 352:237 353:238 354:239 355:240 356:241 357:241 358:241 359:242 360:243 361:244 362:245 363:245 364:245 365:246 366:246 367:247 368:247 369:247 370:248 371:249 372:250 373:251 374:252 375:253 376:254 377:255 378:256 379:256 380:257 381:258 382:259\n",
            "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 11268 26323 5313 2363 2010 8065 2013 2029 2118 1029 102 26323 5313 20209 16425 13098 2363 2010 6887 1012 1040 1012 2013 1996 2533 1997 3274 4163 1010 21183 5899 1010 2551 2007 2934 17027 2050 14115 14856 24914 1010 1998 6984 1000 17053 1011 8114 13792 1998 2951 5090 1024 3399 1998 6388 9312 1000 1012 3188 2000 5241 24829 2226 1999 2249 1010 2002 2001 1999 3731 2551 2007 2934 5472 2953 12436 3501 2850 1005 1055 8332 16012 2378 14192 17592 2177 2012 3731 2118 1010 1998 2934 2798 26947 8043 3385 1005 1055 3565 15007 2470 2177 2012 10210 1012 2077 3048 2000 3731 1010 2002 2001 1037 29272 3507 2012 1996 2415 2005 15078 5107 3989 1006 26226 2278 1007 1010 2820 2005 15078 3330 1004 4163 1006 3256 2015 1007 1010 2118 1997 3146 2012 5899 1012 2002 2499 2007 2934 16469 18902 19497 3501 1012 20209 16425 13098 2085 5260 1996 9373 1998 6388 9896 6558 1006 5572 1007 2177 2073 2027 10152 2006 2119 9896 2640 1998 9896 3330 1012 2002 2907 2050 1037 4101 6098 2007 1996 2820 2005 3935 15078 4163 1006 24264 6169 1007 1012 26323 5313 20209 16425 13098 2003 2747 2920 1999 2019 24978 2546 1011 6787 2622 2007 2798 26947 8043 3385 1998 7112 3779 1997 10210 2006 2311 1037 26261 12273 4014 22334 21624 2170 1000 13433 9905 4313 1000 1012 1037 26261 12273 4014 11859 1996 3643 1997 1037 8370 2391 1999 1037 1040 1011 8789 13589 8370 2012 2051 1056 2004 1037 3853 1997 8581 8370 2685 2012 3522 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000033\n",
            "INFO:tensorflow:example_index: 18\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] prof reza ##ul received his phd from which university ? [SEP] of texas at austin . he worked with professor chandra ##jit baja ##j . chow ##dh ##ury now leads the theoretical and experimental algorithm ##ics ( tea ) group where they concentrate on both algorithm design and algorithm engineering . he hold ##a a joint appointment with the institute for advanced computational sciences ( ia ##cs ) . reza ##ul chow ##dh ##ury is currently involved in an ns ##f - funded project with charles lei ##ser ##son and steven johnson of mit on building a ste ##nc ##il computation compiler called \" po ##cho ##ir \" . a ste ##nc ##il defines the value of a grid point in a d - dimensional spatial grid at time t as a function of neighboring grid points at recent times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will make good use of the memory hierarchy and processor pipeline ##s endemic to multi ##core processors and will run fast on a diverse set of hardware platforms . a wide variety of ste ##nc ##il - based applications — ranging across physics , biology , chemistry , energy , climate , mechanical and electrical engineering , finance , and other areas — will become easier to develop and maintain . some of his other projects focus on efficient resource - oblivious algorithms , fast energetic ##s computation , and protein - protein docking awards . reza ##ul chow ##dh ##ury is a recipient of the prestigious ns ##f career award . reza ##ul chow ##dh ##ury received a best paper award in ip ##dp ##s 2010 for introducing [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:83 13:84 14:85 15:86 16:86 17:87 18:88 19:89 20:90 21:91 22:91 23:92 24:92 25:92 26:93 27:93 28:93 29:94 30:95 31:96 32:97 33:98 34:99 35:100 36:100 37:101 38:101 39:101 40:102 41:103 42:104 43:105 44:106 45:107 46:108 47:109 48:110 49:111 50:112 51:112 52:113 53:114 54:114 55:115 56:116 57:117 58:118 59:119 60:120 61:121 62:122 63:123 64:124 65:125 66:125 67:125 68:125 69:125 70:125 71:125 72:126 73:126 74:126 75:127 76:128 77:129 78:130 79:131 80:132 81:132 82:132 83:132 84:133 85:134 86:135 87:136 88:136 89:136 90:137 91:138 92:139 93:140 94:141 95:142 96:143 97:144 98:145 99:145 100:145 101:146 102:147 103:148 104:149 105:149 106:149 107:149 108:149 109:149 110:150 111:151 112:151 113:151 114:152 115:153 116:154 117:155 118:156 119:157 120:158 121:159 122:160 123:161 124:161 125:161 126:162 127:163 128:164 129:165 130:166 131:167 132:168 133:169 134:170 135:171 136:172 137:173 138:174 139:175 140:176 141:177 142:178 143:178 144:179 145:179 146:179 147:180 148:180 149:181 150:182 151:182 152:183 153:184 154:185 155:186 156:187 157:187 158:188 159:188 160:189 161:190 162:190 163:191 164:192 165:193 166:194 167:195 168:196 169:197 170:198 171:198 172:199 173:199 174:200 175:200 176:200 177:201 178:201 179:201 180:201 181:201 182:202 183:202 184:202 185:203 186:204 187:204 188:205 189:206 190:207 191:208 192:209 193:210 194:211 195:212 196:212 197:213 198:213 199:214 200:215 201:216 202:217 203:218 204:219 205:220 206:221 207:222 208:223 209:224 210:225 211:226 212:227 213:228 214:228 215:229 216:230 217:231 218:231 219:232 220:233 221:234 222:235 223:236 224:237 225:238 226:239 227:240 228:241 229:241 230:241 231:242 232:243 233:244 234:245 235:245 236:245 237:246 238:246 239:247 240:247 241:247 242:248 243:249 244:250 245:251 246:252 247:253 248:254 249:255 250:256 251:256 252:257 253:258 254:259 255:260 256:261 257:262 258:263 259:264 260:265 261:266 262:267 263:268 264:269 265:269 266:270 267:271 268:272 269:272 270:273 271:274 272:275 273:276 274:277 275:278 276:279 277:280 278:281 279:282 280:283 281:284 282:284 283:285 284:286 285:287 286:288 287:289 288:289 289:289 290:289 291:289 292:290 293:291 294:292 295:293 296:294 297:294 298:295 299:295 300:296 301:296 302:297 303:297 304:298 305:298 306:299 307:300 308:301 309:302 310:302 311:303 312:303 313:304 314:305 315:306 316:307 317:308 318:309 319:310 320:311 321:312 322:313 323:314 324:314 325:315 326:316 327:317 328:318 329:319 330:320 331:321 332:322 333:323 334:323 335:323 336:324 337:324 338:325 339:326 340:326 341:327 342:327 343:328 344:329 345:329 346:329 347:330 348:331 349:331 350:332 351:332 352:333 353:333 354:333 355:334 356:335 357:336 358:337 359:338 360:339 361:340 362:340 363:341 364:342 365:342 366:343 367:343 368:344 369:344 370:344 371:345 372:346 373:347 374:348 375:349 376:350 377:351 378:351 379:351 380:352 381:353 382:354\n",
            "INFO:tensorflow:token_is_max_context: 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 11268 26323 5313 2363 2010 8065 2013 2029 2118 1029 102 1997 3146 2012 5899 1012 2002 2499 2007 2934 16469 18902 19497 3501 1012 20209 16425 13098 2085 5260 1996 9373 1998 6388 9896 6558 1006 5572 1007 2177 2073 2027 10152 2006 2119 9896 2640 1998 9896 3330 1012 2002 2907 2050 1037 4101 6098 2007 1996 2820 2005 3935 15078 4163 1006 24264 6169 1007 1012 26323 5313 20209 16425 13098 2003 2747 2920 1999 2019 24978 2546 1011 6787 2622 2007 2798 26947 8043 3385 1998 7112 3779 1997 10210 2006 2311 1037 26261 12273 4014 22334 21624 2170 1000 13433 9905 4313 1000 1012 1037 26261 12273 4014 11859 1996 3643 1997 1037 8370 2391 1999 1037 1040 1011 8789 13589 8370 2012 2051 1056 2004 1037 3853 1997 8581 8370 2685 2012 3522 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 2191 2204 2224 1997 1996 3638 12571 1998 13151 13117 2015 7320 2000 4800 17345 18017 1998 2097 2448 3435 2006 1037 7578 2275 1997 8051 7248 1012 1037 2898 3528 1997 26261 12273 4014 1011 2241 5097 1517 7478 2408 5584 1010 7366 1010 6370 1010 2943 1010 4785 1010 6228 1998 5992 3330 1010 5446 1010 1998 2060 2752 1517 2097 2468 6082 2000 4503 1998 5441 1012 2070 1997 2010 2060 3934 3579 2006 8114 7692 1011 18333 13792 1010 3435 18114 2015 22334 1010 1998 5250 1011 5250 25776 2982 1012 26323 5313 20209 16425 13098 2003 1037 7799 1997 1996 8919 24978 2546 2476 2400 1012 26323 5313 20209 16425 13098 2363 1037 2190 3259 2400 1999 12997 18927 2015 2230 2005 10449 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000034\n",
            "INFO:tensorflow:example_index: 18\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] prof reza ##ul received his phd from which university ? [SEP] times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will make good use of the memory hierarchy and processor pipeline ##s endemic to multi ##core processors and will run fast on a diverse set of hardware platforms . a wide variety of ste ##nc ##il - based applications — ranging across physics , biology , chemistry , energy , climate , mechanical and electrical engineering , finance , and other areas — will become easier to develop and maintain . some of his other projects focus on efficient resource - oblivious algorithms , fast energetic ##s computation , and protein - protein docking awards . reza ##ul chow ##dh ##ury is a recipient of the prestigious ns ##f career award . reza ##ul chow ##dh ##ury received a best paper award in ip ##dp ##s 2010 for introducing the notion of multi ##core - oblivious algorithms . he is also interested in programming contests , and won an ac ##m ic ##pc regional contest as a student . some contest problems he authored for training students are included in the \" programming challenges : the programming contest training manual \" by steven ski ##ena & miguel rev ##illa . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 12:176 13:177 14:178 15:178 16:179 17:179 18:179 19:180 20:180 21:181 22:182 23:182 24:183 25:184 26:185 27:186 28:187 29:187 30:188 31:188 32:189 33:190 34:190 35:191 36:192 37:193 38:194 39:195 40:196 41:197 42:198 43:198 44:199 45:199 46:200 47:200 48:200 49:201 50:201 51:201 52:201 53:201 54:202 55:202 56:202 57:203 58:204 59:204 60:205 61:206 62:207 63:208 64:209 65:210 66:211 67:212 68:212 69:213 70:213 71:214 72:215 73:216 74:217 75:218 76:219 77:220 78:221 79:222 80:223 81:224 82:225 83:226 84:227 85:228 86:228 87:229 88:230 89:231 90:231 91:232 92:233 93:234 94:235 95:236 96:237 97:238 98:239 99:240 100:241 101:241 102:241 103:242 104:243 105:244 106:245 107:245 108:245 109:246 110:246 111:247 112:247 113:247 114:248 115:249 116:250 117:251 118:252 119:253 120:254 121:255 122:256 123:256 124:257 125:258 126:259 127:260 128:261 129:262 130:263 131:264 132:265 133:266 134:267 135:268 136:269 137:269 138:270 139:271 140:272 141:272 142:273 143:274 144:275 145:276 146:277 147:278 148:279 149:280 150:281 151:282 152:283 153:284 154:284 155:285 156:286 157:287 158:288 159:289 160:289 161:289 162:289 163:289 164:290 165:291 166:292 167:293 168:294 169:294 170:295 171:295 172:296 173:296 174:297 175:297 176:298 177:298 178:299 179:300 180:301 181:302 182:302 183:303 184:303 185:304 186:305 187:306 188:307 189:308 190:309 191:310 192:311 193:312 194:313 195:314 196:314 197:315 198:316 199:317 200:318 201:319 202:320 203:321 204:322 205:323 206:323 207:323 208:324 209:324 210:325 211:326 212:326 213:327 214:327 215:328 216:329 217:329 218:329 219:330 220:331 221:331 222:332 223:332 224:333 225:333 226:333 227:334 228:335 229:336 230:337 231:338 232:339 233:340 234:340 235:341 236:342 237:342 238:343 239:343 240:344 241:344 242:344 243:345 244:346 245:347 246:348 247:349 248:350 249:351 250:351 251:351 252:352 253:353 254:354 255:355 256:356 257:357 258:358 259:358 260:358 261:358 262:359 263:359 264:360 265:361 266:362 267:363 268:364 269:365 270:366 271:366 272:367 273:368 274:369 275:370 276:370 277:371 278:371 279:372 280:373 281:374 282:375 283:376 284:376 285:377 286:378 287:379 288:380 289:381 290:382 291:383 292:384 293:385 294:386 295:387 296:388 297:389 298:389 299:390 300:390 301:391 302:392 303:393 304:394 305:395 306:395 307:396 308:397 309:398 310:398 311:399 312:400 313:401 314:401 315:401\n",
            "INFO:tensorflow:token_is_max_context: 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True\n",
            "INFO:tensorflow:input_ids: 101 11268 26323 5313 2363 2010 8065 2013 2029 2118 1029 102 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 2191 2204 2224 1997 1996 3638 12571 1998 13151 13117 2015 7320 2000 4800 17345 18017 1998 2097 2448 3435 2006 1037 7578 2275 1997 8051 7248 1012 1037 2898 3528 1997 26261 12273 4014 1011 2241 5097 1517 7478 2408 5584 1010 7366 1010 6370 1010 2943 1010 4785 1010 6228 1998 5992 3330 1010 5446 1010 1998 2060 2752 1517 2097 2468 6082 2000 4503 1998 5441 1012 2070 1997 2010 2060 3934 3579 2006 8114 7692 1011 18333 13792 1010 3435 18114 2015 22334 1010 1998 5250 1011 5250 25776 2982 1012 26323 5313 20209 16425 13098 2003 1037 7799 1997 1996 8919 24978 2546 2476 2400 1012 26323 5313 20209 16425 13098 2363 1037 2190 3259 2400 1999 12997 18927 2015 2230 2005 10449 1996 9366 1997 4800 17345 1011 18333 13792 1012 2002 2003 2036 4699 1999 4730 15795 1010 1998 2180 2019 9353 2213 24582 15042 3164 5049 2004 1037 3076 1012 2070 5049 3471 2002 8786 2005 2731 2493 2024 2443 1999 1996 1000 4730 7860 1024 1996 4730 5049 2731 6410 1000 2011 7112 8301 8189 1004 8374 7065 9386 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000035\n",
            "INFO:tensorflow:example_index: 19\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] what are some ste ##nc ##il based applications ? [SEP] reza ##ul chow ##dh ##ury received his ph . d . from the department of computer sciences , ut austin , working with professor vijay ##a rama ##chan ##dran , and defending \" cache - efficient algorithms and data structures : theory and experimental evaluation \" . prior to joining sb ##u in 2011 , he was in boston working with professor sand ##or va ##j ##da ' s structural bio ##in ##form ##atics group at boston university , and professor charles lei ##ser ##son ' s super ##tech research group at mit . before moving to boston , he was a postdoctoral fellow at the center for computational visual ##ization ( cv ##c ) , institute for computational engineering & sciences ( ice ##s ) , university of texas at austin . he worked with professor chandra ##jit baja ##j . chow ##dh ##ury now leads the theoretical and experimental algorithm ##ics ( tea ) group where they concentrate on both algorithm design and algorithm engineering . he hold ##a a joint appointment with the institute for advanced computational sciences ( ia ##cs ) . reza ##ul chow ##dh ##ury is currently involved in an ns ##f - funded project with charles lei ##ser ##son and steven johnson of mit on building a ste ##nc ##il computation compiler called \" po ##cho ##ir \" . a ste ##nc ##il defines the value of a grid point in a d - dimensional spatial grid at time t as a function of neighboring grid points at recent times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will make [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:0 13:1 14:1 15:1 16:2 17:3 18:4 19:4 20:4 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:10 29:11 30:12 31:12 32:13 33:14 34:15 35:16 36:16 37:17 38:17 39:17 40:17 41:18 42:19 43:20 44:20 45:20 46:20 47:21 48:22 49:23 50:24 51:24 52:25 53:26 54:27 55:28 56:28 57:28 58:29 59:30 60:31 61:32 62:32 63:33 64:34 65:34 66:35 67:36 68:37 69:38 70:39 71:40 72:41 73:42 74:42 75:43 76:43 77:43 78:43 79:43 80:44 81:45 82:45 83:45 84:45 85:46 86:47 87:48 88:49 89:49 90:50 91:51 92:52 93:53 94:53 95:53 96:53 97:53 98:54 99:54 100:55 101:56 102:57 103:58 104:58 105:59 106:60 107:61 108:62 109:62 110:63 111:64 112:65 113:66 114:67 115:68 116:69 117:70 118:71 119:72 120:73 121:73 122:74 123:74 124:74 125:74 126:74 127:75 128:76 129:77 130:78 131:79 132:80 133:81 134:81 135:81 136:81 137:81 138:82 139:83 140:84 141:85 142:86 143:86 144:87 145:88 146:89 147:90 148:91 149:91 150:92 151:92 152:92 153:93 154:93 155:93 156:94 157:95 158:96 159:97 160:98 161:99 162:100 163:100 164:101 165:101 166:101 167:102 168:103 169:104 170:105 171:106 172:107 173:108 174:109 175:110 176:111 177:112 178:112 179:113 180:114 181:114 182:115 183:116 184:117 185:118 186:119 187:120 188:121 189:122 190:123 191:124 192:125 193:125 194:125 195:125 196:125 197:125 198:125 199:126 200:126 201:126 202:127 203:128 204:129 205:130 206:131 207:132 208:132 209:132 210:132 211:133 212:134 213:135 214:136 215:136 216:136 217:137 218:138 219:139 220:140 221:141 222:142 223:143 224:144 225:145 226:145 227:145 228:146 229:147 230:148 231:149 232:149 233:149 234:149 235:149 236:149 237:150 238:151 239:151 240:151 241:152 242:153 243:154 244:155 245:156 246:157 247:158 248:159 249:160 250:161 251:161 252:161 253:162 254:163 255:164 256:165 257:166 258:167 259:168 260:169 261:170 262:171 263:172 264:173 265:174 266:175 267:176 268:177 269:178 270:178 271:179 272:179 273:179 274:180 275:180 276:181 277:182 278:182 279:183 280:184 281:185 282:186 283:187 284:187 285:188 286:188 287:189 288:190 289:190 290:191 291:192 292:193 293:194 294:195 295:196 296:197 297:198 298:198 299:199 300:199 301:200 302:200 303:200 304:201 305:201 306:201 307:201 308:201 309:202 310:202 311:202 312:203 313:204 314:204 315:205 316:206 317:207 318:208 319:209 320:210 321:211 322:212 323:212 324:213 325:213 326:214 327:215 328:216 329:217 330:218 331:219 332:220 333:221 334:222 335:223 336:224 337:225 338:226 339:227 340:228 341:228 342:229 343:230 344:231 345:231 346:232 347:233 348:234 349:235 350:236 351:237 352:238 353:239 354:240 355:241 356:241 357:241 358:242 359:243 360:244 361:245 362:245 363:245 364:246 365:246 366:247 367:247 368:247 369:248 370:249 371:250 372:251 373:252 374:253 375:254 376:255 377:256 378:256 379:257 380:258 381:259 382:260\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 2070 26261 12273 4014 2241 5097 1029 102 26323 5313 20209 16425 13098 2363 2010 6887 1012 1040 1012 2013 1996 2533 1997 3274 4163 1010 21183 5899 1010 2551 2007 2934 17027 2050 14115 14856 24914 1010 1998 6984 1000 17053 1011 8114 13792 1998 2951 5090 1024 3399 1998 6388 9312 1000 1012 3188 2000 5241 24829 2226 1999 2249 1010 2002 2001 1999 3731 2551 2007 2934 5472 2953 12436 3501 2850 1005 1055 8332 16012 2378 14192 17592 2177 2012 3731 2118 1010 1998 2934 2798 26947 8043 3385 1005 1055 3565 15007 2470 2177 2012 10210 1012 2077 3048 2000 3731 1010 2002 2001 1037 29272 3507 2012 1996 2415 2005 15078 5107 3989 1006 26226 2278 1007 1010 2820 2005 15078 3330 1004 4163 1006 3256 2015 1007 1010 2118 1997 3146 2012 5899 1012 2002 2499 2007 2934 16469 18902 19497 3501 1012 20209 16425 13098 2085 5260 1996 9373 1998 6388 9896 6558 1006 5572 1007 2177 2073 2027 10152 2006 2119 9896 2640 1998 9896 3330 1012 2002 2907 2050 1037 4101 6098 2007 1996 2820 2005 3935 15078 4163 1006 24264 6169 1007 1012 26323 5313 20209 16425 13098 2003 2747 2920 1999 2019 24978 2546 1011 6787 2622 2007 2798 26947 8043 3385 1998 7112 3779 1997 10210 2006 2311 1037 26261 12273 4014 22334 21624 2170 1000 13433 9905 4313 1000 1012 1037 26261 12273 4014 11859 1996 3643 1997 1037 8370 2391 1999 1037 1040 1011 8789 13589 8370 2012 2051 1056 2004 1037 3853 1997 8581 8370 2685 2012 3522 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 2191 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000036\n",
            "INFO:tensorflow:example_index: 19\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] what are some ste ##nc ##il based applications ? [SEP] of texas at austin . he worked with professor chandra ##jit baja ##j . chow ##dh ##ury now leads the theoretical and experimental algorithm ##ics ( tea ) group where they concentrate on both algorithm design and algorithm engineering . he hold ##a a joint appointment with the institute for advanced computational sciences ( ia ##cs ) . reza ##ul chow ##dh ##ury is currently involved in an ns ##f - funded project with charles lei ##ser ##son and steven johnson of mit on building a ste ##nc ##il computation compiler called \" po ##cho ##ir \" . a ste ##nc ##il defines the value of a grid point in a d - dimensional spatial grid at time t as a function of neighboring grid points at recent times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will make good use of the memory hierarchy and processor pipeline ##s endemic to multi ##core processors and will run fast on a diverse set of hardware platforms . a wide variety of ste ##nc ##il - based applications — ranging across physics , biology , chemistry , energy , climate , mechanical and electrical engineering , finance , and other areas — will become easier to develop and maintain . some of his other projects focus on efficient resource - oblivious algorithms , fast energetic ##s computation , and protein - protein docking awards . reza ##ul chow ##dh ##ury is a recipient of the prestigious ns ##f career award . reza ##ul chow ##dh ##ury received a best paper award in ip ##dp ##s 2010 for introducing the [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:83 12:84 13:85 14:86 15:86 16:87 17:88 18:89 19:90 20:91 21:91 22:92 23:92 24:92 25:93 26:93 27:93 28:94 29:95 30:96 31:97 32:98 33:99 34:100 35:100 36:101 37:101 38:101 39:102 40:103 41:104 42:105 43:106 44:107 45:108 46:109 47:110 48:111 49:112 50:112 51:113 52:114 53:114 54:115 55:116 56:117 57:118 58:119 59:120 60:121 61:122 62:123 63:124 64:125 65:125 66:125 67:125 68:125 69:125 70:125 71:126 72:126 73:126 74:127 75:128 76:129 77:130 78:131 79:132 80:132 81:132 82:132 83:133 84:134 85:135 86:136 87:136 88:136 89:137 90:138 91:139 92:140 93:141 94:142 95:143 96:144 97:145 98:145 99:145 100:146 101:147 102:148 103:149 104:149 105:149 106:149 107:149 108:149 109:150 110:151 111:151 112:151 113:152 114:153 115:154 116:155 117:156 118:157 119:158 120:159 121:160 122:161 123:161 124:161 125:162 126:163 127:164 128:165 129:166 130:167 131:168 132:169 133:170 134:171 135:172 136:173 137:174 138:175 139:176 140:177 141:178 142:178 143:179 144:179 145:179 146:180 147:180 148:181 149:182 150:182 151:183 152:184 153:185 154:186 155:187 156:187 157:188 158:188 159:189 160:190 161:190 162:191 163:192 164:193 165:194 166:195 167:196 168:197 169:198 170:198 171:199 172:199 173:200 174:200 175:200 176:201 177:201 178:201 179:201 180:201 181:202 182:202 183:202 184:203 185:204 186:204 187:205 188:206 189:207 190:208 191:209 192:210 193:211 194:212 195:212 196:213 197:213 198:214 199:215 200:216 201:217 202:218 203:219 204:220 205:221 206:222 207:223 208:224 209:225 210:226 211:227 212:228 213:228 214:229 215:230 216:231 217:231 218:232 219:233 220:234 221:235 222:236 223:237 224:238 225:239 226:240 227:241 228:241 229:241 230:242 231:243 232:244 233:245 234:245 235:245 236:246 237:246 238:247 239:247 240:247 241:248 242:249 243:250 244:251 245:252 246:253 247:254 248:255 249:256 250:256 251:257 252:258 253:259 254:260 255:261 256:262 257:263 258:264 259:265 260:266 261:267 262:268 263:269 264:269 265:270 266:271 267:272 268:272 269:273 270:274 271:275 272:276 273:277 274:278 275:279 276:280 277:281 278:282 279:283 280:284 281:284 282:285 283:286 284:287 285:288 286:289 287:289 288:289 289:289 290:289 291:290 292:291 293:292 294:293 295:294 296:294 297:295 298:295 299:296 300:296 301:297 302:297 303:298 304:298 305:299 306:300 307:301 308:302 309:302 310:303 311:303 312:304 313:305 314:306 315:307 316:308 317:309 318:310 319:311 320:312 321:313 322:314 323:314 324:315 325:316 326:317 327:318 328:319 329:320 330:321 331:322 332:323 333:323 334:323 335:324 336:324 337:325 338:326 339:326 340:327 341:327 342:328 343:329 344:329 345:329 346:330 347:331 348:331 349:332 350:332 351:333 352:333 353:333 354:334 355:335 356:336 357:337 358:338 359:339 360:340 361:340 362:341 363:342 364:342 365:343 366:343 367:344 368:344 369:344 370:345 371:346 372:347 373:348 374:349 375:350 376:351 377:351 378:351 379:352 380:353 381:354 382:355\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 2070 26261 12273 4014 2241 5097 1029 102 1997 3146 2012 5899 1012 2002 2499 2007 2934 16469 18902 19497 3501 1012 20209 16425 13098 2085 5260 1996 9373 1998 6388 9896 6558 1006 5572 1007 2177 2073 2027 10152 2006 2119 9896 2640 1998 9896 3330 1012 2002 2907 2050 1037 4101 6098 2007 1996 2820 2005 3935 15078 4163 1006 24264 6169 1007 1012 26323 5313 20209 16425 13098 2003 2747 2920 1999 2019 24978 2546 1011 6787 2622 2007 2798 26947 8043 3385 1998 7112 3779 1997 10210 2006 2311 1037 26261 12273 4014 22334 21624 2170 1000 13433 9905 4313 1000 1012 1037 26261 12273 4014 11859 1996 3643 1997 1037 8370 2391 1999 1037 1040 1011 8789 13589 8370 2012 2051 1056 2004 1037 3853 1997 8581 8370 2685 2012 3522 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 2191 2204 2224 1997 1996 3638 12571 1998 13151 13117 2015 7320 2000 4800 17345 18017 1998 2097 2448 3435 2006 1037 7578 2275 1997 8051 7248 1012 1037 2898 3528 1997 26261 12273 4014 1011 2241 5097 1517 7478 2408 5584 1010 7366 1010 6370 1010 2943 1010 4785 1010 6228 1998 5992 3330 1010 5446 1010 1998 2060 2752 1517 2097 2468 6082 2000 4503 1998 5441 1012 2070 1997 2010 2060 3934 3579 2006 8114 7692 1011 18333 13792 1010 3435 18114 2015 22334 1010 1998 5250 1011 5250 25776 2982 1012 26323 5313 20209 16425 13098 2003 1037 7799 1997 1996 8919 24978 2546 2476 2400 1012 26323 5313 20209 16425 13098 2363 1037 2190 3259 2400 1999 12997 18927 2015 2230 2005 10449 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000037\n",
            "INFO:tensorflow:example_index: 19\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] what are some ste ##nc ##il based applications ? [SEP] times before t . ste ##nc ##il computation ##s are conceptual ##ly simple to implement using nest ##ed loops , but loop ##ing implementations suffer from poor cache performance on multi ##core processors . cache - efficient divide - and - conquer ste ##nc ##il algorithms exist , but most programmers find them difficult to implement . moreover , open problems remain in adapting these algorithms to realistic applications that lack the perfect regular ##ity of simple examples . this research aims to develop a language embedded in c + + that can express ste ##nc ##il computation ##s con ##cise ##ly and can be compiled automatically into highly efficient algorithm ##ic code that will make good use of the memory hierarchy and processor pipeline ##s endemic to multi ##core processors and will run fast on a diverse set of hardware platforms . a wide variety of ste ##nc ##il - based applications — ranging across physics , biology , chemistry , energy , climate , mechanical and electrical engineering , finance , and other areas — will become easier to develop and maintain . some of his other projects focus on efficient resource - oblivious algorithms , fast energetic ##s computation , and protein - protein docking awards . reza ##ul chow ##dh ##ury is a recipient of the prestigious ns ##f career award . reza ##ul chow ##dh ##ury received a best paper award in ip ##dp ##s 2010 for introducing the notion of multi ##core - oblivious algorithms . he is also interested in programming contests , and won an ac ##m ic ##pc regional contest as a student . some contest problems he authored for training students are included in the \" programming challenges : the programming contest training manual \" by steven ski ##ena & miguel rev ##illa . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:176 12:177 13:178 14:178 15:179 16:179 17:179 18:180 19:180 20:181 21:182 22:182 23:183 24:184 25:185 26:186 27:187 28:187 29:188 30:188 31:189 32:190 33:190 34:191 35:192 36:193 37:194 38:195 39:196 40:197 41:198 42:198 43:199 44:199 45:200 46:200 47:200 48:201 49:201 50:201 51:201 52:201 53:202 54:202 55:202 56:203 57:204 58:204 59:205 60:206 61:207 62:208 63:209 64:210 65:211 66:212 67:212 68:213 69:213 70:214 71:215 72:216 73:217 74:218 75:219 76:220 77:221 78:222 79:223 80:224 81:225 82:226 83:227 84:228 85:228 86:229 87:230 88:231 89:231 90:232 91:233 92:234 93:235 94:236 95:237 96:238 97:239 98:240 99:241 100:241 101:241 102:242 103:243 104:244 105:245 106:245 107:245 108:246 109:246 110:247 111:247 112:247 113:248 114:249 115:250 116:251 117:252 118:253 119:254 120:255 121:256 122:256 123:257 124:258 125:259 126:260 127:261 128:262 129:263 130:264 131:265 132:266 133:267 134:268 135:269 136:269 137:270 138:271 139:272 140:272 141:273 142:274 143:275 144:276 145:277 146:278 147:279 148:280 149:281 150:282 151:283 152:284 153:284 154:285 155:286 156:287 157:288 158:289 159:289 160:289 161:289 162:289 163:290 164:291 165:292 166:293 167:294 168:294 169:295 170:295 171:296 172:296 173:297 174:297 175:298 176:298 177:299 178:300 179:301 180:302 181:302 182:303 183:303 184:304 185:305 186:306 187:307 188:308 189:309 190:310 191:311 192:312 193:313 194:314 195:314 196:315 197:316 198:317 199:318 200:319 201:320 202:321 203:322 204:323 205:323 206:323 207:324 208:324 209:325 210:326 211:326 212:327 213:327 214:328 215:329 216:329 217:329 218:330 219:331 220:331 221:332 222:332 223:333 224:333 225:333 226:334 227:335 228:336 229:337 230:338 231:339 232:340 233:340 234:341 235:342 236:342 237:343 238:343 239:344 240:344 241:344 242:345 243:346 244:347 245:348 246:349 247:350 248:351 249:351 250:351 251:352 252:353 253:354 254:355 255:356 256:357 257:358 258:358 259:358 260:358 261:359 262:359 263:360 264:361 265:362 266:363 267:364 268:365 269:366 270:366 271:367 272:368 273:369 274:370 275:370 276:371 277:371 278:372 279:373 280:374 281:375 282:376 283:376 284:377 285:378 286:379 287:380 288:381 289:382 290:383 291:384 292:385 293:386 294:387 295:388 296:389 297:389 298:390 299:390 300:391 301:392 302:393 303:394 304:395 305:395 306:396 307:397 308:398 309:398 310:399 311:400 312:401 313:401 314:401\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 2070 26261 12273 4014 2241 5097 1029 102 2335 2077 1056 1012 26261 12273 4014 22334 2015 2024 17158 2135 3722 2000 10408 2478 9089 2098 15932 1010 2021 7077 2075 24977 9015 2013 3532 17053 2836 2006 4800 17345 18017 1012 17053 1011 8114 11443 1011 1998 1011 16152 26261 12273 4014 13792 4839 1010 2021 2087 28547 2424 2068 3697 2000 10408 1012 9308 1010 2330 3471 3961 1999 25357 2122 13792 2000 12689 5097 2008 3768 1996 3819 3180 3012 1997 3722 4973 1012 2023 2470 8704 2000 4503 1037 2653 11157 1999 1039 1009 1009 2008 2064 4671 26261 12273 4014 22334 2015 9530 18380 2135 1998 2064 2022 9227 8073 2046 3811 8114 9896 2594 3642 2008 2097 2191 2204 2224 1997 1996 3638 12571 1998 13151 13117 2015 7320 2000 4800 17345 18017 1998 2097 2448 3435 2006 1037 7578 2275 1997 8051 7248 1012 1037 2898 3528 1997 26261 12273 4014 1011 2241 5097 1517 7478 2408 5584 1010 7366 1010 6370 1010 2943 1010 4785 1010 6228 1998 5992 3330 1010 5446 1010 1998 2060 2752 1517 2097 2468 6082 2000 4503 1998 5441 1012 2070 1997 2010 2060 3934 3579 2006 8114 7692 1011 18333 13792 1010 3435 18114 2015 22334 1010 1998 5250 1011 5250 25776 2982 1012 26323 5313 20209 16425 13098 2003 1037 7799 1997 1996 8919 24978 2546 2476 2400 1012 26323 5313 20209 16425 13098 2363 1037 2190 3259 2400 1999 12997 18927 2015 2230 2005 10449 1996 9366 1997 4800 17345 1011 18333 13792 1012 2002 2003 2036 4699 1999 4730 15795 1010 1998 2180 2019 9353 2213 24582 15042 3164 5049 2004 1037 3076 1012 2070 5049 3471 2002 8786 2005 2731 2493 2024 2443 1999 1996 1000 4730 7860 1024 1996 4730 5049 2731 6410 1000 2011 7112 8301 8189 1004 8374 7065 9386 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 48\n",
            "INFO:tensorflow:  Num split examples = 74\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "WARNING:tensorflow:From run_squad.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-12-11 07:32:09.746072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-12-11 07:32:09.746565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-12-11 07:32:09.746610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-12-11 07:32:10.212472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-12-11 07:32:10.212554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-12-11 07:32:10.212573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-12-11 07:32:10.212952: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-12-11 07:32:10.213013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from output_small/model.ckpt-11000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:Writing predictions to: output_small/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: output_small/nbest_predictions.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fbn_jkSwcDaH",
        "colab_type": "code",
        "outputId": "0f30a9e4-f453-4b05-ba1e-ea4beae843ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "cell_type": "code",
      "source": [
        "!cat output_small/predictions.json"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"c0a0\": \"SHIP\",\n",
            "    \"c0a1\": \"United Healthcare\",\n",
            "    \"c0a2\": \"$200\",\n",
            "    \"c0a3\": \"$3,000\",\n",
            "    \"c0a4\": \"to your student account in SOLAR\",\n",
            "    \"c0a5\": \"United Healthcare Customer Service\",\n",
            "    \"c0a6\": \"Student Health Insurance Office\",\n",
            "    \"c1a0\": \"$624.45\",\n",
            "    \"c1a1\": \"$867.83\",\n",
            "    \"c1a2\": \"$10 copay for tier 1 drugs, and a $20\",\n",
            "    \"c1a3\": \"$20\",\n",
            "    \"c1a4\": \"$20\",\n",
            "    \"c1a5\": \"to your student account in SOLAR\",\n",
            "    \"c1a6\": \"Unlimited coverage\",\n",
            "    \"c1a7\": \"Unlimited coverage\",\n",
            "    \"c2a0\": \"You are required to graduate\",\n",
            "    \"c3a0\": \"Grades for courses that are \\\"repeatable for credit\\\" cannot be forgiven this way\",\n",
            "    \"c4a0\": \"University of Massachusetts, Amherst\",\n",
            "    \"c5a0\": \"UT Austin\",\n",
            "    \"c5a1\": \"physics, biology, chemistry, energy, climate, mechanical and electrical engineering, finance\",\n",
            "    \"c5a2\": \"IPDPS 2010\",\n",
            "    \"c5a3\": \"Pochoir\",\n",
            "    \"c5a4\": \"Pochoir\",\n",
            "    \"c6a0\": \"John S. Toll\",\n",
            "    \"c6a1\": \"1971\",\n",
            "    \"c7a0\": \"1957\",\n",
            "    \"c7a1\": \"220\",\n",
            "    \"c7a2\": \"It is also a member of the larger Universities Research Association\",\n",
            "    \"c8a0\": \"Stony Brook, New York\",\n",
            "    \"c8a1\": \"It is part of the State University of New York (SUNY) system\",\n",
            "    \"c9a0\": \"Seawolves\",\n",
            "    \"c10a0\": \"15,000\",\n",
            "    \"c11a0\": \"Nelson Rockefeller\",\n",
            "    \"c11a1\": \"1960\",\n",
            "    \"c12a0\": \"782\",\n",
            "    \"c13a0\": \"Shirley Strum Kenny\",\n",
            "    \"c14a0\": \"relatively affordable tuition\",\n",
            "    \"c15a0\": \"Kenneth P. LaValle Stadium\",\n",
            "    \"c15a1\": \"Joe Nathan, Stuart Goldstein, and Glenn Dubin\",\n",
            "    \"c16a0\": \"70,000 square feet\",\n",
            "    \"c16a1\": \"$40.8 million\",\n",
            "    \"c17a0\": \"The west campus\",\n",
            "    \"c17a1\": \"The athletic facilities are in the northwest quadrant of west campus\",\n",
            "    \"c18a0\": \"Soundmen\",\n",
            "    \"c18a1\": \"Wolfie\",\n",
            "    \"c19a0\": \"Joe Nathan\",\n",
            "    \"c19a1\": \"2018\",\n",
            "    \"c20a0\": \"Port Jefferson Line\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rWX7IcPaaOrn",
        "colab_type": "code",
        "outputId": "8906dbfb-34a5-4c4a-bae9-2c90091c2e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 evaluate-v2.0.py handmade_qa_sbu.json  /Downloads/output_3MB/predictions.json #trained on 100% data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 41.666666666666664,\n",
            "  \"f1\": 59.3946158008658,\n",
            "  \"total\": 48,\n",
            "  \"HasAns_exact\": 41.666666666666664,\n",
            "  \"HasAns_f1\": 59.3946158008658,\n",
            "  \"HasAns_total\": 48\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rb9OtY0oBKQd",
        "colab_type": "code",
        "outputId": "52ad3d0a-5d65-4a5b-815d-503f4e2327ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 evaluate-v2.0.py qna_sbu.json  /Downloads/output_small/predictions.json #trained on 100% data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 78.05429864253394,\n",
            "  \"f1\": 88.05315913347594,\n",
            "  \"total\": 442,\n",
            "  \"HasAns_exact\": 78.05429864253394,\n",
            "  \"HasAns_f1\": 88.05315913347594,\n",
            "  \"HasAns_total\": 442\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RHgfxU9daVtY",
        "colab_type": "code",
        "outputId": "0c84cb5d-5a9a-46bb-c5a8-6daba353c616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 evaluate-v2.0.py qna_sbu.json  /Downloads/output_3MB/predictions.json #trained on 30% data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 70.58823529411765,\n",
            "  \"f1\": 81.10657521410083,\n",
            "  \"total\": 442,\n",
            "  \"HasAns_exact\": 70.58823529411765,\n",
            "  \"HasAns_f1\": 81.10657521410083,\n",
            "  \"HasAns_total\": 442\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QKgXad0ADPD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}